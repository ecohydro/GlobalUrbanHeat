{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tmax States Final\n",
    "\n",
    "A notebook to subset Tmax daily for the 13000 GHS urban areas to identify dates >40c, consecuritve days >40 c etc.\n",
    "\n",
    "Moved from cpt_tmax_old on 2020.02.22 by Cascade Tuholske"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from random import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import geopandas as gpd \n",
    "import glob\n",
    "from statistics import mean\n",
    "import julian\n",
    "import time \n",
    "import multiprocessing as mp \n",
    "from multiprocessing import Pool\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Function Loads all Tmax Data as an X-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir_path, space_dim, time_dim):\n",
    "    \"\"\" Function reads in all Tmax .csv files, joins them by date along the x-axis\n",
    "    and returns the whole record as a x-array data array\n",
    "    \n",
    "    Args:   \n",
    "        dir_path = path to .csv files \n",
    "        time_dim = name for time dim as a str ... use date :-)\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0)\n",
    "    \"\"\"\n",
    "    fn_list = sorted(glob.glob(dir_path+'*.csv'))\n",
    "    df_out = pd.DataFrame()\n",
    "    date_list = []\n",
    "\n",
    "    # Open all Tmax files and concat into a df\n",
    "    for i, fn in enumerate(fn_list):    \n",
    "        # Open the CSV\n",
    "        df = pd.read_csv(fn)\n",
    "\n",
    "        # Get the city ids \n",
    "        if i == 1:\n",
    "            df_id = df[space_dim]\n",
    "\n",
    "        # get only the Tmax columns and concate date list \n",
    "        df_temp = df.iloc[:,3:] # get only temp columns\n",
    "        date_list = date_list+list(df_temp.columns)\n",
    "\n",
    "        # Drop cities w/ no temp record \n",
    "        df_temp_drop = df_temp.dropna()\n",
    "\n",
    "        # Merge\n",
    "        df_out = pd.concat([df_out, df_temp_drop], axis=1)\n",
    "        print(df_out.shape)\n",
    "    \n",
    "    # make date into an array\n",
    "    tmax_arr = df_out.to_numpy()\n",
    "\n",
    "    # Make data into an xr.DataArray\n",
    "    tmax_xr_da = xr.DataArray(tmax_arr, coords=[df_id, date_list], \n",
    "                             dims=[space_dim, time_dim])\n",
    "    return tmax_xr_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 Function finds all the Tmax Events and writes it to a dateframe w/ dates for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_days(xarray, Tthresh):\n",
    "    \"\"\" Function finds all the tmax days in a year and sums total days per year \n",
    "    greater than a threshold within a year where Tmax > Tthresh for each city. Returns the total number of days,\n",
    "    the dates, the tempatures, and the intensity (daily Tmax - Tthresh)\n",
    "    \n",
    "    Args: \n",
    "        xarray = an xarray object with dims = (space, times)\n",
    "        Tthresh = float of temp threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty lists & df\n",
    "    id_list = []\n",
    "    date_list = []\n",
    "    tmax_list = []\n",
    "    intensity_list = []\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # subset xarray\n",
    "    out = xarray.where(xarray > Tthresh, drop = True)\n",
    "\n",
    "    # start loop \n",
    "    for index, loc in enumerate(out.ID_HDC_G0):\n",
    "        id_list.append(out.ID_HDC_G0.values[index]) # get IDS\n",
    "        date_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values) # get event dates\n",
    "        \n",
    "        # #CPT 2020.02.23 \n",
    "        # dayTot_list.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values)) # get event totals\n",
    "        \n",
    "        tmax_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values) # get temp values\n",
    "        intensity_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values - Tthresh) # get severity\n",
    "\n",
    "    # write to a data frame\n",
    "    df_out['ID_HDC_G0'] = id_list\n",
    "    # df_out['total_days'] = dayTot_list #CPT 2020.02.23\n",
    "    df_out['dates'] = date_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "    df_out['tmax_tntensity'] = intensity_list\n",
    "\n",
    "    # return df_out\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 Function chunks Tmax events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's split test 2\n",
    "# def chunk_df(df, n, DATA_IN):\n",
    "#     \"Function chunks a data frame and puts chunks in a list, n is number of chunks\"\n",
    "#     list_df = [df[i:i+n] for i in range(0,df.shape[0],n)]\n",
    "    \n",
    "#     for i in range(n):\n",
    "#         out_fn = DATA_IN+'chunk_'+str(i)+'.csv'\n",
    "#         list_df[i].to_csv(out_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 Function splits the dataset into Tmax events (continuous days >Tmax) for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jul_convert(dates):\n",
    "    \"Function turn days into julian datetime\"\n",
    "    jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "    \n",
    "    return jul_days\n",
    "\n",
    "def event_split(dates, ID_HDC_G0, intensity, tmax): #, total_days): #CPT 2020.02.23\n",
    "    \n",
    "    \"\"\" Searchs a list of dates and isolates sequential dates as a list, then calculates event stats.\n",
    "    See comments in code for more details. \n",
    "    \n",
    "    Args:\n",
    "        dates: pandas.core.index as julian dates\n",
    "        ID_HDC_G0: city ID as string\n",
    "        intensity: numpy.ndarray of intensities values\n",
    "        tmax: numpy.ndarray of intensities values of tmax values\n",
    "        total_days: total number of tmax days in a year for a given city\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # city id\n",
    "    city_id = ID_HDC_G0\n",
    "    # tot_days = total_days #CPT 2020.02.23\n",
    "    \n",
    "    # lists to fill\n",
    "    city_id_list = []\n",
    "    # tot_days_list = [] #CPT 2020.02.23\n",
    "    event_dates_list = []\n",
    "    dur_list = []\n",
    "    intensity_list = []\n",
    "    tmax_list = []\n",
    "    avg_temp_list = []\n",
    "    avg_int_list = []\n",
    "    tot_int_list = []\n",
    "    year_list = []\n",
    "    \n",
    "    # data frame out\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # turn days into julian days\n",
    "    jul_days = jul_convert(dates)\n",
    "    \n",
    "    # Counters to make sure we write the correct event dates to a list, don't want julian days in output\n",
    "    counter = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    # Loop through dur list and isolate seq days, temps, and intensities\n",
    "    for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "        \n",
    "        seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "        dur = len(seq) # duration of each event\n",
    "        \n",
    "        counter = counter + dur # add duration to counter\n",
    "        end = counter # end of current event\n",
    "        \n",
    "        event_dates = dates[start:end] # dates of tmax days during each event\n",
    "        intense = intensity[start:end] # intensity of each day during event\n",
    "        temp = tmax[start:end] # temp of each day during event\n",
    "        avg_temp = mean(temp) # avg. temp during event\n",
    "        avg_int = mean(intense) # avg. intensity during event\n",
    "        tot_int = intense.sum() # total intensity during event\n",
    "        \n",
    "        start = counter # reset start to current end (e.g. counter)\n",
    "        year = event_dates[0].split('.')[0]\n",
    "        \n",
    "        # fill lists\n",
    "        city_id_list.append(city_id)\n",
    "        year_list.append(year)\n",
    "        # tot_days_list.append(tot_days) #CPT 2020.02.23\n",
    "        dur_list.append(dur)\n",
    "        event_dates_list.append(event_dates)\n",
    "        intensity_list.append(intense)\n",
    "        tmax_list.append(temp)\n",
    "        avg_temp_list.append(avg_temp)\n",
    "        avg_int_list.append(avg_int)\n",
    "        tot_int_list.append(tot_int)\n",
    "\n",
    "    # write out as a dateframe\n",
    "    df_out['ID_HDC_G0'] = city_id_list\n",
    "    df_out['year'] = year_list\n",
    "    # df_out['total_days'] = tot_days_list #CPT 2020.02.23\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['avg_temp'] = avg_temp_list\n",
    "    df_out['avg_intensity'] = avg_int_list\n",
    "    df_out['tot_intensity'] = tot_int_list\n",
    "    df_out['event_dates'] = event_dates_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['intensity'] = intensity_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 function feeds output from function 3 into function 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_stats(df_in):\n",
    "    \"\"\" runs event_split functionon a dataframe to produce desired tmax stats\n",
    "\n",
    "        NOTE - If you add arguments to event_split to make more states,\n",
    "        be sure to update this function\n",
    "\n",
    "        args:\n",
    "            df: input dataframe\n",
    "    \"\"\"\n",
    "    df_out = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # NOTE - If you add arguments to event_split to make more stats,\n",
    "    # be sure to update this function\n",
    "\n",
    "    for index, row in df_in.iterrows():\n",
    "        dates = row['dates'] # Get event dates\n",
    "        intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "        tmax = row['tmax'] # Get tmax for each day\n",
    "        ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "        # total_days = row['total_days'] # get total number of tmax days -- CPT 2020.02.23\n",
    "\n",
    "        df = event_split(dates, ID_HDC_G0, intensity, tmax)# , total_days) #CPT 2020.02.23\n",
    "\n",
    "        df_out = df_out.append(df)\n",
    "\n",
    "    return df_out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 function threads it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stats(dir_path, space_dim, time_dim, Tthresh, fn_out):\n",
    "    \n",
    "    \"\"\" Function ties all the Tmax Stats functions together and writes final stats for each Tmax \n",
    "    event to a .csv file. Returns results as a dataframe if needed\n",
    "    \n",
    "    Args:\n",
    "        dir_path = path to .csv files \n",
    "        time_dim = name for time dim as a str ... use date :-)\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0)\n",
    "        Tthresh = float of temp threshold\n",
    "        fn_out = file and path to write final csv\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # read in data\n",
    "    step1= read_data(dir_path, space_dim = space_dim, time_dim = time_dim)\n",
    "    #step1_sub = step1[:,:10] # subset data for testing\n",
    "    print('Stack x-array made')\n",
    "    \n",
    "    # Mask data based on Tmax threshold ... we're using 40.6C\n",
    "    step2 = tmax_days(step1, Tthresh)\n",
    "    print('Tmax masked')\n",
    "    \n",
    "    \n",
    "    # Calculate stats\n",
    "    step3 = tmax_stats(step2)\n",
    "    print('Stats made')\n",
    "\n",
    "    # Save file out\n",
    "    #step3.to_csv(fn_out)\n",
    "    \n",
    "    return step3\n",
    "\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-HI/' # output from avg temp\n",
    "DATA_OUT = '/home/cascade/projects/UrbanHeat/data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_path = DATA_IN \n",
    "space_dim = 'ID_HDC_G0'\n",
    "time_dim = 'date'\n",
    "Tthresh = 40.6\n",
    "fn_out = DATA_OUT+'All_data_HI406.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13067, 365)\n",
      "(13067, 731)\n",
      "(13067, 1096)\n",
      "(13067, 1461)\n",
      "(13067, 1826)\n",
      "(13067, 2192)\n",
      "(13067, 2557)\n",
      "(13067, 2922)\n",
      "(13067, 3287)\n",
      "(13067, 3653)\n",
      "(13067, 4018)\n",
      "(13067, 4383)\n",
      "(13067, 4748)\n",
      "(13067, 5114)\n",
      "(13067, 5479)\n",
      "(13067, 5844)\n",
      "(13067, 6209)\n",
      "(13067, 6575)\n",
      "(13067, 6940)\n",
      "(13067, 7305)\n",
      "(13067, 7670)\n",
      "(13067, 8036)\n",
      "(13067, 8401)\n",
      "(13067, 8766)\n",
      "(13067, 9131)\n",
      "(13067, 9497)\n",
      "(13067, 9862)\n",
      "(13067, 10227)\n",
      "(13067, 10592)\n",
      "(13067, 10958)\n",
      "(13067, 11323)\n",
      "(13067, 11688)\n",
      "(13067, 12053)\n",
      "(13067, 12419)\n",
      "Stack x-array made\n",
      "Tmax masked\n",
      "Stats made\n"
     ]
    }
   ],
   "source": [
    "runit = run_stats(dir_path, space_dim, time_dim, Tthresh, fn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1521"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(runit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1= read_data(dir_path, space_dim = space_dim, time_dim = time_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_sub = step1[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tthresh = 40.6\n",
    "step2 = tmax_days(step1_sub, Tthresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_out = tmax_stats(step2)\n",
    "\n",
    "### NOTE 2020.02.22 --- see if this write out correctly\n",
    "#df_out.to_csv('/home/cascade/projects/UrbanHeat/data/All_stats_HI406_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>year</th>\n",
       "      <th>duration</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_intensity</th>\n",
       "      <th>tot_intensity</th>\n",
       "      <th>event_dates</th>\n",
       "      <th>intensity</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10630</td>\n",
       "      <td>1983</td>\n",
       "      <td>2</td>\n",
       "      <td>41.169058</td>\n",
       "      <td>0.569058</td>\n",
       "      <td>1.138117</td>\n",
       "      <td>[1983.01.06, 1983.01.07]</td>\n",
       "      <td>[0.29257217264085256, 0.8455443555204525]</td>\n",
       "      <td>[40.892572172640854, 41.445544355520454]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12799</td>\n",
       "      <td>1983</td>\n",
       "      <td>3</td>\n",
       "      <td>42.726401</td>\n",
       "      <td>2.126401</td>\n",
       "      <td>6.379204</td>\n",
       "      <td>[1983.01.01, 1983.01.02, 1983.01.03]</td>\n",
       "      <td>[2.7539840539556195, 2.8988528219620875, 0.726...</td>\n",
       "      <td>[43.35398405395562, 43.49885282196209, 41.3263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12799</td>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>42.101542</td>\n",
       "      <td>1.501542</td>\n",
       "      <td>1.501542</td>\n",
       "      <td>[1983.01.07]</td>\n",
       "      <td>[1.5015423810544917]</td>\n",
       "      <td>[42.10154238105449]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12799</td>\n",
       "      <td>1983</td>\n",
       "      <td>2</td>\n",
       "      <td>41.282618</td>\n",
       "      <td>0.682618</td>\n",
       "      <td>1.365235</td>\n",
       "      <td>[1983.01.09, 1983.01.10]</td>\n",
       "      <td>[1.073923854489017, 0.2913114130661114]</td>\n",
       "      <td>[41.67392385448902, 40.89131141306611]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12820</td>\n",
       "      <td>1983</td>\n",
       "      <td>2</td>\n",
       "      <td>41.971993</td>\n",
       "      <td>1.371993</td>\n",
       "      <td>2.743987</td>\n",
       "      <td>[1983.01.01, 1983.01.02]</td>\n",
       "      <td>[1.2265718525154057, 1.5174147668343707]</td>\n",
       "      <td>[41.82657185251541, 42.11741476683437]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_HDC_G0  year  duration   avg_temp  avg_intensity  tot_intensity  \\\n",
       "0      10630  1983         2  41.169058       0.569058       1.138117   \n",
       "0      12799  1983         3  42.726401       2.126401       6.379204   \n",
       "1      12799  1983         1  42.101542       1.501542       1.501542   \n",
       "2      12799  1983         2  41.282618       0.682618       1.365235   \n",
       "0      12820  1983         2  41.971993       1.371993       2.743987   \n",
       "\n",
       "                            event_dates  \\\n",
       "0              [1983.01.06, 1983.01.07]   \n",
       "0  [1983.01.01, 1983.01.02, 1983.01.03]   \n",
       "1                          [1983.01.07]   \n",
       "2              [1983.01.09, 1983.01.10]   \n",
       "0              [1983.01.01, 1983.01.02]   \n",
       "\n",
       "                                           intensity  \\\n",
       "0          [0.29257217264085256, 0.8455443555204525]   \n",
       "0  [2.7539840539556195, 2.8988528219620875, 0.726...   \n",
       "1                               [1.5015423810544917]   \n",
       "2            [1.073923854489017, 0.2913114130661114]   \n",
       "0           [1.2265718525154057, 1.5174147668343707]   \n",
       "\n",
       "                                                tmax  \n",
       "0           [40.892572172640854, 41.445544355520454]  \n",
       "0  [43.35398405395562, 43.49885282196209, 41.3263...  \n",
       "1                                [42.10154238105449]  \n",
       "2             [41.67392385448902, 40.89131141306611]  \n",
       "0             [41.82657185251541, 42.11741476683437]  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Dec 31 - Jan 1 Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_in = pd.read_csv('/home/cascade/projects/UrbanHeat/data/All_stats_HI406_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5668643"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stats_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>total_days</th>\n",
       "      <th>duration</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_intensity</th>\n",
       "      <th>tot_intensity</th>\n",
       "      <th>event_dates</th>\n",
       "      <th>intensity</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3554</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43.438784</td>\n",
       "      <td>2.838784</td>\n",
       "      <td>2.838784</td>\n",
       "      <td>['1989.06.30']</td>\n",
       "      <td>[2.83878425]</td>\n",
       "      <td>[43.43878425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3554</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41.557437</td>\n",
       "      <td>0.957437</td>\n",
       "      <td>0.957437</td>\n",
       "      <td>['2003.07.29']</td>\n",
       "      <td>[0.95743653]</td>\n",
       "      <td>[41.55743653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3554</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43.966580</td>\n",
       "      <td>3.366580</td>\n",
       "      <td>3.366580</td>\n",
       "      <td>['2010.07.07']</td>\n",
       "      <td>[3.36658027]</td>\n",
       "      <td>[43.96658027]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2429</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>40.795059</td>\n",
       "      <td>0.195059</td>\n",
       "      <td>0.195059</td>\n",
       "      <td>['1984.07.31']</td>\n",
       "      <td>[0.19505924]</td>\n",
       "      <td>[40.79505924]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2429</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>42.365319</td>\n",
       "      <td>1.765319</td>\n",
       "      <td>1.765319</td>\n",
       "      <td>['1991.07.08']</td>\n",
       "      <td>[1.76531907]</td>\n",
       "      <td>[42.36531907]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID_HDC_G0  total_days  duration   avg_temp  avg_intensity  \\\n",
       "0           0       3554           3         1  43.438784       2.838784   \n",
       "1           1       3554           3         1  41.557437       0.957437   \n",
       "2           2       3554           3         1  43.966580       3.366580   \n",
       "3           0       2429           9         1  40.795059       0.195059   \n",
       "4           1       2429           9         1  42.365319       1.765319   \n",
       "\n",
       "   tot_intensity     event_dates     intensity           tmax  \n",
       "0       2.838784  ['1989.06.30']  [2.83878425]  [43.43878425]  \n",
       "1       0.957437  ['2003.07.29']  [0.95743653]  [41.55743653]  \n",
       "2       3.366580  ['2010.07.07']  [3.36658027]  [43.96658027]  \n",
       "3       0.195059  ['1984.07.31']  [0.19505924]  [40.79505924]  \n",
       "4       1.765319  ['1991.07.08']  [1.76531907]  [42.36531907]  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_search(df, date):\n",
    "    \n",
    "    \"\"\" Searches Tmax data frame to find dates within a Tmax event with the goal of finding 12.31-01.01 overlap\n",
    "    Args:\n",
    "        df = tmax df\n",
    "        data = date you want to find\n",
    "    \n",
    "    Returns df with event id, event dates, city id, year, and tmax temps \n",
    "    \"\"\"\n",
    "\n",
    "    event_id_list = []\n",
    "    event_dates_list = []\n",
    "    city_id_list = []\n",
    "    event_year_list = []\n",
    "    tmax_list = []\n",
    "    total_days_list = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if date in row['event_dates']:\n",
    "            \n",
    "            #event_id = row['Event_ID']\n",
    "            event_dates = row['event_dates']\n",
    "            city_id = row['ID_HDC_G0']\n",
    "            #event_year = row['year']\n",
    "            tmax = row['tmax']\n",
    "            total_days = row['total_days']\n",
    "            \n",
    "            #event_id_list.append(event_id)\n",
    "            event_dates_list.append(event_dates)\n",
    "            city_id_list.append(city_id)\n",
    "            #event_year_list.append(event_year)\n",
    "            tmax_list.append(tmax)\n",
    "            total_days_list.append(total_days)\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    df_out['ID_HDC_G0'] = city_id_list\n",
    "    #df_out['Event_ID'] = event_id_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "    df_out['event_dates'] = event_dates_list\n",
    "    #df_out['year'] = event_year_list\n",
    "    df_out['total_days'] = total_days_list\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '12.31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = date_search(stats_in, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>tmax</th>\n",
       "      <th>event_dates</th>\n",
       "      <th>total_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>[41.88869451]</td>\n",
       "      <td>['2010.12.31']</td>\n",
       "      <td>5290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "      <td>[41.73767473 41.40027191]</td>\n",
       "      <td>['1989.12.30' '1989.12.31']</td>\n",
       "      <td>6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>375</td>\n",
       "      <td>[43.101553]</td>\n",
       "      <td>['2002.12.31']</td>\n",
       "      <td>6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>375</td>\n",
       "      <td>[41.77394773]</td>\n",
       "      <td>['2005.12.31']</td>\n",
       "      <td>6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>375</td>\n",
       "      <td>[44.34242563]</td>\n",
       "      <td>['2007.12.31']</td>\n",
       "      <td>6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>375</td>\n",
       "      <td>[43.78522023 41.19842822]</td>\n",
       "      <td>['2010.12.31' '2011.01.01']</td>\n",
       "      <td>6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>375</td>\n",
       "      <td>[41.25341645 44.49574652 43.60375475 43.491900...</td>\n",
       "      <td>['2015.12.28' '2015.12.29' '2015.12.30' '2015....</td>\n",
       "      <td>6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>390</td>\n",
       "      <td>[41.59291018]</td>\n",
       "      <td>['2007.12.31']</td>\n",
       "      <td>4278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>391</td>\n",
       "      <td>[41.03117554]</td>\n",
       "      <td>['2007.12.31']</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7728</td>\n",
       "      <td>[41.53073374]</td>\n",
       "      <td>['2012.12.31']</td>\n",
       "      <td>4364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_HDC_G0                                               tmax  \\\n",
       "0        350                                      [41.88869451]   \n",
       "1        375                          [41.73767473 41.40027191]   \n",
       "2        375                                        [43.101553]   \n",
       "3        375                                      [41.77394773]   \n",
       "4        375                                      [44.34242563]   \n",
       "5        375                          [43.78522023 41.19842822]   \n",
       "6        375  [41.25341645 44.49574652 43.60375475 43.491900...   \n",
       "7        390                                      [41.59291018]   \n",
       "8        391                                      [41.03117554]   \n",
       "9       7728                                      [41.53073374]   \n",
       "\n",
       "                                         event_dates  total_days  \n",
       "0                                     ['2010.12.31']        5290  \n",
       "1                        ['1989.12.30' '1989.12.31']        6124  \n",
       "2                                     ['2002.12.31']        6124  \n",
       "3                                     ['2005.12.31']        6124  \n",
       "4                                     ['2007.12.31']        6124  \n",
       "5                        ['2010.12.31' '2011.01.01']        6124  \n",
       "6  ['2015.12.28' '2015.12.29' '2015.12.30' '2015....        6124  \n",
       "7                                     ['2007.12.31']        4278  \n",
       "8                                     ['2007.12.31']        3495  \n",
       "9                                     ['2012.12.31']        4364  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['2015.12.28' '2015.12.29' '2015.12.30' '2015.12.31' '2016.01.01']\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es['event_dates'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>total_days</th>\n",
       "      <th>duration</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_intensity</th>\n",
       "      <th>tot_intensity</th>\n",
       "      <th>event_dates</th>\n",
       "      <th>intensity</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2441868</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>3</td>\n",
       "      <td>42.703217</td>\n",
       "      <td>2.103217</td>\n",
       "      <td>6.309651</td>\n",
       "      <td>['1983.01.20' '1983.01.21' '1983.01.22']</td>\n",
       "      <td>[1.8220826  2.83717738 1.65039061]</td>\n",
       "      <td>[42.4220826  43.43717738 42.25039061]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2441869</td>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>1</td>\n",
       "      <td>41.869750</td>\n",
       "      <td>1.269750</td>\n",
       "      <td>1.269750</td>\n",
       "      <td>['1983.01.30']</td>\n",
       "      <td>[1.26975034]</td>\n",
       "      <td>[41.86975034]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2441870</td>\n",
       "      <td>2</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>2</td>\n",
       "      <td>41.852571</td>\n",
       "      <td>1.252571</td>\n",
       "      <td>2.505142</td>\n",
       "      <td>['1983.02.01' '1983.02.02']</td>\n",
       "      <td>[1.88940372 0.61573789]</td>\n",
       "      <td>[42.48940372 41.21573789]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2441871</td>\n",
       "      <td>3</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>1</td>\n",
       "      <td>45.847263</td>\n",
       "      <td>5.247263</td>\n",
       "      <td>5.247263</td>\n",
       "      <td>['1983.02.06']</td>\n",
       "      <td>[5.24726308]</td>\n",
       "      <td>[45.84726308]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2441872</td>\n",
       "      <td>4</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>4</td>\n",
       "      <td>45.447617</td>\n",
       "      <td>4.847617</td>\n",
       "      <td>19.390470</td>\n",
       "      <td>['1983.03.05' '1983.03.06' '1983.03.07' '1983....</td>\n",
       "      <td>[5.68699648 6.94049717 5.77288793 0.99008814]</td>\n",
       "      <td>[46.28699648 47.54049717 46.37288793 41.59008814]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2442959</td>\n",
       "      <td>1091</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>2</td>\n",
       "      <td>42.267758</td>\n",
       "      <td>1.667758</td>\n",
       "      <td>3.335516</td>\n",
       "      <td>['2016.11.30' '2016.12.01']</td>\n",
       "      <td>[1.16794035 2.16757582]</td>\n",
       "      <td>[41.76794035 42.76757582]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2442960</td>\n",
       "      <td>1092</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>6</td>\n",
       "      <td>44.752279</td>\n",
       "      <td>4.152279</td>\n",
       "      <td>24.913672</td>\n",
       "      <td>['2016.12.03' '2016.12.04' '2016.12.05' '2016....</td>\n",
       "      <td>[0.68738888 0.1823002  7.6203832  6.98349534 6...</td>\n",
       "      <td>[41.28738888 40.7823002  48.2203832  47.583495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2442961</td>\n",
       "      <td>1093</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>3</td>\n",
       "      <td>41.693444</td>\n",
       "      <td>1.093444</td>\n",
       "      <td>3.280332</td>\n",
       "      <td>['2016.12.12' '2016.12.13' '2016.12.14']</td>\n",
       "      <td>[0.31888825 1.60105008 1.36039368]</td>\n",
       "      <td>[40.91888825 42.20105008 41.96039368]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2442962</td>\n",
       "      <td>1094</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>2</td>\n",
       "      <td>42.878464</td>\n",
       "      <td>2.278464</td>\n",
       "      <td>4.556928</td>\n",
       "      <td>['2016.12.18' '2016.12.19']</td>\n",
       "      <td>[2.82346886 1.73345885]</td>\n",
       "      <td>[43.42346886 42.33345885]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2442963</td>\n",
       "      <td>1095</td>\n",
       "      <td>375</td>\n",
       "      <td>6124</td>\n",
       "      <td>1</td>\n",
       "      <td>40.787771</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>0.187771</td>\n",
       "      <td>['2016.12.26']</td>\n",
       "      <td>[0.18777112]</td>\n",
       "      <td>[40.78777112]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  ID_HDC_G0  total_days  duration   avg_temp  \\\n",
       "2441868           0        375        6124         3  42.703217   \n",
       "2441869           1        375        6124         1  41.869750   \n",
       "2441870           2        375        6124         2  41.852571   \n",
       "2441871           3        375        6124         1  45.847263   \n",
       "2441872           4        375        6124         4  45.447617   \n",
       "...             ...        ...         ...       ...        ...   \n",
       "2442959        1091        375        6124         2  42.267758   \n",
       "2442960        1092        375        6124         6  44.752279   \n",
       "2442961        1093        375        6124         3  41.693444   \n",
       "2442962        1094        375        6124         2  42.878464   \n",
       "2442963        1095        375        6124         1  40.787771   \n",
       "\n",
       "         avg_intensity  tot_intensity  \\\n",
       "2441868       2.103217       6.309651   \n",
       "2441869       1.269750       1.269750   \n",
       "2441870       1.252571       2.505142   \n",
       "2441871       5.247263       5.247263   \n",
       "2441872       4.847617      19.390470   \n",
       "...                ...            ...   \n",
       "2442959       1.667758       3.335516   \n",
       "2442960       4.152279      24.913672   \n",
       "2442961       1.093444       3.280332   \n",
       "2442962       2.278464       4.556928   \n",
       "2442963       0.187771       0.187771   \n",
       "\n",
       "                                               event_dates  \\\n",
       "2441868           ['1983.01.20' '1983.01.21' '1983.01.22']   \n",
       "2441869                                     ['1983.01.30']   \n",
       "2441870                        ['1983.02.01' '1983.02.02']   \n",
       "2441871                                     ['1983.02.06']   \n",
       "2441872  ['1983.03.05' '1983.03.06' '1983.03.07' '1983....   \n",
       "...                                                    ...   \n",
       "2442959                        ['2016.11.30' '2016.12.01']   \n",
       "2442960  ['2016.12.03' '2016.12.04' '2016.12.05' '2016....   \n",
       "2442961           ['2016.12.12' '2016.12.13' '2016.12.14']   \n",
       "2442962                        ['2016.12.18' '2016.12.19']   \n",
       "2442963                                     ['2016.12.26']   \n",
       "\n",
       "                                                 intensity  \\\n",
       "2441868                 [1.8220826  2.83717738 1.65039061]   \n",
       "2441869                                       [1.26975034]   \n",
       "2441870                            [1.88940372 0.61573789]   \n",
       "2441871                                       [5.24726308]   \n",
       "2441872      [5.68699648 6.94049717 5.77288793 0.99008814]   \n",
       "...                                                    ...   \n",
       "2442959                            [1.16794035 2.16757582]   \n",
       "2442960  [0.68738888 0.1823002  7.6203832  6.98349534 6...   \n",
       "2442961                 [0.31888825 1.60105008 1.36039368]   \n",
       "2442962                            [2.82346886 1.73345885]   \n",
       "2442963                                       [0.18777112]   \n",
       "\n",
       "                                                      tmax  \n",
       "2441868              [42.4220826  43.43717738 42.25039061]  \n",
       "2441869                                      [41.86975034]  \n",
       "2441870                          [42.48940372 41.21573789]  \n",
       "2441871                                      [45.84726308]  \n",
       "2441872  [46.28699648 47.54049717 46.37288793 41.59008814]  \n",
       "...                                                    ...  \n",
       "2442959                          [41.76794035 42.76757582]  \n",
       "2442960  [41.28738888 40.7823002  48.2203832  47.583495...  \n",
       "2442961              [40.91888825 42.20105008 41.96039368]  \n",
       "2442962                          [43.42346886 42.33345885]  \n",
       "2442963                                      [40.78777112]  \n",
       "\n",
       "[1096 rows x 10 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_in[stats_in['ID_HDC_G0'] == 375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1983"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(stats_in['event_dates'][2441868].split(' ')[0].split('[\\'')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_parallel(fn):\n",
    "    \n",
    "    \"\"\" EXPLAIN\n",
    "    \"\"\"\n",
    "\n",
    "    # print current process\n",
    "    print(mp.current_process())\n",
    "    \n",
    "    chunk = fn.split('chunk_')[1].split('.csv')[0] # Updated 2020.02.19 CPT\n",
    "    df_days = pd.read_csv(fn)\n",
    "\n",
    "    # Open the GHS-ID List with GeoPANDAS read_file\n",
    "    ghs_ids_fn = 'GHS-UCSB-IDS.csv'\n",
    "    ghs_ids_df = pd.read_csv(DATA_INTERIM+ghs_ids_fn)\n",
    "\n",
    "    print(df_days.head())\n",
    "#     # tmax events stats, out as df\n",
    "#     df_out = tmax_stats(df_days)\n",
    "\n",
    "#     # merge to get countries\n",
    "#     ghs_ids_df_out = ghs_ids_df.merge(df_out, on='ID_HDC_G0', how = 'inner')\n",
    "#     # write it all out\n",
    "#     ghs_ids_df_out.to_csv(DATA_IN+'chunk_stats+'+chunk+'.csv')\n",
    "\n",
    "#     print(year, 'SAVED!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_loop(function, file_list, cpu_num):\n",
    "    \"\"\"  EXPLAIN\n",
    "    \"\"\" \n",
    "    start = time.time()\n",
    "    pool = Pool(processes = cpu_num)\n",
    "    pool.map(function, file_list)\n",
    "    pool.close()\n",
    "\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
