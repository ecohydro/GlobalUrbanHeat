{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tmax Subset\n",
    "\n",
    "A notebook to subset Tmax daily for the 13000 GHS urban areas to identify dates >40c, consecuritve days >40 c etc.\n",
    "\n",
    "**Need to subset**\n",
    "- Days per year (done)\n",
    "- Duration of each event \n",
    "- Intensity of each day during each event (>40.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depdencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from random import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import geopandas as gpd \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_xr(file_in, time_dim, space_dim):\n",
    "    \n",
    "    \"\"\" Function reads in a csv w/ GHS-UCDB IDs and temp, isolates the temp\n",
    "    and returns a xarray data array with dims set to city ids and dates\n",
    "    \n",
    "    Args:\n",
    "        file_in = file name and path\n",
    "        time_dim = name for time dim as a str ... use date :-)\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_in) # read the file in as a df\n",
    "    print(df.shape)\n",
    "    \n",
    "    df_id = df[space_dim] # get IDs\n",
    "    df_temp = df.iloc[:,3:] # get only temp columns\n",
    "    df_temp.index = df_id # set index values\n",
    "    df_temp_drop = df_temp.dropna() # Drop cities w/ no temp record \n",
    "    print(len(df_temp_drop))\n",
    "    \n",
    "    temp_np = df_temp_drop.to_numpy() # turn temp cols into an np array\n",
    "    \n",
    "    # make xr Data Array w/ data as temp and dims as spece (e.g. id)\n",
    "    \n",
    "    # Note 2019 09 17 changed to xr.Dataset from xr.Dataarray\n",
    "    temp_xr_da = xr.DataArray(temp_np, coords=[df_temp_drop.index, df_temp_drop.columns], \n",
    "                            dims=[space_dim, time_dim])\n",
    "    \n",
    "    return temp_xr_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_eventTot(xarray, Tthresh, year):\n",
    "    \"\"\" Function returns the number of days within a year where Tmax > Tthresh for each city.\n",
    "    \n",
    "    Args: \n",
    "        xarray = an xarray object with dims = (space, times)\n",
    "        Tthresh = int of temp threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    ## NOTE FOR SOME REASON out.ID_HDC_G0 cannot be fed a string ... note sure why so be careful with col names\n",
    "    out = xarray.where(xarray > Tthresh, drop = True)\n",
    "    id_list = []\n",
    "    event_tot = []\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    for index, loc in enumerate(out.ID_HDC_G0):\n",
    "        id_list.append(out.ID_HDC_G0.values[index])\n",
    "        event_tot.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values))\n",
    "    \n",
    "    df_out['ID_HDC_G0'] = id_list\n",
    "    df_out[year] = event_tot\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eventTot_loop(dir_nm, time_dim, space_dim, Tthresh):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs to calc the total number of events greater than a threshold.\n",
    "        Leap years explain the difference in shapes 368 vs 369\n",
    "    \n",
    "    Args:\n",
    "        dir_nm = dir path to loop through\n",
    "        time_dim = name for time dim as a str ... use date :-) for csv_to_xr function\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0) for csv_to_xr function\n",
    "        Tthresh = int of temp threshold for temp_event function -- 40.6 is\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the GHS-ID List with GeoPANDAS read_file\n",
    "    ghs_ids_fn = 'GHS-UCSB-IDS.csv'\n",
    "    ghs_ids_df = pd.read_csv(DATA_INTERIM+ghs_ids_fn)\n",
    "    \n",
    "    # Git File list\n",
    "    fn_list = glob.glob(DAILY_PATH+'*.csv')\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "        \n",
    "        # Get year for arg for temp_event function\n",
    "        year = fn.split('GHS-Tmax-DAILY_')[1].split('.csv')[0]\n",
    "        print(year)\n",
    "        \n",
    "        temp_xr_da = csv_to_xr(fn, time_dim, space_dim)\n",
    "        \n",
    "        df_out = temp_eventTot(temp_xr_da, Tthresh, year)\n",
    "        \n",
    "        ghs_ids_df = ghs_ids_df.merge(df_out, on='ID_HDC_G0', how = 'outer') #<<<<----- NEED TO FIX THIS\n",
    "    \n",
    "    # build in later drop all NA GHS-IDs\n",
    "    \n",
    "    return ghs_ids_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_eventL_a(xarray, Tthresh, year): #<---------------- # NEED TO RENAME or\n",
    "    \"\"\" Function calculates the length of each Tmax threshold event as the number of days in a row\n",
    "    greater than a threshold within a year where Tmax > Tthresh for each city.\n",
    "    \n",
    "    Args: \n",
    "        xarray = an xarray object with dims = (space, times)\n",
    "        Tthresh = int of temp threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    ## NOTE FOR SOME REASON out.ID_HDC_G0 cannot be fed a string ... note sure why so be careful with col names\n",
    "    out = xarray.where(xarray > Tthresh, drop = True)\n",
    "    id_list = []\n",
    "    event_L = []\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    for index, loc in enumerate(out.ID_HDC_G0):\n",
    "        id_list.append(out.ID_HDC_G0.values[index])\n",
    "        event_tot.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values))\n",
    "    \n",
    "    df_out['ID_HDC_G0'] = id_list\n",
    "    df_out[year] = event_tot\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_eventL(xarray, Tthresh):\n",
    "    \"\"\" Function calculates the length of each Tmax threshold event as the number of days in a row\n",
    "    greater than a threshold within a year where Tmax > Tthresh for each city. Returns the length,\n",
    "    the dates, the tempatures, and the severity (daily Tmax - Tthresh)\n",
    "    \n",
    "    Args: \n",
    "        xarray = an xarray object with dims = (space, times)\n",
    "        Tthresh = int of temp threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty lists & df\n",
    "    id_list = []\n",
    "    date_list = []\n",
    "    dayTot_list = []\n",
    "    temp_list = []\n",
    "    severity_list = []\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # subset xarry\n",
    "    out = xarray.where(xarray > Tthresh, drop = True)\n",
    "\n",
    "    # start loop \n",
    "    for index, loc in enumerate(out.ID_HDC_G0):\n",
    "        id_list.append(out.ID_HDC_G0.values[index]) # get IDS\n",
    "        date_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values) # get event dates\n",
    "        \n",
    "        # this is actually getting the total events of all 2019-09-22\n",
    "        dayTot_list.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values)) # get event lengths\n",
    "        \n",
    "        temp_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values) # get temp values\n",
    "        severity_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values - Tthresh) # get severity\n",
    "\n",
    "    \n",
    "    # write to a data frame\n",
    "    df_out['ID_HDC_G0'] = id_list\n",
    "    df_out['Days_Total'] = eventL_list\n",
    "    df_out['Event_Dates'] = date_list\n",
    "    df_out['Event_Temps'] = temp_list\n",
    "    df_out['Event_Severity'] = severity_list\n",
    "\n",
    "    # return df_out\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eventL_loop(dir_nm, fn_out, time_dim, space_dim, Tthresh):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs to apply temp_eventL function and save out a .csv for each year\n",
    "    \n",
    "    Args:\n",
    "        dir_nm = dir path to loop through\n",
    "        fn_out = string to label out files\n",
    "        time_dim = name for time dim as a str ... use date :-) for csv_to_xr function\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0) for csv_to_xr function\n",
    "        Tthresh = int of temp threshold for temp_event function -- 40.6 is\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the GHS-ID List with GeoPANDAS read_file\n",
    "    ghs_ids_fn = 'GHS-UCSB-IDS.csv'\n",
    "    ghs_ids_df = pd.read_csv(DATA_INTERIM+ghs_ids_fn)\n",
    "        \n",
    "    # Git File list\n",
    "    fn_list = glob.glob(DAILY_PATH+'*.csv')\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "        \n",
    "        # Get year for arg for temp_event function\n",
    "        year = fn.split('GHS-Tmax-DAILY_')[1].split('.csv')[0]\n",
    "        print(year)\n",
    "        \n",
    "        temp_xr_da = csv_to_xr(fn, time_dim, space_dim)\n",
    "        \n",
    "        df_out = temp_eventL(temp_xr_da, Tthresh)\n",
    "                \n",
    "        ghs_ids_df_out = ghs_ids_df.merge(df_out, on='ID_HDC_G0', how = 'inner') #<<<<----- NEED TO FIX THIS\n",
    "\n",
    "        ghs_ids_df_out.to_csv(DATA_OUT+fn_out+year+'.csv')\n",
    "\n",
    "        print(year, 'SAVED!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/'\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13135, 368)\n",
      "13067\n"
     ]
    }
   ],
   "source": [
    "xr1993 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (ID_HDC_G0: 13067, date: 365)>\n",
       "array([[-43.921947, -33.71345 , -33.054974, ..., -12.416152, -13.232986,\n",
       "        -15.403823],\n",
       "       [ -4.804248,  -3.914425,  -7.533999, ...,  -5.186461, -10.945722,\n",
       "        -16.29516 ],\n",
       "       [-23.904118, -17.422953, -13.182008, ..., -12.788978, -11.337886,\n",
       "        -10.00939 ],\n",
       "       ...,\n",
       "       [ 16.028023,  17.73603 ,  20.493294, ...,  14.559421,  15.160739,\n",
       "         15.184024],\n",
       "       [ 16.420553,  17.87142 ,  22.519674, ...,  15.680964,  16.169733,\n",
       "         16.039179],\n",
       "       [ 16.6943  ,  17.559229,  21.480919, ...,  14.446052,  15.235602,\n",
       "         14.005591]])\n",
       "Coordinates:\n",
       "  * ID_HDC_G0  (ID_HDC_G0) int64 5782 3316 5645 3185 ... 1116 1114 1161 1169\n",
       "  * date       (date) object '1983.01.01' '1983.01.02' ... '1983.12.31'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eventL_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ef43ebfa75a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_eventL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr1993\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-cda4b8f14c1c>\u001b[0m in \u001b[0;36mtemp_eventL\u001b[0;34m(xarray, Tthresh)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# write to a data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID_HDC_G0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Days_Total'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meventL_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Event_Dates'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Event_Temps'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eventL_list' is not defined"
     ]
    }
   ],
   "source": [
    "test = temp_eventL(xr1993, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>Event_Length</th>\n",
       "      <th>Event_Dates</th>\n",
       "      <th>Event_Temps</th>\n",
       "      <th>Event_Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6279</td>\n",
       "      <td>14</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[40.637226, 42.146217, 43.225623999999996, 40....</td>\n",
       "      <td>[0.03722599999999687, 1.5462169999999986, 2.62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>6295</td>\n",
       "      <td>10</td>\n",
       "      <td>[1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...</td>\n",
       "      <td>[41.303112, 42.403027, 41.33662, 42.872417, 41...</td>\n",
       "      <td>[0.7031119999999973, 1.8030270000000002, 0.736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>6229</td>\n",
       "      <td>14</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[42.190994, 42.450027, 43.509415000000004, 40....</td>\n",
       "      <td>[1.590994000000002, 1.8500269999999972, 2.9094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>6249</td>\n",
       "      <td>15</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[41.742354999999996, 43.00139, 44.029526000000...</td>\n",
       "      <td>[1.142354999999995, 2.4013899999999992, 3.4295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>6236</td>\n",
       "      <td>16</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[41.7475, 42.906532, 43.937798, 41.069748, 42....</td>\n",
       "      <td>[1.1475000000000009, 2.306531999999997, 3.3377...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>1664</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.08.05]</td>\n",
       "      <td>[41.430878]</td>\n",
       "      <td>[0.8308779999999985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>6263</td>\n",
       "      <td>15</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[41.94552, 43.20455, 44.232690000000005, 41.33...</td>\n",
       "      <td>[1.3455200000000005, 2.604549999999996, 3.6326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>6309</td>\n",
       "      <td>5</td>\n",
       "      <td>[1983.06.24, 1983.06.27, 1983.06.28, 1983.06.2...</td>\n",
       "      <td>[41.467690000000005, 41.93708, 40.816628, 41.0...</td>\n",
       "      <td>[0.8676900000000032, 1.3370800000000003, 0.216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>12850</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.08.06]</td>\n",
       "      <td>[41.18087]</td>\n",
       "      <td>[0.5808699999999973]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>1661</td>\n",
       "      <td>2</td>\n",
       "      <td>[1983.06.15, 1983.08.05]</td>\n",
       "      <td>[40.63337, 40.745804]</td>\n",
       "      <td>[0.0333699999999979, 0.14580399999999827]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>12841</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.08.06]</td>\n",
       "      <td>[42.226093]</td>\n",
       "      <td>[1.6260929999999973]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>6312</td>\n",
       "      <td>8</td>\n",
       "      <td>[1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...</td>\n",
       "      <td>[40.835654999999996, 41.93557, 40.869164000000...</td>\n",
       "      <td>[0.23565499999999417, 1.335569999999997, 0.269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>6205</td>\n",
       "      <td>2</td>\n",
       "      <td>[1983.06.29, 1983.06.30]</td>\n",
       "      <td>[40.96825, 40.976826]</td>\n",
       "      <td>[0.3682499999999962, 0.3768260000000012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>6203</td>\n",
       "      <td>13</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[41.656876000000004, 41.91591, 42.975296, 42.1...</td>\n",
       "      <td>[1.0568760000000026, 1.3159099999999953, 2.375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>1613</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.06.15]</td>\n",
       "      <td>[41.2614]</td>\n",
       "      <td>[0.6614000000000004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>2761</td>\n",
       "      <td>9</td>\n",
       "      <td>[1983.06.27, 1983.07.07, 1983.07.23, 1983.07.2...</td>\n",
       "      <td>[42.827420000000004, 42.640809999999995, 41.29...</td>\n",
       "      <td>[2.227420000000002, 2.0408099999999934, 0.6940...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>2790</td>\n",
       "      <td>3</td>\n",
       "      <td>[1983.07.07, 1983.07.24, 1983.08.29]</td>\n",
       "      <td>[42.469685, 40.748492999999996, 41.240513]</td>\n",
       "      <td>[1.869684999999997, 0.14849299999999488, 0.640...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>5349</td>\n",
       "      <td>88</td>\n",
       "      <td>[1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...</td>\n",
       "      <td>[41.509215999999995, 44.25772, 42.885985999999...</td>\n",
       "      <td>[0.9092159999999936, 3.6577199999999976, 2.285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>6280</td>\n",
       "      <td>13</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[41.118237, 42.552242, 43.61627, 41.074978, 42...</td>\n",
       "      <td>[0.5182369999999992, 1.9522419999999983, 3.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>1668</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.08.05]</td>\n",
       "      <td>[40.858604]</td>\n",
       "      <td>[0.2586039999999983]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1623</td>\n",
       "      <td>3</td>\n",
       "      <td>[1983.06.15, 1983.06.16, 1983.09.06]</td>\n",
       "      <td>[42.449690000000004, 40.707535, 40.890144]</td>\n",
       "      <td>[1.8496900000000025, 0.1075349999999986, 0.290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>6302</td>\n",
       "      <td>9</td>\n",
       "      <td>[1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...</td>\n",
       "      <td>[41.131367, 42.23128, 41.164875, 42.700676, 41...</td>\n",
       "      <td>[0.5313669999999959, 1.6312799999999967, 0.564...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>2097</td>\n",
       "      <td>3</td>\n",
       "      <td>[1983.07.10, 1983.08.06, 1983.08.20]</td>\n",
       "      <td>[40.84176, 40.677690000000005, 40.69319]</td>\n",
       "      <td>[0.2417599999999993, 0.07769000000000403, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>6277</td>\n",
       "      <td>13</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[41.702248, 42.96128, 43.989418, 41.0907969999...</td>\n",
       "      <td>[1.102247999999996, 2.3612800000000007, 3.3894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>5358</td>\n",
       "      <td>91</td>\n",
       "      <td>[1983.05.21, 1983.06.01, 1983.06.02, 1983.06.0...</td>\n",
       "      <td>[40.734726, 41.691296, 44.4398, 43.06806599999...</td>\n",
       "      <td>[0.13472600000000057, 1.0912959999999998, 3.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>5927</td>\n",
       "      <td>2</td>\n",
       "      <td>[1983.07.28, 1983.07.29]</td>\n",
       "      <td>[40.822975, 41.583168]</td>\n",
       "      <td>[0.22297499999999815, 0.9831679999999992]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>6341</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.06.24]</td>\n",
       "      <td>[40.963584999999995]</td>\n",
       "      <td>[0.3635849999999934]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427</td>\n",
       "      <td>5305</td>\n",
       "      <td>81</td>\n",
       "      <td>[1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...</td>\n",
       "      <td>[41.29473, 43.808859999999996, 42.0465, 42.808...</td>\n",
       "      <td>[0.6947299999999998, 3.2088599999999943, 1.446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>5331</td>\n",
       "      <td>91</td>\n",
       "      <td>[1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...</td>\n",
       "      <td>[41.91895, 44.287247, 42.493637, 43.15344, 43....</td>\n",
       "      <td>[1.318950000000001, 3.6872469999999993, 1.8936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>[1983.05.27, 1983.07.04, 1983.07.10, 1983.07.1...</td>\n",
       "      <td>[40.62904, 41.171574, 41.279720000000005, 42.7...</td>\n",
       "      <td>[0.029040000000001953, 0.5715739999999983, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>5111</td>\n",
       "      <td>35</td>\n",
       "      <td>[1983.06.02, 1983.06.03, 1983.06.05, 1983.06.1...</td>\n",
       "      <td>[41.448966999999996, 41.207115, 41.631126, 41....</td>\n",
       "      <td>[0.8489669999999947, 0.6071150000000003, 1.031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>5320</td>\n",
       "      <td>89</td>\n",
       "      <td>[1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...</td>\n",
       "      <td>[42.363937, 44.440567, 42.584457, 43.040665000...</td>\n",
       "      <td>[1.7639369999999985, 3.840567, 1.9844569999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>5488</td>\n",
       "      <td>27</td>\n",
       "      <td>[1983.07.02, 1983.07.03, 1983.07.04, 1983.07.1...</td>\n",
       "      <td>[41.693073, 40.66814, 41.684345, 40.658558, 42...</td>\n",
       "      <td>[1.0930729999999969, 0.06813999999999965, 1.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>5337</td>\n",
       "      <td>92</td>\n",
       "      <td>[1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...</td>\n",
       "      <td>[42.792477000000005, 44.869106, 43.53383, 43.6...</td>\n",
       "      <td>[2.192477000000004, 4.269106000000001, 2.93383...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>5900</td>\n",
       "      <td>60</td>\n",
       "      <td>[1983.06.08, 1983.06.19, 1983.06.20, 1983.06.2...</td>\n",
       "      <td>[40.624615000000006, 41.47041, 43.84187, 43.37...</td>\n",
       "      <td>[0.024615000000004272, 0.8704099999999997, 3.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>5322</td>\n",
       "      <td>90</td>\n",
       "      <td>[1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...</td>\n",
       "      <td>[42.420578000000006, 44.497208, 42.641098, 43....</td>\n",
       "      <td>[1.8205780000000047, 3.897207999999999, 2.0410...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>6329</td>\n",
       "      <td>3</td>\n",
       "      <td>[1983.06.23, 1983.06.24, 1983.06.27]</td>\n",
       "      <td>[40.695625, 41.521846999999994, 41.83386199999...</td>\n",
       "      <td>[0.0956249999999983, 0.9218469999999925, 1.233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>6217</td>\n",
       "      <td>10</td>\n",
       "      <td>[1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...</td>\n",
       "      <td>[41.557495, 42.34857, 40.813416, 41.521088, 41...</td>\n",
       "      <td>[0.9574950000000015, 1.7485700000000008, 0.213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>5361</td>\n",
       "      <td>94</td>\n",
       "      <td>[1983.05.21, 1983.06.01, 1983.06.02, 1983.06.0...</td>\n",
       "      <td>[40.685944, 42.964386, 45.041016, 43.966156, 4...</td>\n",
       "      <td>[0.0859439999999978, 2.364385999999996, 4.4410...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>6310</td>\n",
       "      <td>8</td>\n",
       "      <td>[1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...</td>\n",
       "      <td>[41.01079, 41.970079999999996, 41.30199, 42.83...</td>\n",
       "      <td>[0.41078999999999866, 1.3700799999999944, 0.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>12873</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.07.19]</td>\n",
       "      <td>[40.680664]</td>\n",
       "      <td>[0.08066399999999874]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>5975</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.07.30]</td>\n",
       "      <td>[40.78395]</td>\n",
       "      <td>[0.18394999999999584]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>5345</td>\n",
       "      <td>96</td>\n",
       "      <td>[1983.05.21, 1983.06.01, 1983.06.02, 1983.06.0...</td>\n",
       "      <td>[40.762733000000004, 43.044563000000004, 45.12...</td>\n",
       "      <td>[0.1627330000000029, 2.4445630000000023, 4.521...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>6231</td>\n",
       "      <td>12</td>\n",
       "      <td>[1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...</td>\n",
       "      <td>[40.610287, 42.27557, 43.066646999999996, 41.5...</td>\n",
       "      <td>[0.010286999999998159, 1.6755700000000004, 2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>5569</td>\n",
       "      <td>25</td>\n",
       "      <td>[1983.07.03, 1983.07.04, 1983.07.05, 1983.07.1...</td>\n",
       "      <td>[40.871365000000004, 41.281063, 40.7879, 40.66...</td>\n",
       "      <td>[0.27136500000000296, 0.6810630000000018, 0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>12877</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.07.19]</td>\n",
       "      <td>[40.814323]</td>\n",
       "      <td>[0.21432300000000026]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>5692</td>\n",
       "      <td>1</td>\n",
       "      <td>[1983.08.12]</td>\n",
       "      <td>[40.793816]</td>\n",
       "      <td>[0.1938159999999982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>5313</td>\n",
       "      <td>90</td>\n",
       "      <td>[1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...</td>\n",
       "      <td>[42.379875, 44.456505, 42.600395, 43.056602000...</td>\n",
       "      <td>[1.779874999999997, 3.8565049999999985, 2.0003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>5326</td>\n",
       "      <td>94</td>\n",
       "      <td>[1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...</td>\n",
       "      <td>[42.701477000000004, 44.778107, 42.921997, 43....</td>\n",
       "      <td>[2.1014770000000027, 4.178106999999997, 2.3219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>6265</td>\n",
       "      <td>18</td>\n",
       "      <td>[1983.06.21, 1983.06.22, 1983.06.23, 1983.06.2...</td>\n",
       "      <td>[40.98955, 41.406147, 42.965717, 43.708942, 41...</td>\n",
       "      <td>[0.38954999999999984, 0.8061469999999957, 2.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID_HDC_G0  Event_Length  \\\n",
       "400       6279            14   \n",
       "401       6295            10   \n",
       "402       6229            14   \n",
       "403       6249            15   \n",
       "404       6236            16   \n",
       "405       1664             1   \n",
       "406       6263            15   \n",
       "407       6309             5   \n",
       "408      12850             1   \n",
       "409       1661             2   \n",
       "410      12841             1   \n",
       "411       6312             8   \n",
       "412       6205             2   \n",
       "413       6203            13   \n",
       "414       1613             1   \n",
       "415       2761             9   \n",
       "416       2790             3   \n",
       "417       5349            88   \n",
       "418       6280            13   \n",
       "419       1668             1   \n",
       "420       1623             3   \n",
       "421       6302             9   \n",
       "422       2097             3   \n",
       "423       6277            13   \n",
       "424       5358            91   \n",
       "425       5927             2   \n",
       "426       6341             1   \n",
       "427       5305            81   \n",
       "428       5331            91   \n",
       "429         56            12   \n",
       "430       5111            35   \n",
       "431       5320            89   \n",
       "432       5488            27   \n",
       "433       5337            92   \n",
       "434       5900            60   \n",
       "435       5322            90   \n",
       "436       6329             3   \n",
       "437       6217            10   \n",
       "438       5361            94   \n",
       "439       6310             8   \n",
       "440      12873             1   \n",
       "441       5975             1   \n",
       "442       5345            96   \n",
       "443       6231            12   \n",
       "444       5569            25   \n",
       "445      12877             1   \n",
       "446       5692             1   \n",
       "447       5313            90   \n",
       "448       5326            94   \n",
       "449       6265            18   \n",
       "\n",
       "                                           Event_Dates  \\\n",
       "400  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "401  [1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...   \n",
       "402  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "403  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "404  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "405                                       [1983.08.05]   \n",
       "406  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "407  [1983.06.24, 1983.06.27, 1983.06.28, 1983.06.2...   \n",
       "408                                       [1983.08.06]   \n",
       "409                           [1983.06.15, 1983.08.05]   \n",
       "410                                       [1983.08.06]   \n",
       "411  [1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...   \n",
       "412                           [1983.06.29, 1983.06.30]   \n",
       "413  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "414                                       [1983.06.15]   \n",
       "415  [1983.06.27, 1983.07.07, 1983.07.23, 1983.07.2...   \n",
       "416               [1983.07.07, 1983.07.24, 1983.08.29]   \n",
       "417  [1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...   \n",
       "418  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "419                                       [1983.08.05]   \n",
       "420               [1983.06.15, 1983.06.16, 1983.09.06]   \n",
       "421  [1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...   \n",
       "422               [1983.07.10, 1983.08.06, 1983.08.20]   \n",
       "423  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "424  [1983.05.21, 1983.06.01, 1983.06.02, 1983.06.0...   \n",
       "425                           [1983.07.28, 1983.07.29]   \n",
       "426                                       [1983.06.24]   \n",
       "427  [1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...   \n",
       "428  [1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...   \n",
       "429  [1983.05.27, 1983.07.04, 1983.07.10, 1983.07.1...   \n",
       "430  [1983.06.02, 1983.06.03, 1983.06.05, 1983.06.1...   \n",
       "431  [1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...   \n",
       "432  [1983.07.02, 1983.07.03, 1983.07.04, 1983.07.1...   \n",
       "433  [1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...   \n",
       "434  [1983.06.08, 1983.06.19, 1983.06.20, 1983.06.2...   \n",
       "435  [1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...   \n",
       "436               [1983.06.23, 1983.06.24, 1983.06.27]   \n",
       "437  [1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...   \n",
       "438  [1983.05.21, 1983.06.01, 1983.06.02, 1983.06.0...   \n",
       "439  [1983.06.23, 1983.06.24, 1983.06.26, 1983.06.2...   \n",
       "440                                       [1983.07.19]   \n",
       "441                                       [1983.07.30]   \n",
       "442  [1983.05.21, 1983.06.01, 1983.06.02, 1983.06.0...   \n",
       "443  [1983.06.22, 1983.06.23, 1983.06.24, 1983.06.2...   \n",
       "444  [1983.07.03, 1983.07.04, 1983.07.05, 1983.07.1...   \n",
       "445                                       [1983.07.19]   \n",
       "446                                       [1983.08.12]   \n",
       "447  [1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...   \n",
       "448  [1983.06.01, 1983.06.02, 1983.06.03, 1983.06.0...   \n",
       "449  [1983.06.21, 1983.06.22, 1983.06.23, 1983.06.2...   \n",
       "\n",
       "                                           Event_Temps  \\\n",
       "400  [40.637226, 42.146217, 43.225623999999996, 40....   \n",
       "401  [41.303112, 42.403027, 41.33662, 42.872417, 41...   \n",
       "402  [42.190994, 42.450027, 43.509415000000004, 40....   \n",
       "403  [41.742354999999996, 43.00139, 44.029526000000...   \n",
       "404  [41.7475, 42.906532, 43.937798, 41.069748, 42....   \n",
       "405                                        [41.430878]   \n",
       "406  [41.94552, 43.20455, 44.232690000000005, 41.33...   \n",
       "407  [41.467690000000005, 41.93708, 40.816628, 41.0...   \n",
       "408                                         [41.18087]   \n",
       "409                              [40.63337, 40.745804]   \n",
       "410                                        [42.226093]   \n",
       "411  [40.835654999999996, 41.93557, 40.869164000000...   \n",
       "412                              [40.96825, 40.976826]   \n",
       "413  [41.656876000000004, 41.91591, 42.975296, 42.1...   \n",
       "414                                          [41.2614]   \n",
       "415  [42.827420000000004, 42.640809999999995, 41.29...   \n",
       "416         [42.469685, 40.748492999999996, 41.240513]   \n",
       "417  [41.509215999999995, 44.25772, 42.885985999999...   \n",
       "418  [41.118237, 42.552242, 43.61627, 41.074978, 42...   \n",
       "419                                        [40.858604]   \n",
       "420         [42.449690000000004, 40.707535, 40.890144]   \n",
       "421  [41.131367, 42.23128, 41.164875, 42.700676, 41...   \n",
       "422           [40.84176, 40.677690000000005, 40.69319]   \n",
       "423  [41.702248, 42.96128, 43.989418, 41.0907969999...   \n",
       "424  [40.734726, 41.691296, 44.4398, 43.06806599999...   \n",
       "425                             [40.822975, 41.583168]   \n",
       "426                               [40.963584999999995]   \n",
       "427  [41.29473, 43.808859999999996, 42.0465, 42.808...   \n",
       "428  [41.91895, 44.287247, 42.493637, 43.15344, 43....   \n",
       "429  [40.62904, 41.171574, 41.279720000000005, 42.7...   \n",
       "430  [41.448966999999996, 41.207115, 41.631126, 41....   \n",
       "431  [42.363937, 44.440567, 42.584457, 43.040665000...   \n",
       "432  [41.693073, 40.66814, 41.684345, 40.658558, 42...   \n",
       "433  [42.792477000000005, 44.869106, 43.53383, 43.6...   \n",
       "434  [40.624615000000006, 41.47041, 43.84187, 43.37...   \n",
       "435  [42.420578000000006, 44.497208, 42.641098, 43....   \n",
       "436  [40.695625, 41.521846999999994, 41.83386199999...   \n",
       "437  [41.557495, 42.34857, 40.813416, 41.521088, 41...   \n",
       "438  [40.685944, 42.964386, 45.041016, 43.966156, 4...   \n",
       "439  [41.01079, 41.970079999999996, 41.30199, 42.83...   \n",
       "440                                        [40.680664]   \n",
       "441                                         [40.78395]   \n",
       "442  [40.762733000000004, 43.044563000000004, 45.12...   \n",
       "443  [40.610287, 42.27557, 43.066646999999996, 41.5...   \n",
       "444  [40.871365000000004, 41.281063, 40.7879, 40.66...   \n",
       "445                                        [40.814323]   \n",
       "446                                        [40.793816]   \n",
       "447  [42.379875, 44.456505, 42.600395, 43.056602000...   \n",
       "448  [42.701477000000004, 44.778107, 42.921997, 43....   \n",
       "449  [40.98955, 41.406147, 42.965717, 43.708942, 41...   \n",
       "\n",
       "                                        Event_Severity  \n",
       "400  [0.03722599999999687, 1.5462169999999986, 2.62...  \n",
       "401  [0.7031119999999973, 1.8030270000000002, 0.736...  \n",
       "402  [1.590994000000002, 1.8500269999999972, 2.9094...  \n",
       "403  [1.142354999999995, 2.4013899999999992, 3.4295...  \n",
       "404  [1.1475000000000009, 2.306531999999997, 3.3377...  \n",
       "405                               [0.8308779999999985]  \n",
       "406  [1.3455200000000005, 2.604549999999996, 3.6326...  \n",
       "407  [0.8676900000000032, 1.3370800000000003, 0.216...  \n",
       "408                               [0.5808699999999973]  \n",
       "409          [0.0333699999999979, 0.14580399999999827]  \n",
       "410                               [1.6260929999999973]  \n",
       "411  [0.23565499999999417, 1.335569999999997, 0.269...  \n",
       "412           [0.3682499999999962, 0.3768260000000012]  \n",
       "413  [1.0568760000000026, 1.3159099999999953, 2.375...  \n",
       "414                               [0.6614000000000004]  \n",
       "415  [2.227420000000002, 2.0408099999999934, 0.6940...  \n",
       "416  [1.869684999999997, 0.14849299999999488, 0.640...  \n",
       "417  [0.9092159999999936, 3.6577199999999976, 2.285...  \n",
       "418  [0.5182369999999992, 1.9522419999999983, 3.016...  \n",
       "419                               [0.2586039999999983]  \n",
       "420  [1.8496900000000025, 0.1075349999999986, 0.290...  \n",
       "421  [0.5313669999999959, 1.6312799999999967, 0.564...  \n",
       "422  [0.2417599999999993, 0.07769000000000403, 0.09...  \n",
       "423  [1.102247999999996, 2.3612800000000007, 3.3894...  \n",
       "424  [0.13472600000000057, 1.0912959999999998, 3.83...  \n",
       "425          [0.22297499999999815, 0.9831679999999992]  \n",
       "426                               [0.3635849999999934]  \n",
       "427  [0.6947299999999998, 3.2088599999999943, 1.446...  \n",
       "428  [1.318950000000001, 3.6872469999999993, 1.8936...  \n",
       "429  [0.029040000000001953, 0.5715739999999983, 0.6...  \n",
       "430  [0.8489669999999947, 0.6071150000000003, 1.031...  \n",
       "431  [1.7639369999999985, 3.840567, 1.9844569999999...  \n",
       "432  [1.0930729999999969, 0.06813999999999965, 1.08...  \n",
       "433  [2.192477000000004, 4.269106000000001, 2.93383...  \n",
       "434  [0.024615000000004272, 0.8704099999999997, 3.2...  \n",
       "435  [1.8205780000000047, 3.897207999999999, 2.0410...  \n",
       "436  [0.0956249999999983, 0.9218469999999925, 1.233...  \n",
       "437  [0.9574950000000015, 1.7485700000000008, 0.213...  \n",
       "438  [0.0859439999999978, 2.364385999999996, 4.4410...  \n",
       "439  [0.41078999999999866, 1.3700799999999944, 0.70...  \n",
       "440                              [0.08066399999999874]  \n",
       "441                              [0.18394999999999584]  \n",
       "442  [0.1627330000000029, 2.4445630000000023, 4.521...  \n",
       "443  [0.010286999999998159, 1.6755700000000004, 2.4...  \n",
       "444  [0.27136500000000296, 0.6810630000000018, 0.18...  \n",
       "445                              [0.21432300000000026]  \n",
       "446                               [0.1938159999999982]  \n",
       "447  [1.779874999999997, 3.8565049999999985, 2.0003...  \n",
       "448  [2.1014770000000027, 4.178106999999997, 2.3219...  \n",
       "449  [0.38954999999999984, 0.8061469999999957, 2.36...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[400:450]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find breaks in time serise\n",
    "\n",
    "https://stackoverflow.com/questions/40118037/how-can-i-detect-gaps-and-consecutive-periods-in-a-time-series-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this https://stackoverflow.com/questions/52901387/find-group-of-consecutive-dates-in-pandas-dataframe\n",
    "\n",
    "dt = test[test['ID_HDC_G0'] == 6279]['Event_Dates']\n",
    "day = pd.Timedelta('1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1983.06.22', '1983.06.23', '1983.06.24', '1983.06.25',\n",
       "        '1983.06.26', '1983.06.27', '1983.06.28', '1983.06.29',\n",
       "        '1983.06.30', '1983.07.01', '1983.07.21', '1983.07.22',\n",
       "        '1983.07.23', '1983.08.01'], dtype=object)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = test[test['ID_HDC_G0'] == 6279]\n",
    "city_list = city.Event_Dates.tolist()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['dates'] = city_list\n",
    "df.dates.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['1983.06.20', '1983.06.23', '1983.06.24', '1983.06.25',\n",
    "        '1983.06.26', '1983.06.27', '1983.06.28', '1983.06.29',\n",
    "        '1983.06.30', '1983.07.01', '1983.07.21', '1983.07.22',\n",
    "        '1983.07.23', '1983.08.01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dates = pd.to_datetime(dates)\n",
    "shift = pd_dates.shift(1, freq = 'D')\n",
    "day = pd.Timedelta('1d')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['dates'] = pd_dates\n",
    "# df['shift'] = shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dates\n",
       "0   False\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "5    True\n",
       "6    True\n",
       "7    True\n",
       "8    True\n",
       "9   False\n",
       "10   True\n",
       "11   True\n",
       "12  False\n",
       "13  False"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_block = ((df - df.shift(-1)).abs() == day)\n",
    "in_block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot index with multidimensional key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-0170e092cbdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_block\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1837\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot index with multidimensional key"
     ]
    }
   ],
   "source": [
    "filt = df.loc[in_block]\n",
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3 days</td>\n",
       "      <td>3 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>20 days</td>\n",
       "      <td>20 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>9 days</td>\n",
       "      <td>9 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dates   shift\n",
       "0      NaT     NaT\n",
       "1   3 days  3 days\n",
       "2   1 days  1 days\n",
       "3   1 days  1 days\n",
       "4   1 days  1 days\n",
       "5   1 days  1 days\n",
       "6   1 days  1 days\n",
       "7   1 days  1 days\n",
       "8   1 days  1 days\n",
       "9   1 days  1 days\n",
       "10 20 days 20 days\n",
       "11  1 days  1 days\n",
       "12  1 days  1 days\n",
       "13  9 days  9 days"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_list = dt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400    NaN\n",
       "Name: Event_Dates, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_list = ['1983.06.22', '1983.06.23', '1983.06.24', '1983.06.25',\n",
    "       '1983.06.26', '1983.06.27', '1983.06.28', '1983.06.29',\n",
    "       '1983.06.30', '1983.07.01', '1983.07.21', '1983.07.22',\n",
    "       '1983.07.23', '1983.08.01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400    False\n",
       "Name: Event_Dates, dtype: bool"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_block = ((dt - dt.shift(-1)).abs() == day) | (dt.diff() == day)\n",
    "in_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASCADE I THINK THIS IS WHERE TO START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x7fa19a591208>\n",
      "<map object at 0x7fa19a591208>\n",
      "<map object at 0x7fa19a591198>\n",
      "<map object at 0x7fa19a591198>\n",
      "<map object at 0x7fa19a591208>\n",
      "<map object at 0x7fa19a591208>\n"
     ]
    }
   ],
   "source": [
    "### Another idea\n",
    "# https://stackoverflow.com/questions/2361945/detecting-consecutive-integers-in-a-list\n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "data = [1, 4,5,6, 10, 15,16,17,18, 22, 25,26,27,28]\n",
    "\n",
    "for k, g in groupby(enumerate(data), lambda x: x[1]-x[0]):\n",
    "    print(map(itemgetter(1), g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[4, 5, 6]\n",
      "[10]\n",
      "[15, 16, 17, 18]\n",
      "[22]\n",
      "[25, 26, 27, 28]\n"
     ]
    }
   ],
   "source": [
    "L = [1,  4,5,6, 10, 15,16,17,18, 22, 25,26,27,28]\n",
    "for k, g in groupby(enumerate(L), lambda x: x[1]-x[0] ) :\n",
    "  print (list(map(itemgetter(1), g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = ['1983.06.20', '1983.06.23', '1983.06.24', '1983.06.25',\n",
    "        '1983.06.26', '1983.06.27', '1983.06.28', '1983.06.29',\n",
    "        '1983.06.30', '1983.07.01', '1983.07.21', '1983.07.22',\n",
    "        '1983.07.23', '1983.08.01']\n",
    "\n",
    "pd_dates = pd.to_datetime(dates)\n",
    "df_dates = pd.DataFrame()\n",
    "df_dates['dates'] = pd_dates\n",
    "\n",
    "\n",
    "\n",
    "test = df_dates['dates'].apply(lambda x: x.toordinal())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[724081]\n",
      "[724084, 724085, 724086, 724087, 724088, 724089, 724090, 724091, 724092]\n",
      "[724112, 724113, 724114]\n",
      "[724123]\n"
     ]
    }
   ],
   "source": [
    "for k, g in groupby(enumerate(test), lambda x: x[1]-x[0]):\n",
    "  print (list(map(itemgetter(1), g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths \n",
    "\n",
    "# UPDATE AS NEEDED <<<<< ------------------------------------------\n",
    "DAILY_PATH = '/home/cascade/projects/data_out/CHIRTS-GHS-DAILY/'\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out/CHIRTS-GHS-Events/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name\n",
    "fn_out = 'CHIRTS-GHS-Events'\n",
    "dir_nm = DAILY_PATH\n",
    "time_dim = 'date'\n",
    "space_dim = 'ID_HDC_G0'\n",
    "Tthresh = 40.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventL_loop(dir_nm, fn_out, time_dim, space_dim, Tthresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "y = range(1,125)\n",
    "year = '2010'\n",
    "country = 'INDIA'\n",
    "plt.hist(india[year], bins = 125)\n",
    "plt.xlabel('Number of Days in '+year+' where Tmax >40c in ')\n",
    "plt.ylabel('Number of cities')\n",
    "plt.title(country+': For all cities with Tmax >40, how many days in '+year+' were >40C? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP BACK TO POLYGONS AND LOOK AT IT \n",
    "SHP_DIR = '/Users/cascade/Github/UrbanHeat/data/raw/ghs-ucdb/'\n",
    "shp_fn = 'GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp'\n",
    "shps = gpd.read_file(SHP_DIR+shp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ghs = gpd.GeoDataFrame()\n",
    "df_ghs['geometry'] = shps.geometry\n",
    "df_ghs['ID_HDC_G0'] = shps.ID_HDC_G0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_ghs.merge(events, on='ID_HDC_G0', how = 'inner') #<<<<----- NEED TO FIX THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write it out\n",
    "DATA_INTERIM = '/Users/cascade/Github/UrbanHeat/data/interim/'\n",
    "fn_out = 'GHS-TmaxDaily-events.shp'\n",
    "df_merge.to_file(DATA_INTERIM+fn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return the ID and Date where Tmax is greater than 40 as a dict, but will not return actual tempatures \n",
    "\n",
    "Tmax = np.random.randint(20, high=50, size=(3,10)) # Make a 3x10 random list\n",
    "print(Tmax)\n",
    "results = np.where(Tmax > 40) # find the index and rows\n",
    "coords = list(zip(results[0], results[1])) # zip the i and js into tuples\n",
    "\n",
    "b = [(k, list(list(zip(*g))[1])) for k, g in groupby(coords, itemgetter(0))] # group by rows\n",
    "\n",
    "print(b)\n",
    "dict_out = dict(b) # turn into a dict, where keys are city ids and values are dates\n",
    "dict_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict_out.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(Tmax > 40, Tmax, Tmax*0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(Tmax > 40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(Tmax>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_search(array):\n",
    "    results = np.where(array > 40) # find the index and rows\n",
    "    coords = list(zip(results[0], results[1])) # zip the i and js into tuples\n",
    "    b = [(k, list(list(zip(*g))[1])) for k, g in groupby(coords, itemgetter(0))] # group by rows\n",
    "    dict_out = dict(b) # turn into a dict, where keys are city ids and values are dates\n",
    "\n",
    "    return dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in = '/Users/cascade/Desktop/GHS-Tmax-DAILY_1983.csv'\n",
    "\n",
    "df = pd.read_csv(file_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_drop = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head()\n",
    "arr = df_sub.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_search = temp_search(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some fake data\n",
    "Tmax = np.random.randint(20, high=50, size=(3,10))\n",
    "locs = ['001', '002', '003']\n",
    "times = pd.date_range('2000-01-01', periods=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = xr.DataArray(Tmax, coords=[locs, times], dims=['space', 'times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = foo.where(foo > 40, drop = True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for loc in out.space:\n",
    "    print(len(out.sel(space = loc).dropna(dim = 'times').times.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in out.space.values:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.space.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr1993 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')\n",
    "out = xr1993.where(xr1993 > 40.6, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40 - out.sel(ID_HDC_G0 = 5885).dropna(dim = 'date').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event_tot.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values))\n",
    "\n",
    "id_list = []\n",
    "date_list = []\n",
    "eventL_list = []\n",
    "temp_list = []\n",
    "df_out = pd.DataFrame()\n",
    "\n",
    "# start loop \n",
    "for index, loc in enumerate(out.ID_HDC_G0):\n",
    "\n",
    "    id_list.append(out.ID_HDC_G0.values[index]) # get IDS\n",
    "    date_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values) # get event dates\n",
    "    eventL_list.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values)) # get event lengths\n",
    "    temp_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values) #get temp values\n",
    "\n",
    "# write to a data frame\n",
    "df_out['ID_HDC_G0'] = id_list\n",
    "df_out['Event_Length'] = eventL_list\n",
    "df_out['Event_Dates'] = date_list\n",
    "df_out['Event_Temps'] = temp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run routine\n",
    "# all_events_df = event_loop(DAILY_PATH, 'date', 'ID_HDC_G0', 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move IDS to Index \n",
    "\n",
    "all_events_df = all_events_df.set_index(['ID_HDC_G0', 'CTR_MN_NM'], drop = True)\n",
    "all_events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs\n",
    "all_events_df_drop = all_events_df.dropna(how = 'all')\n",
    "all_events_df_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = all_events_df_drop.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['ID_HDC_G0'] = all_events_df_drop.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_df_drop = all_events_df_drop.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_events_df_drop.to_csv(DATA_OUT+'20190831_TMax-GHS_TotEvents83-2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india = all_events_df_drop[all_events_df_drop['CTR_MN_NM'] == 'India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
