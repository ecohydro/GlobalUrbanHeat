{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN = '/home/CHIRTS/Tmax/v1.0/daily_ERA5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list= sorted(glob(DATA_IN+'*/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = dir_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_nm = dir_list[0]\n",
    "dir_year = dir_nm.split(DATA_IN)[1].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'Tmax.'\n",
    "for fn in sorted(os.listdir(dir_nm)):\n",
    "    \n",
    "    if fn.startswith(DATA):        \n",
    "        dir_year = dir_nm.split(DATA_IN)[1].split('/')[0]\n",
    "        # Get the date of each chirt file\n",
    "        date = (fn.split(DATA)[1].split('.tif')[0]) \n",
    "        print(dir_year)\n",
    "        print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_Tmax = '/home/cascade/projects/UrbanHeat/data/interim/ERA5_Tmax/'\n",
    "DIR_RH = '/home/cascade/projects/UrbanHeat/data/interim/ERA5_RH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax = pd.read_csv(DIR_Tmax+'GHS-ERA5-Tmax_1983.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax.iloc[:,3:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH = pd.read_csv(DIR_RH+'GHS-ERA5-RH_1983.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH.iloc[:,3:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'GHS-ERA5-Tmax_1983.csv'\n",
    "data = 'GHS-ERA5-Tmax_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.split(data)[1].split('.csv')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_Tmax = '/home/cascade/projects/UrbanHeat/data/interim/ERA5_Tmax/'\n",
    "DIR_RH = '/home/cascade/projects/UrbanHeat/data/interim/ERA5_RH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "Tmax_fn_list = glob.glob(DIR_Tmax+'*.csv')\n",
    "RH_fn_list = glob.glob(DIR_RH+'*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tmax_fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'GHS-ERA5-HI_1983.csv'\n",
    "FN_IN = 'GHS-ERA5-HI_'\n",
    "year = fn.split(FN_IN)[1].split('.csv')[0] # for some reason it's 2...?\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# File Paths + FN\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/' # interim data\n",
    "DATA_PROCESSED = '/home/cascade/projects/UrbanHeat/data/processed/'\n",
    "DATA_IN = DATA_INTERIM+'ERA5_HI/' # output from avg temp <<<<< UPDATE\n",
    "\n",
    "#FN_OUT = DATA_PROCESSED+'AllDATA-GHS-ERA5-HI406.csv' #<<< UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# File Paths + FN\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/' # interim data\n",
    "DATA_PROCESSED = '/home/cascade/projects/UrbanHeat/data/processed/'\n",
    "DATA_IN = DATA_INTERIM+'ERA5_HI/' # output from avg temp <<<<< UPDATE\n",
    "\n",
    "FN_OUT = DATA_PROCESSED+'AllDATA-GHS-ERA5-HI406.csv' #<<< UPDATE\n",
    "FN_IN = 'GHS-ERA5-HI_'\n",
    "\n",
    "def event_stack_loop(dir_in):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs of tmax events for each year and\n",
    "    stack them into one data frame. Current file name is CHIRTS-GHS-Events-StatsXXXX.csv\n",
    "    \n",
    "    Args:\n",
    "        dir_in = dir path to loop through\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get File list\n",
    "    fn_list = glob.glob(dir_in+'*.csv')\n",
    "    \n",
    "    fn_list = fn_list[:2]\n",
    "    \n",
    "    # Data frame to fill\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "            \n",
    "        year = fn.split(FN_IN)[1].split('.csv')[0] # for some reason it's 2...?\n",
    "        print(year)\n",
    "        \n",
    "        # open csv \n",
    "        stats = pd.read_csv(fn)\n",
    "        \n",
    "        stats['year'] = year\n",
    "#        print('stats is ', stats.shape)\n",
    "        \n",
    "        print(len(df_out))\n",
    "        \n",
    "        df_out = df_out.append(stats, sort = False)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "# Run script\n",
    "event_stack = event_stack_loop(DATA_IN)\n",
    "print(len(event_stack))\n",
    "\n",
    "# Add 'Event_ID'\n",
    "event_stack = event_stack.rename(columns = {'Unnamed: 0' : 'Event_ID'})\n",
    "\n",
    "event_ids = range(1, len(event_stack)+1)\n",
    "len(event_ids)\n",
    "\n",
    "event_stack['Event_ID'] = event_ids\n",
    "\n",
    "#event_stack.to_csv(FN_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4826833a649e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Run script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mevent_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_stack_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_IN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4826833a649e>\u001b[0m in \u001b[0;36mevent_stack_loop\u001b[0;34m(dir_in)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFN_IN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# for some reason it's 2...?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# GHS-ERA5-Stats_\n",
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# File Paths + FN\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/' # interim data\n",
    "DATA_PROCESSED = '/home/cascade/projects/UrbanHeat/data/processed/'\n",
    "DATA_IN = DATA_INTERIM+'ERA5_STATS/' # <<<<< UPDATE\n",
    "\n",
    "FN_OUT = DATA_PROCESSED+'AllDATA-GHS-ERA5-HI406.csv' #<<< UPDATE\n",
    "FN_IN = 'GHS-ERA5-STATS_' #<<< UPDATE\n",
    "\n",
    "def event_stack_loop(dir_in):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs of tmax events for each year and\n",
    "    stack them into one data frame. Current file name is CHIRTS-GHS-Events-StatsXXXX.csv\n",
    "    \n",
    "    Args:\n",
    "        dir_in = dir path to loop through\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get File list\n",
    "    fn_list = glob.glob(dir_in+'*.csv')\n",
    "    fn_list = fn_list[:3]\n",
    "    \n",
    "    # Data frame to fill\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "            \n",
    "        year = fn.split(FN_IN)[1].split('.csv')[0] # for some reason it's 2...?\n",
    "        print(year)\n",
    "        \n",
    "        # open csv \n",
    "        stats = pd.read_csv(fn)\n",
    "        \n",
    "        # drop index col\n",
    "        stats = stats.iloc[:,1:]\n",
    "        \n",
    "        stats['year'] = year\n",
    "        \n",
    "        print(len(df_out))\n",
    "        \n",
    "        df_out = df_out.append(stats)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "# Run script\n",
    "event_stack = event_stack_loop(DATA_IN)\n",
    "print(len(event_stack))\n",
    "\n",
    "# Add 'Event_ID'\n",
    "event_ids = range(1, len(event_stack)+1)\n",
    "len(event_ids)\n",
    "\n",
    "event_stack['Event_ID'] = event_ids\n",
    "\n",
    "print('Writing final df to disk')\n",
    "#event_stack.to_csv(FN_OUT)\n",
    "print('ALL DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = glob.glob(DATA_IN+'*.csv')\n",
    "fn_list = fn_list[:3]\n",
    "\n",
    "df1 = pd.read_csv(fn_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/cascade/projects/UrbanHeat/data/interim/ERA5_STATS/GHS-ERA5-Stats_2010.csv',\n",
       " '/home/cascade/projects/UrbanHeat/data/interim/ERA5_STATS/GHS-ERA5-Stats_1989.csv',\n",
       " '/home/cascade/projects/UrbanHeat/data/interim/ERA5_STATS/GHS-ERA5-Stats_1987.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN_IN = 'GHS-ERA5-Stats_'\n",
    "year = fn_list[0].split(FN_IN)[1].split('.csv')[0]\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  ID_HDC_G0 CTR_MN_NM  total_days  duration   avg_temp  \\\n",
      "0           0       5645    Russia           1         1  42.596714   \n",
      "1           1       5872    Russia           6         6  43.411134   \n",
      "2           2       6155    Russia           1         1  42.275731   \n",
      "3           3       4993    Russia           1         1  41.127857   \n",
      "4           4       3091    Poland           1         1  42.874764   \n",
      "\n",
      "   avg_intensity  tot_intensity  \\\n",
      "0       1.996714       1.996714   \n",
      "1       2.811134      16.866806   \n",
      "2       1.675731       1.675731   \n",
      "3       0.527857       0.527857   \n",
      "4       2.274764       2.274764   \n",
      "\n",
      "                                         event_dates  \\\n",
      "0                                     ['1983.06.28']   \n",
      "1  ['1983.06.23' '1983.06.24' '1983.06.25' '1983....   \n",
      "2                                     ['1983.06.26']   \n",
      "3                                     ['1983.08.15']   \n",
      "4                                     ['1983.05.16']   \n",
      "\n",
      "                                           intensity  \\\n",
      "0                                       [1.99671447]   \n",
      "1  [5.31903748 2.9527051  0.88265857 2.27567969 4...   \n",
      "2                                       [1.67573143]   \n",
      "3                                       [0.52785663]   \n",
      "4                                       [2.27476433]   \n",
      "\n",
      "                                                tmax  year  Event_ID  \n",
      "0                                      [42.59671447]  1983         1  \n",
      "1  [45.91903748 43.5527051  41.48265857 42.875679...  1983         2  \n",
      "2                                      [42.27573143]  1983         3  \n",
      "3                                      [41.12785663]  1983         4  \n",
      "4                                      [42.87476433]  1983         5  \n",
      "5757330\n",
      "5745226\n",
      "   Unnamed: 0  ID_HDC_G0 CTR_MN_NM  total_days  duration   avg_temp  \\\n",
      "0           0       5645    Russia           1         1  42.596714   \n",
      "1           1       5872    Russia           6         6  43.411134   \n",
      "2           2       6155    Russia           1         1  42.275731   \n",
      "3           3       4993    Russia           1         1  41.127857   \n",
      "4          61       5094    Russia           1         1  41.751296   \n",
      "\n",
      "   avg_intensity  tot_intensity  \\\n",
      "0       1.996714       1.996714   \n",
      "1       2.811134      16.866806   \n",
      "2       1.675731       1.675731   \n",
      "3       0.527857       0.527857   \n",
      "4       1.151296       1.151296   \n",
      "\n",
      "                                         event_dates  \\\n",
      "0                                     ['1983.06.28']   \n",
      "1  ['1983.06.23' '1983.06.24' '1983.06.25' '1983....   \n",
      "2                                     ['1983.06.26']   \n",
      "3                                     ['1983.08.15']   \n",
      "4                                     ['1983.07.14']   \n",
      "\n",
      "                                           intensity  \\\n",
      "0                                       [1.99671447]   \n",
      "1  [5.31903748 2.9527051  0.88265857 2.27567969 4...   \n",
      "2                                       [1.67573143]   \n",
      "3                                       [0.52785663]   \n",
      "4                                       [1.15129609]   \n",
      "\n",
      "                                                tmax  year  Event_ID  region  \\\n",
      "0                                      [42.59671447]  1983         1  Europe   \n",
      "1  [45.91903748 43.5527051  41.48265857 42.875679...  1983         2  Europe   \n",
      "2                                      [42.27573143]  1983         3  Europe   \n",
      "3                                      [41.12785663]  1983         4  Europe   \n",
      "4                                      [41.75129609]  1983        62  Europe   \n",
      "\n",
      "       sub-region intermediate-region  \n",
      "0  Eastern Europe      Eastern Europe  \n",
      "1  Eastern Europe      Eastern Europe  \n",
      "2  Eastern Europe      Eastern Europe  \n",
      "3  Eastern Europe      Eastern Europe  \n",
      "4  Eastern Europe      Eastern Europe  \n",
      "   Unnamed: 0  ID_HDC_G0 CTR_MN_NM  total_days  duration   avg_temp  \\\n",
      "0           0       5645    Russia           1         1  42.596714   \n",
      "1           0       5645    Russia           2         1  40.762713   \n",
      "2           1       5645    Russia           2         1  42.299558   \n",
      "3           0       5645    Russia           3         3  44.492237   \n",
      "4           0       5645    Russia           1         1  40.829614   \n",
      "\n",
      "   avg_intensity  tot_intensity                               event_dates  \\\n",
      "0       1.996714       1.996714                            ['1983.06.28']   \n",
      "1       0.162713       0.162713                            ['1989.07.03']   \n",
      "2       1.699558       1.699558                            ['1989.07.21']   \n",
      "3       3.892237      11.676712  ['1990.07.15' '1990.07.16' '1990.07.17']   \n",
      "4       0.229614       0.229614                            ['1994.07.01']   \n",
      "\n",
      "                            intensity                                   tmax  \\\n",
      "0                        [1.99671447]                          [42.59671447]   \n",
      "1                        [0.16271323]                          [40.76271323]   \n",
      "2                        [1.69955783]                          [42.29955783]   \n",
      "3  [7.13736697 4.07729667 0.46204822]  [47.73736697 44.67729667 41.06204822]   \n",
      "4                        [0.22961432]                          [40.82961432]   \n",
      "\n",
      "   year  Event_ID  region      sub-region intermediate-region  GCPNT_LAT  \\\n",
      "0  1983         1  Europe  Eastern Europe      Eastern Europe  66.083799   \n",
      "1  1989    993096  Europe  Eastern Europe      Eastern Europe  66.083799   \n",
      "2  1989    993097  Europe  Eastern Europe      Eastern Europe  66.083799   \n",
      "3  1990   1155480  Europe  Eastern Europe      Eastern Europe  66.083799   \n",
      "4  1994   1820456  Europe  Eastern Europe      Eastern Europe  66.083799   \n",
      "\n",
      "   GCPNT_LON  \n",
      "0   76.64658  \n",
      "1   76.64658  \n",
      "2   76.64658  \n",
      "3   76.64658  \n",
      "4   76.64658  \n"
     ]
    }
   ],
   "source": [
    "#### Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "#### Load Files\n",
    "\n",
    "DATA_PROCESSED = '/home/cascade/projects/UrbanHeat/data/processed/'\n",
    "FN_IN = DATA_PROCESSED+\"AllDATA-GHS-ERA5-HI406.csv\" # SET\n",
    "FN_OUT = DATA_PROCESSED+\"AllDATA-GHS-ERA5-HI406-META.csv\" # SET\n",
    "\n",
    "events = pd.read_csv(FN_IN)\n",
    "ghs = gpd.read_file('/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/raw/GHS_UCDB/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp')\n",
    "countries = pd.read_csv('/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/raw/countrylist.csv')\n",
    "\n",
    "print(events.head())\n",
    "\n",
    "# Fix Ivory Coast\n",
    "#events.CTR_MN_NM = events.CTR_MN_NM.replace('CÃ´te d\\'Ivoire', 'Ivory Coast') #CPT 2020.02.23\n",
    "\n",
    "#### Merge Events and Countries <<<--- 2020.03.30 commented out by CPT, not needed\n",
    "# ghs_countries = pd.DataFrame()\n",
    "# ghs_countries['CTR_MN_NM'] = ghs['CTR_MN_NM']\n",
    "# ghs_countries['ID_HDC_G0'] = ghs['ID_HDC_G0']\n",
    "# events = events.merge(ghs_countries, on = 'ID_HDC_G0', how = 'inner')\n",
    "events.CTR_MN_NM = events.CTR_MN_NM.replace('CÃ´te d\\'Ivoire', 'Ivory Coast') \n",
    "\n",
    "# make a region dataframe of the cols we want\n",
    "regions = pd.DataFrame()\n",
    "regions['CTR_MN_NM'] = countries['name']\n",
    "regions['region'] = countries['region']\n",
    "regions['sub-region'] = countries['sub-region']\n",
    "regions['intermediate-region'] = countries['intermediate-region']\n",
    "\n",
    "# Merge \n",
    "print(len(events))\n",
    "events = events.merge(regions, on = 'CTR_MN_NM', how = 'inner')\n",
    "print(len(events))\n",
    "\n",
    "print(events.head())\n",
    "\n",
    "#### Add lat/lon of GHS-UCDB to events\n",
    "# get GHS-UCDB lat/long\n",
    "df = pd.DataFrame()\n",
    "df['ID_HDC_G0'] = ghs['ID_HDC_G0']\n",
    "df['GCPNT_LAT'] = ghs['GCPNT_LAT']\n",
    "df['GCPNT_LON'] = ghs['GCPNT_LON']\n",
    "\n",
    "# merge\n",
    "events = events.merge(df, on = 'ID_HDC_G0', how = 'inner')\n",
    "\n",
    "print(events.head())\n",
    "\n",
    "# save out file \n",
    "events.to_csv(FN_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>CTR_MN_NM</th>\n",
       "      <th>total_days</th>\n",
       "      <th>duration</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_intensity</th>\n",
       "      <th>tot_intensity</th>\n",
       "      <th>event_dates</th>\n",
       "      <th>intensity</th>\n",
       "      <th>tmax</th>\n",
       "      <th>year</th>\n",
       "      <th>Event_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5645</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.596714</td>\n",
       "      <td>1.996714</td>\n",
       "      <td>1.996714</td>\n",
       "      <td>['1983.06.28']</td>\n",
       "      <td>[1.99671447]</td>\n",
       "      <td>[42.59671447]</td>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5872</td>\n",
       "      <td>Russia</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43.411134</td>\n",
       "      <td>2.811134</td>\n",
       "      <td>16.866806</td>\n",
       "      <td>['1983.06.23' '1983.06.24' '1983.06.25' '1983....</td>\n",
       "      <td>[5.31903748 2.9527051  0.88265857 2.27567969 4...</td>\n",
       "      <td>[45.91903748 43.5527051  41.48265857 42.875679...</td>\n",
       "      <td>1983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6155</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.275731</td>\n",
       "      <td>1.675731</td>\n",
       "      <td>1.675731</td>\n",
       "      <td>['1983.06.26']</td>\n",
       "      <td>[1.67573143]</td>\n",
       "      <td>[42.27573143]</td>\n",
       "      <td>1983</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4993</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.127857</td>\n",
       "      <td>0.527857</td>\n",
       "      <td>0.527857</td>\n",
       "      <td>['1983.08.15']</td>\n",
       "      <td>[0.52785663]</td>\n",
       "      <td>[41.12785663]</td>\n",
       "      <td>1983</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3091</td>\n",
       "      <td>Poland</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.874764</td>\n",
       "      <td>2.274764</td>\n",
       "      <td>2.274764</td>\n",
       "      <td>['1983.05.16']</td>\n",
       "      <td>[2.27476433]</td>\n",
       "      <td>[42.87476433]</td>\n",
       "      <td>1983</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID_HDC_G0 CTR_MN_NM  total_days  duration   avg_temp  \\\n",
       "0           0       5645    Russia           1         1  42.596714   \n",
       "1           1       5872    Russia           6         6  43.411134   \n",
       "2           2       6155    Russia           1         1  42.275731   \n",
       "3           3       4993    Russia           1         1  41.127857   \n",
       "4           4       3091    Poland           1         1  42.874764   \n",
       "\n",
       "   avg_intensity  tot_intensity  \\\n",
       "0       1.996714       1.996714   \n",
       "1       2.811134      16.866806   \n",
       "2       1.675731       1.675731   \n",
       "3       0.527857       0.527857   \n",
       "4       2.274764       2.274764   \n",
       "\n",
       "                                         event_dates  \\\n",
       "0                                     ['1983.06.28']   \n",
       "1  ['1983.06.23' '1983.06.24' '1983.06.25' '1983....   \n",
       "2                                     ['1983.06.26']   \n",
       "3                                     ['1983.08.15']   \n",
       "4                                     ['1983.05.16']   \n",
       "\n",
       "                                           intensity  \\\n",
       "0                                       [1.99671447]   \n",
       "1  [5.31903748 2.9527051  0.88265857 2.27567969 4...   \n",
       "2                                       [1.67573143]   \n",
       "3                                       [0.52785663]   \n",
       "4                                       [2.27476433]   \n",
       "\n",
       "                                                tmax  year  Event_ID  \n",
       "0                                      [42.59671447]  1983         1  \n",
       "1  [45.91903748 43.5527051  41.48265857 42.875679...  1983         2  \n",
       "2                                      [42.27573143]  1983         3  \n",
       "3                                      [41.12785663]  1983         4  \n",
       "4                                      [42.87476433]  1983         5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
