{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS Calculations\n",
    "\n",
    "Notebook to crunch numbers for the MS.\n",
    "\n",
    "by Cascade Tuholske 2020.02.23 \n",
    "\n",
    "Updated 2020.08.27 - CPT\n",
    "Was run on ERA5 RH with CHIRTS-Daily Tmax from ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Depdencies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Regressions, no intercept addition is needed because we're using SK LEARN HERE \n",
    "\n",
    "def lm_func(df, col):\n",
    "    \n",
    "    \"simple linear model of a time series data, returns coef\"\n",
    "    \n",
    "    # Get Data\n",
    "    X_year = np.array(df.groupby('year')['ID_HDC_G0'].mean().index).reshape((-1, 1))\n",
    "    Y_stats = np.array(df.groupby('year')[col].sum()).reshape((-1, 1))\n",
    "\n",
    "    # Add Intercept\n",
    "    X_year_2 = sm.add_constant(X_year)\n",
    "\n",
    "    # Regress\n",
    "    model = sm.OLS(Y_stats, X_year_2).fit() \n",
    "        \n",
    "    coef = int(model.params[1])\n",
    "    #coef = int(coef)\n",
    "            \n",
    "    # R2 and P\n",
    "    r2 = model.rsquared_adj\n",
    "    p = model.pvalues[0]\n",
    "    \n",
    "    return coef, round(r2, 2), round(p, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Data\n",
    "DATA = 'WBGT32_1D' # UPDATE \n",
    "\n",
    "# file paths\n",
    "DATA_IN = \"/home/cascade/projects/UrbanHeat/data/\"  \n",
    "FIG_OUT = \"/home/cascade/projects/UrbanHeat/figures/\"\n",
    "FN_IN = 'processed/PNAS-DATA-v2/'+DATA+'_EXP.json'\n",
    "HI_STATS = pd.read_json(DATA_IN+FN_IN, orient = 'split')\n",
    "\n",
    "# Set scale\n",
    "scale = 10**9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322082\n",
      "321538\n"
     ]
    }
   ],
   "source": [
    "# Drop cites where 1983 had 1 day and none elsewhere\n",
    "\n",
    "print(len(HI_STATS))\n",
    "only83 = HI_STATS.groupby('ID_HDC_G0')['tot_days'].sum() == 1 # sum up total days and find those with 1 day\n",
    "only83 = list(only83[only83 == True].index) # make a list of IDs\n",
    "sub = HI_STATS[HI_STATS['ID_HDC_G0'].isin(only83)] # subset those IDs\n",
    "bad_ids = sub[(sub['year'] == 1983) & (sub['tot_days'] == 1)] # drop those from 1983 only\n",
    "drop_list = list(bad_ids['ID_HDC_G0']) # make a list\n",
    "HI_STATS= HI_STATS[~HI_STATS['ID_HDC_G0'].isin(drop_list)] # drop those from the list\n",
    "print(len(HI_STATS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Add In Meta Data (e.g. geographic data)\n",
    "meta_fn = DATA_IN+'interim/GHS-UCDB-IDS.csv'\n",
    "meta_data = pd.read_csv(meta_fn)\n",
    "\n",
    "#### Merge in meta\n",
    "HI_STATS = HI_STATS.merge(meta_data, on = 'ID_HDC_G0', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person days in 2016 was 125.6137485348937 billion\n",
      "person days in 1983 was 44.458472045749346 billion\n",
      "pct increase in people days 83 - 16 is  182.54175808298746\n"
     ]
    }
   ],
   "source": [
    "#### Total Change in people Days\n",
    "data = HI_STATS.groupby('year')['people_days'].sum()\n",
    "year = str(data.index[33])\n",
    "value = str(data.values[33]/10**9)\n",
    "print('person days in 2016 was '+value+' billion')\n",
    "\n",
    "year = str(data.index[0])\n",
    "value = str(data.values[0]/10**9)\n",
    "print('person days in 1983 was '+value+' billion')\n",
    "\n",
    "#### Pct Change in Poeple Days 1983 - 2016\n",
    "pdays16 = data.iloc[len(data) -1]\n",
    "pdays83 = data.iloc[0]\n",
    "out = (data.iloc[len(data) -1] - data.iloc[0]) / data.iloc[0] * 100\n",
    "print('pct increase in people days 83 - 16 is ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual increase in people days  was 2.217352888  p= 0.0\n",
      "annual increase in people days heat  was 0.727434647  p= 0.0\n",
      "annual increase in people days pop  was 1.48991824  p= 0.0\n",
      "attrib heat  was 32.80644460955103  p= 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Rate of change\n",
    "data = HI_STATS\n",
    "coef, r2, p = lm_func(data, 'people_days')\n",
    "print('annual increase in people days ', 'was', coef/10**9, ' p=', p)\n",
    "coef1, r21, p1 = lm_func(data, 'people_days_heat')\n",
    "print('annual increase in people days heat ', 'was', coef1/10**9, ' p=', p)\n",
    "coef2, r22, p2 = lm_func(data, 'people_days_pop')\n",
    "print('annual increase in people days pop ', 'was', coef2/10**9, ' p=', p)\n",
    "print('attrib heat ', 'was', coef1 / coef *100, ' p=', p, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warming is what pct of total? 32.807099734551066\n"
     ]
    }
   ],
   "source": [
    "#### Pct Pday Annual Increase from Heat\n",
    "coef_pdays, r2_pdays, p_pdays = lm_func(HI_STATS, 'people_days') # regress pdays\n",
    "coef_heat, r2_heat, p_heat = lm_func(HI_STATS, 'people_days_heat') # regreas heat\n",
    "\n",
    "print('warming is what pct of total?', coef_heat/coef_pdays *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Largest cities compared to global total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Top cities\n",
    "cities = pd.read_csv(DATA_PATH+'processed/PNAS-DATA-v2/WBGT32_1D_EXP-TOP50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = cities.sort_values('coef_pdays', ascending = False).head(25) # get the top ten cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 cities of total annual increase 24.507376418058552\n"
     ]
    }
   ],
   "source": [
    "# What pct of the global annual increase comes from the top ten cities?\n",
    "ans = top['coef_pdays'].sum() / coef\n",
    "print('Top 25 cities of total annual increase', ans * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coefs = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_EXP05.json', orient = 'split')\n",
    "GHS = gpd.read_file('/home/cascade/projects/UrbanHeat/data/raw/GHS_UCDB/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6022"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pct of cities w/ increases in exposure:  45.84697373429768\n"
     ]
    }
   ],
   "source": [
    "#### Number of cities w/ sig increase in exposure?\n",
    "print('The pct of cities w/ increases in exposure: ', len(city_coefs)/len(GHS)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6022"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what pct of pday cities are low lat? 50.94652939222849\n"
     ]
    }
   ],
   "source": [
    "ans = len(city_coefs[(city_coefs['GCPNT_LAT'] < 23.5) & (city_coefs['GCPNT_LAT'] > -23.5)]) / len(city_coefs)\n",
    "print('what pct of pday cities are low lat?', ans*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what pct of global pop are cities with sig pdays?\n"
     ]
    }
   ],
   "source": [
    "print('what pct of global pop are cities with sig pdays?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_search(country, data_set):\n",
    "    \"what pct of cities had a p-day increase?\"\n",
    "    print('Num of Cities in '+country+' ', len(data_set[data_set['CTR_MN_NM'] == country]) / len(GHS[GHS['CTR_MN_NM'] == country]) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = city_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Cities in Senegal  93.93939393939394\n"
     ]
    }
   ],
   "source": [
    "country_search('Senegal', data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Cities in Nigeria  91.92546583850931\n"
     ]
    }
   ],
   "source": [
    "country_search('Nigeria', data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Cities in India  86.48399014778325\n"
     ]
    }
   ],
   "source": [
    "country_search('India', data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pct of global population exposured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coefs = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_EXP05.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(DATA_IN+'interim/GHS-UCDB-Interp.csv')\n",
    "p16 = pop[['ID_HDC_G0', 'P2016']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13135"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdays_pop = pd.merge(city_coefs[['ID_HDC_G0']], p16, on = 'ID_HDC_G0', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the global urban population in 2016 3535326298.5424414\n",
      "How many people live in cities with increasing exp in 2016 1661009084.2793088\n",
      "What pct of total urban pop has sig increase exp in 2015 46.983190348345396\n"
     ]
    }
   ],
   "source": [
    "ans = pdays_pop['P2016'].sum() / p16['P2016'].sum() * 100 \n",
    "print('What is the global urban population in 2016', p16['P2016'].sum())\n",
    "print('How many people live in cities with increasing exp in 2016', pdays_pop['P2016'].sum())\n",
    "print('What pct of total urban pop has sig increase exp in 2015', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What pct of total world pop has sig increase exp in 2016 22.49772530792403\n"
     ]
    }
   ],
   "source": [
    "# From UN-DESA 2018 estimates for total global pop in 2015\n",
    "ans =  pdays_pop['P2016'].sum() / 7383009000 * 100\n",
    "print('What pct of total world pop has sig increase exp in 2016', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UN-DESA Urban pop in 2015 was  3 981 498\n",
    "p16['P2016'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Heat Days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_totdays = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_HEATP05.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What pct of all cities had sig increase in days/yr > WBGT32 C ?\n",
      "0.38797106966121053\n",
      "5096\n"
     ]
    }
   ],
   "source": [
    "print('What pct of all cities had sig increase in days/yr > WBGT32 C ?')\n",
    "print(len(city_totdays)/len(GHS))\n",
    "print(len(city_totdays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What pct of all cities >1 day / yr in days/yr > WBGT32 C ?\n",
      "0.1884278644842025\n",
      "2475\n"
     ]
    }
   ],
   "source": [
    "print('What pct of all cities >1 day / yr in days/yr > WBGT32 C ?')\n",
    "print(len(city_totdays[city_totdays['coef_totDays'] >= 1])/len(GHS))\n",
    "print(len(city_totdays[city_totdays['coef_totDays'] >= 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many cities day increase per year ... 1, 3\n",
    "top = len(city_totdays)\n",
    "bottom = len(city_totdays[city_totdays['coef_totDays'] >= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print(top)\n",
    "print(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are some big cities?\n",
    "hot50 = city_totdays[(city_totdays['coef_totDays'] >= 1.5) * city_totdays['P2016'] >= 5*10**5][['coef_totDays', 'UC_NM_MN']].sort_values('coef_totDays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hot50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conakry tot days: []\n",
      "columbo tot days: [0.1697479]\n",
      "San Sal tot days: []\n"
     ]
    }
   ],
   "source": [
    "#### Columbo & San Salvador & Conakry\n",
    "print('Conakry tot days:', city_totdays[city_totdays['ID_HDC_G0'] == 1502]['coef_totDays'].values)\n",
    "print('columbo tot days:', city_totdays[city_totdays['ID_HDC_G0'] == 8835]['coef_totDays'].values)\n",
    "print('San Sal tot days:', city_totdays[city_totdays['ID_HDC_G0'] == 321]['coef_totDays'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dehli & Kolkata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi 6955 & Kolkata 9691\n",
    "K = city_coefs[city_coefs['ID_HDC_G0']== 9691]\n",
    "D = city_coefs[city_coefs['ID_HDC_G0']== 6955]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of heat Kolkata 5599    50.402206\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Share of heat Kolkata', K.coef_heat / K.coef_pdays * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of heat Delhi 3201    23.607115\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Share of heat Delhi', D.coef_heat / D.coef_pdays * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populations of specific cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(DATA_IN+'interim/GHS-UCDB-Interp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9691, Kolkata 1998\n",
    "# 2046, Paris 2003\n",
    "# 4417, Aleppo 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pop[pop['ID_HDC_G0'] == 9691]['P2015'] / 10**3\n",
    "print('Pop of Kolkata in 1998', ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Annual Rates\n",
    "\n",
    "scale = 10**6\n",
    "geog = 'sub-region'\n",
    "\n",
    "for label in np.unique(HI_STATS[geog]):\n",
    "    label = label\n",
    "    data = HI_STATS[HI_STATS[geog] == label]\n",
    "    \n",
    "    #### Rate of change\n",
    "    coef, r2, p = lm_func(data, 'people_days')\n",
    "    print('annual increase in people days '+label, 'was', coef/scale, ' p=', p)\n",
    "    coef1, r21, p1 = lm_func(data, 'people_days_heat')\n",
    "    print('annual increase in people days heat '+label, 'was', coef1/scale, ' p=', p)\n",
    "    coef2, r22, p2 = lm_func(data, 'people_days_pop')\n",
    "    print('annual increase in people days pop '+label, 'was', coef2/scale, ' p=', p)\n",
    "    print('attrib heat '+label, 'was', coef1 / coef *100, ' p=', p, '\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Trends for Africa, N & SS\n",
    "geog = 'region'\n",
    "location = 'Africa'\n",
    "data = HI_STATS[HI_STATS[geog] == location]\n",
    "print(location)\n",
    "\n",
    "#### Total Change in people Days\n",
    "data = data.groupby('year')['people_days'].sum()\n",
    "year = str(data.index[33])\n",
    "value = str(data.values[33]/10**9)\n",
    "print('person days in 2016 was '+value+' billion')\n",
    "\n",
    "year = str(data.index[0])\n",
    "value = str(data.values[0]/10**9)\n",
    "print('person days in 1983 was '+value+' billion')\n",
    "\n",
    "#### Pct Change in Poeple Days 1983 - 2016\n",
    "pdays16 = data.iloc[len(data) -1]\n",
    "pdays83 = data.iloc[0]\n",
    "out = (data.iloc[len(data) -1] - data.iloc[0]) / data.iloc[0] * 100\n",
    "print('pct increase in people days 83 - 16 is ', out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### S Asia as pct of total  global = 5.245146271 B \n",
    "\n",
    "print('pct of total pdays from S Asia is ', 1899.70765 / 10**3 / 5.245146271 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Median Slope\n",
    "region = 'Europe'\n",
    "col = 'coef_heat'\n",
    "geog = 'region'\n",
    "scale = 10**3\n",
    "result = city_coefs[city_coefs[geog]== region][col].median()\n",
    "print(region, col, 'is ', result/scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend First vs. Second Half of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Share of exposure due to heat by 17 year split\n",
    "\n",
    "## 1983 - 1999\n",
    "data1 = HI_STATS[(HI_STATS['year'] >= 1983) & (HI_STATS['year'] < 2000)]\n",
    "coef1pop , r21pop, p1pop  = lm_func(data1 , 'people_days_pop')\n",
    "coef1heat , r21heat, p1heat = lm_func(data1 , 'people_days_heat')\n",
    "\n",
    "years = list(np.unique(data1['year']))\n",
    "plt.plot(years, data1.groupby('year')['people_days_heat'].sum())\n",
    "sns.regplot(years, data1.groupby('year')['people_days_heat'].sum(), \n",
    "            color = 'blue', scatter = False, truncate = True)\n",
    "\n",
    "## 2000 - 2016\n",
    "data2 = HI_STATS[(HI_STATS['year'] >= 2000) & (HI_STATS['year'] <= 2016)]\n",
    "coef2heat , r22heat, p2heat = lm_func(data2 , 'people_days_heat')\n",
    "coef2pop , r22pop, p1pop  = lm_func(data2 , 'people_days_pop')\n",
    "\n",
    "years = list(np.unique(data1['year']))\n",
    "plt.plot(years, data2.groupby('year')['people_days_heat'].sum())\n",
    "sns.regplot(years, data2.groupby('year')['people_days_heat'].sum(), \n",
    "            color = 'orange', scatter = False, truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2000 - 2016\n",
    "data2pop = HI_STATS[(HI_STATS['year'] >= 1983) & (HI_STATS['year'] < 2000)]\n",
    "coef2pop , r22pop, p1pop  = lm_func(data2pop , 'people_days_pop')\n",
    "\n",
    "data2heat = HI_STATS[(HI_STATS['year'] >= 2000) & (HI_STATS['year'] <= 2016)]\n",
    "coef2heat , r22heat, p2heat = lm_func(data2heat , 'people_days_heat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Estimates\n",
    "print('From 83 - 99, contribution from heat was', coef1heat/(coef1pop+coef1heat))\n",
    "print('From 00 - 16, contribution from heat was', coef2heat/(coef2pop+coef2heat))\n",
    "print('From 83 - 00, heat was', coef1heat/10**9, round(p1heat, 3))\n",
    "print('From 00 - 16, heat was', coef2heat/10**9)\n",
    "print('From 83 - 00, pop was', coef1pop/10**9)\n",
    "print('From 00 - 16, pop was', coef2pop/10**9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Waves\n",
    "\n",
    "- 9691 Kolkata 1998\n",
    "- 2046 Paris 2003\n",
    "- 4417, Aleppo 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Heat Wave From All DATA\n",
    "def select_city_year(df, city_id, year):\n",
    "    \"Quick search to find city and years within HI_STATS\"\n",
    "    df_out = df[(df['ID_HDC_G0'] == city_id) & (df['year'] == year)]\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "meta_fn = '/home/cascade/projects/UrbanHeat/data/processed/AllDATA-GHS-ERA5-HI406-META.csv'\n",
    "ALL_DATA = pd.read_csv(meta_fn)\n",
    "\n",
    "# [4417, 'Aleppo'] [2046, 'Paris'] [9691, 'Kolkata'] \n",
    "city = select_city_year(ALL_DATA, 4417, 2010)\n",
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a def\n",
    "df = pd.DataFrame()\n",
    "df = df.append(means, ignore_index=True)\n",
    "df = df.append(hi_year, ignore_index=True)\n",
    "df.columns = cols\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Isloate daily HI vs averages \n",
    "# Kolkata df.iloc[:,54:72]\n",
    "# Paris df.iloc[:,125:125+9] \n",
    "# Aleppo df.iloc[:,92 :145]\n",
    "wave = df.iloc[:,92 :145]\n",
    "wave = wave.transpose()\n",
    "wave.columns = ['mean', 'HI']\n",
    "wave['hi_dif'] = wave['HI'] - wave['mean'] \n",
    "# wave['>50'] = wave['HI'] - 50\n",
    "print(wave['hi_dif'].mean())\n",
    "wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_city_year(df, city_id, year):\n",
    "    \"Quick search to find city and years within HI_STATS\"\n",
    "    df_out = df[(df['ID_HDC_G0'] == city_id) & (df['year'] == year)]\n",
    "    \n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = select_city_year(ALL_DATA, 4417, 2010)\n",
    "city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = '/home/cascade/projects/UrbanHeat/data/interim/ERA5_HI/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'GHS-ERA5-HI_2009.csv'\n",
    "data = pd.read_csv(dir_list+fn)\n",
    "city = data[data['ID_HDC_G0'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_list = []\n",
    "dates_list = []\n",
    "for fn in sorted(os.listdir(dir_list)):\n",
    "    data = pd.read_csv(dir_list+fn)\n",
    "    city = data[data['ID_HDC_G0'] == 14]\n",
    "    dates = list(city.iloc[:,3:])\n",
    "    temps = list(city.iloc[:,3:].values[0])\n",
    "    dates_list.extend(dates)\n",
    "    temps_list.extend(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(dates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Total Change in people Days\n",
    "print('For Africa ...')\n",
    "data = HI_STATS[HI_STATS['region'] == 'Africa']\n",
    "data = data.groupby('year')['people_days'].sum()\n",
    "year = str(data.index[33])\n",
    "value = str(data.values[33]/10**9)\n",
    "print('person days in 2016 was '+value+' billion')\n",
    "\n",
    "year = str(data.index[0])\n",
    "value = str(data.values[0]/10**9)\n",
    "print('person days in 1983 was '+value+' billion')\n",
    "\n",
    "#### Pct Change in Poeple Days 1983 - 2016\n",
    "pdays16 = data.iloc[len(data) -1]\n",
    "pdays83 = data.iloc[0]\n",
    "out = (data.iloc[len(data) -1] - data.iloc[0]) / data.iloc[0] * 100\n",
    "print('pct increase in people days 83 - 16 is ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('What is the avg exp for Africa from 1986 - 2005')\n",
    "data.iloc[3:23].mean() / 10**9 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
