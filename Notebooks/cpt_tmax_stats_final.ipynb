{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tmax States Final\n",
    "\n",
    "A notebook to subset Tmax daily for the 13000 GHS urban areas to identify dates >40c, consecuritve days >40 c etc.\n",
    "\n",
    "Moved from cpt_tmax_subset to clean up all the code on 2019-09-24\n",
    "\n",
    "**Need to subset**\n",
    "- Days per year \n",
    "- Duration of each event \n",
    "- Intensity of each day during each event (>40.6)\n",
    "- Avg temp\n",
    "- Avg intsensity\n",
    "\n",
    "**NOTE 2019.10.19 FOUND BUG IN DATA ---> EVENTS TOO LONG**\n",
    "Some events too long and have dates that are note sequential in them.\n",
    "\n",
    "I think I fixed the problem on 2019.10.19 and reran the code\n",
    "\n",
    "\n",
    "**NOTE 2019.10.19 RE RAN CODE TO PRODUCE STATS FOR ALL YEARS AFTER FIXING BUG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from random import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import geopandas as gpd \n",
    "import glob\n",
    "from statistics import mean\n",
    "import julian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #1 Function  turns csv into x-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_xr(file_in, time_dim, space_dim):\n",
    "    \n",
    "    \"\"\" Function reads in a csv w/ GHS-UCDB IDs and temp, isolates the temp\n",
    "    and returns a xarray data array with dims set to city ids and dates\n",
    "    \n",
    "    Args:\n",
    "        file_in = file name and path\n",
    "        time_dim = name for time dim as a str ... use date :-)\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_in) # read the file in as a df\n",
    "    print(df.shape)\n",
    "    \n",
    "    df_id = df[space_dim] # get IDs\n",
    "    df_temp = df.iloc[:,3:] # get only temp columns\n",
    "    df_temp.index = df_id # set index values\n",
    "    df_temp_drop = df_temp.dropna() # Drop cities w/ no temp record \n",
    "    print(len(df_temp_drop))\n",
    "    \n",
    "    temp_np = df_temp_drop.to_numpy() # turn temp cols into an np array\n",
    "    \n",
    "    # make xr Data Array w/ data as temp and dims as spece (e.g. id)\n",
    "    \n",
    "    # Note 2019 09 17 changed to xr.Dataset from xr.Dataarray\n",
    "    temp_xr_da = xr.DataArray(temp_np, coords=[df_temp_drop.index, df_temp_drop.columns], \n",
    "                            dims=[space_dim, time_dim])\n",
    "    \n",
    "    return temp_xr_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2 Function finds all the Tmax Events and writes it to a dateframe w/ dates for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_days(xarray, Tthresh):\n",
    "    \"\"\" Function finds all the tmax days in a year and sums total days per year \n",
    "    greater than a threshold within a year where Tmax > Tthresh for each city. Returns the total number of days,\n",
    "    the dates, the tempatures, and the intensity (daily Tmax - Tthresh)\n",
    "    \n",
    "    Args: \n",
    "        xarray = an xarray object with dims = (space, times)\n",
    "        Tthresh = int of temp threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty lists & df\n",
    "    id_list = []\n",
    "    date_list = []\n",
    "    dayTot_list = []\n",
    "    tmax_list = []\n",
    "    intensity_list = []\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # subset xarray\n",
    "    out = xarray.where(xarray > Tthresh, drop = True)\n",
    "\n",
    "    # start loop \n",
    "    for index, loc in enumerate(out.ID_HDC_G0):\n",
    "        id_list.append(out.ID_HDC_G0.values[index]) # get IDS\n",
    "        date_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values) # get event dates\n",
    "        \n",
    "        # this is actually getting the total events of all, 2019-09-22\n",
    "        dayTot_list.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values)) # get event totals\n",
    "        \n",
    "        tmax_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values) # get temp values\n",
    "        intensity_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values - Tthresh) # get severity\n",
    "\n",
    "    # write to a data frame\n",
    "    df_out['ID_HDC_G0'] = id_list\n",
    "    df_out['total_days'] = dayTot_list\n",
    "    df_out['dates'] = date_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "    df_out['tmax_tntensity'] = intensity_list\n",
    "\n",
    "    # return df_out\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #3 Function splits the dataset into Tmax events (continuous days >Tmax) for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jul_convert(dates):\n",
    "    \"Function turn days into julian datetime\"\n",
    "    jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "    \n",
    "    return jul_days\n",
    "\n",
    "def event_split(dates, ID_HDC_G0, intensity, tmax, total_days):\n",
    "    \"\"\" Searchs a list of dates and isolates sequential dates as a list, then calculates event stats.\n",
    "    See comments in code for more details. \n",
    "    \n",
    "    Args:\n",
    "        dates: pandas.core.index as julian dates\n",
    "        ID_HDC_G0: city ID as string\n",
    "        country: country for each city as string\n",
    "        intensity: numpy.ndarray of intensities values\n",
    "        tmax: numpy.ndarray of intensities values of tmax values\n",
    "        total_days: total number of tmax days in a year for a given city\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # city id\n",
    "    city_id = ID_HDC_G0\n",
    "    tot_days = total_days\n",
    "    \n",
    "    # lists to fill\n",
    "    city_id_list = []\n",
    "    tot_days_list = []\n",
    "    event_dates_list = []\n",
    "    dur_list = []\n",
    "    intensity_list = []\n",
    "    tmax_list = []\n",
    "    avg_temp_list = []\n",
    "    avg_int_list = []\n",
    "    tot_int_list = []\n",
    "    \n",
    "    # data frame out\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # turn days into julian days\n",
    "    jul_days = jul_convert(dates)\n",
    "    \n",
    "    # Counters to make sure we write the correct event dates to a list, don't want julian days in output\n",
    "    counter = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    # Loop through dur list and isolate seq days, temps, and intensities\n",
    "    for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "        \n",
    "        seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "        dur = len(seq) # duration of each event\n",
    "        \n",
    "        counter = counter + dur # add duration to counter\n",
    "        end = counter # end of current event\n",
    "        \n",
    "        event_dates = dates[start:end] # dates of tmax days during each event\n",
    "        intense = intensity[start:end] # intensity of each day during event\n",
    "        temp = tmax[start:end] # temp of each day during event\n",
    "        avg_temp = mean(temp) # avg. temp during event\n",
    "        avg_int = mean(intense) # avg. intensity during event\n",
    "        tot_int = intense.sum() # total intensity during event\n",
    "        \n",
    "        start = counter # reset start to current end (e.g. counter)\n",
    "        \n",
    "        # fill lists\n",
    "        city_id_list.append(city_id)\n",
    "        tot_days_list.append(tot_days)\n",
    "        dur_list.append(dur)\n",
    "        event_dates_list.append(event_dates)\n",
    "        intensity_list.append(intense)\n",
    "        tmax_list.append(temp)\n",
    "        avg_temp_list.append(avg_temp)\n",
    "        avg_int_list.append(avg_int)\n",
    "        tot_int_list.append(tot_int)\n",
    "\n",
    "    # write out as a dateframe\n",
    "    df_out['ID_HDC_G0'] = city_id_list\n",
    "    df_out['total_days'] = tot_days_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['avg_temp'] = avg_temp_list\n",
    "    df_out['avg_intensity'] = avg_int_list\n",
    "    df_out['tot_intensity'] = tot_int_list\n",
    "    df_out['event_dates'] = event_dates_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['intensity'] = intensity_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #4 Function feeds output from function 2 into function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_stats(df_in):\n",
    "    \"\"\" runs event_split functionon a dataframe to produce desired tmax stats\n",
    "    \n",
    "        NOTE - If you add arguments to event_split to make more states, \n",
    "        be sure to update this function\n",
    "    \n",
    "        args:\n",
    "            df: input dataframe\n",
    "        \n",
    "    \"\"\"\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # NOTE - If you add arguments to event_split to make more stats, \n",
    "    # be sure to update this function\n",
    "    \n",
    "    for index, row in df_in.iterrows():\n",
    "        dates = row['dates'] # Get event dates\n",
    "        intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "        tmax = row['tmax'] # Get tmax for each day\n",
    "        ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "        total_days = row['total_days'] # get total number of tmax days\n",
    "\n",
    "        df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "\n",
    "        df_out = df_out.append(df)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #5 Loops through a file list and applies functions 1 - 4 to the data to produce Tmax stats for all tmax events in a given year across all cities in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_loop(dir_in, dir_out, fn_out, time_dim, space_dim, Tthresh):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs to apply csv_to_xr and\n",
    "    tmax_stats function and save out a .csv for each year\n",
    "    \n",
    "    Args:\n",
    "        dir_in = dir path to loop through\n",
    "        dir_out = dir path to save files out\n",
    "        fn_out = string to label out files\n",
    "        time_dim = name for time dim as a str ... use date :-) for csv_to_xr function\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0) for csv_to_xr function\n",
    "        Tthresh = int of temp threshold for temp_event function -- 40.6 is used\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the GHS-ID List with GeoPANDAS read_file\n",
    "    ghs_ids_fn = 'GHS-UCSB-IDS.csv'\n",
    "    ghs_ids_df = pd.read_csv(DATA_INTERIM+ghs_ids_fn)\n",
    "        \n",
    "    # Git File list\n",
    "    fn_list = glob.glob(dir_in+'*.csv')\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "        \n",
    "        # Get year for arg for temp_event function\n",
    "        year = fn.split('GHS-Tmax-DAILY_')[1].split('.csv')[0]\n",
    "        print(year)\n",
    "        \n",
    "        # read csv as a data array\n",
    "        temp_xr_da = csv_to_xr(fn, time_dim, space_dim)\n",
    "        \n",
    "        # data array to tmax events, out as df\n",
    "        df_days = tmax_days(temp_xr_da, Tthresh)\n",
    "        \n",
    "        # tmax events stats, out as df\n",
    "        df_out = tmax_stats(df_days)\n",
    "        \n",
    "        # merge to get countries\n",
    "        ghs_ids_df_out = ghs_ids_df.merge(df_out, on='ID_HDC_G0', how = 'inner') \n",
    "        \n",
    "        # write it all out\n",
    "        ghs_ids_df_out.to_csv(dir_out+fn_out+year+'.csv')\n",
    "\n",
    "        print(year, 'SAVED!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/' # ghs ID list\n",
    "dir_out = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'\n",
    "fn_out = 'CHIRTS-GHS-Events-Stats'\n",
    "time_dim = 'date'\n",
    "space_dim = 'ID_HDC_G0'\n",
    "Tthresh = 40.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983\n",
      "(13135, 368)\n",
      "13067\n",
      "1983 SAVED!\n",
      "1984\n",
      "(13135, 369)\n",
      "13067\n",
      "1984 SAVED!\n",
      "1985\n",
      "(13135, 368)\n",
      "13067\n",
      "1985 SAVED!\n",
      "1986\n",
      "(13135, 368)\n",
      "13067\n",
      "1986 SAVED!\n",
      "1987\n",
      "(13135, 368)\n",
      "13067\n",
      "1987 SAVED!\n",
      "1988\n",
      "(13135, 369)\n",
      "13067\n",
      "1988 SAVED!\n",
      "1989\n",
      "(13135, 368)\n",
      "13067\n",
      "1989 SAVED!\n",
      "1990\n",
      "(13135, 368)\n",
      "13067\n",
      "1990 SAVED!\n",
      "1991\n",
      "(13135, 368)\n",
      "13067\n",
      "1991 SAVED!\n",
      "1992\n",
      "(13135, 369)\n",
      "13067\n",
      "1992 SAVED!\n",
      "1993\n",
      "(13135, 368)\n",
      "13067\n",
      "1993 SAVED!\n",
      "1994\n",
      "(13135, 368)\n",
      "13067\n",
      "1994 SAVED!\n",
      "1995\n",
      "(13135, 368)\n",
      "13067\n",
      "1995 SAVED!\n",
      "1996\n",
      "(13135, 369)\n",
      "13067\n",
      "1996 SAVED!\n",
      "1997\n",
      "(13135, 368)\n",
      "13067\n",
      "1997 SAVED!\n",
      "1998\n",
      "(13135, 368)\n",
      "13067\n",
      "1998 SAVED!\n",
      "1999\n",
      "(13135, 368)\n",
      "13067\n",
      "1999 SAVED!\n",
      "2000\n",
      "(13135, 369)\n",
      "13067\n",
      "2000 SAVED!\n",
      "2001\n",
      "(13135, 368)\n",
      "13067\n",
      "2001 SAVED!\n",
      "2002\n",
      "(13135, 368)\n",
      "13067\n",
      "2002 SAVED!\n",
      "2003\n",
      "(13135, 368)\n",
      "13067\n",
      "2003 SAVED!\n",
      "2004\n",
      "(13135, 369)\n",
      "13067\n",
      "2004 SAVED!\n",
      "2005\n",
      "(13135, 368)\n",
      "13067\n",
      "2005 SAVED!\n",
      "2006\n",
      "(13135, 368)\n",
      "13067\n",
      "2006 SAVED!\n",
      "2007\n",
      "(13135, 368)\n",
      "13067\n",
      "2007 SAVED!\n",
      "2008\n",
      "(13135, 369)\n",
      "13067\n",
      "2008 SAVED!\n",
      "2009\n",
      "(13135, 368)\n",
      "13067\n",
      "2009 SAVED!\n",
      "2010\n",
      "(13135, 368)\n",
      "13067\n",
      "2010 SAVED!\n",
      "2011\n",
      "(13135, 368)\n",
      "13067\n",
      "2011 SAVED!\n",
      "2012\n",
      "(13135, 369)\n",
      "13067\n",
      "2012 SAVED!\n",
      "2013\n",
      "(13135, 368)\n",
      "13067\n",
      "2013 SAVED!\n",
      "2014\n",
      "(13135, 368)\n",
      "13067\n",
      "2014 SAVED!\n",
      "2015\n",
      "(13135, 368)\n",
      "13067\n",
      "2015 SAVED!\n",
      "2016\n",
      "(13135, 369)\n",
      "13067\n",
      "2016 SAVED!\n"
     ]
    }
   ],
   "source": [
    "#stats_loop(dir_in, dir_out, fn_out, time_dim, space_dim, Tthresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA/QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "\n",
    "dir_out = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'\n",
    "fn_out = 'CHIRTS-GHS-Events-Stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_df = pd.read_csv(dir_out+fn_out+'1983.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>CTR_MN_NM</th>\n",
       "      <th>total_days</th>\n",
       "      <th>duration</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_intensity</th>\n",
       "      <th>tot_intensity</th>\n",
       "      <th>event_dates</th>\n",
       "      <th>intensity</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2784</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44.459750</td>\n",
       "      <td>3.859750</td>\n",
       "      <td>3.859750</td>\n",
       "      <td>['1983.07.27']</td>\n",
       "      <td>[3.85975]</td>\n",
       "      <td>[44.45975]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2372</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43.331635</td>\n",
       "      <td>2.731635</td>\n",
       "      <td>2.731635</td>\n",
       "      <td>['1983.07.31']</td>\n",
       "      <td>[2.731635]</td>\n",
       "      <td>[43.331635]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6156</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.336376</td>\n",
       "      <td>0.736376</td>\n",
       "      <td>0.736376</td>\n",
       "      <td>['1983.07.31']</td>\n",
       "      <td>[0.736376]</td>\n",
       "      <td>[41.336376]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2833</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.493180</td>\n",
       "      <td>6.893180</td>\n",
       "      <td>6.893180</td>\n",
       "      <td>['1983.07.27']</td>\n",
       "      <td>[6.89318]</td>\n",
       "      <td>[47.49318]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2885</td>\n",
       "      <td>Austria</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44.013890</td>\n",
       "      <td>3.413890</td>\n",
       "      <td>3.413890</td>\n",
       "      <td>['1983.07.27']</td>\n",
       "      <td>[3.41389]</td>\n",
       "      <td>[44.01389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID_HDC_G0   CTR_MN_NM  total_days  duration   avg_temp  \\\n",
       "0           0       2784     Germany           1         1  44.459750   \n",
       "1           1       2372      France           1         1  43.331635   \n",
       "2           2       6156  Kazakhstan           1         1  41.336376   \n",
       "3           3       2833     Germany           1         1  47.493180   \n",
       "4           4       2885     Austria           1         1  44.013890   \n",
       "\n",
       "   avg_intensity  tot_intensity     event_dates   intensity         tmax  \n",
       "0       3.859750       3.859750  ['1983.07.27']   [3.85975]   [44.45975]  \n",
       "1       2.731635       2.731635  ['1983.07.31']  [2.731635]  [43.331635]  \n",
       "2       0.736376       0.736376  ['1983.07.31']  [0.736376]  [41.336376]  \n",
       "3       6.893180       6.893180  ['1983.07.27']   [6.89318]   [47.49318]  \n",
       "4       3.413890       3.413890  ['1983.07.27']   [3.41389]   [44.01389]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_city = qc_df[qc_df['ID_HDC_G0'] == 5534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>CTR_MN_NM</th>\n",
       "      <th>total_days</th>\n",
       "      <th>duration</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_intensity</th>\n",
       "      <th>tot_intensity</th>\n",
       "      <th>event_dates</th>\n",
       "      <th>intensity</th>\n",
       "      <th>tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22525</td>\n",
       "      <td>22525</td>\n",
       "      <td>5534</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>40.736885</td>\n",
       "      <td>0.136885</td>\n",
       "      <td>0.136885</td>\n",
       "      <td>['1983.01.05']</td>\n",
       "      <td>[0.136885]</td>\n",
       "      <td>[40.736885]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22526</td>\n",
       "      <td>22526</td>\n",
       "      <td>5534</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>84</td>\n",
       "      <td>13</td>\n",
       "      <td>41.737855</td>\n",
       "      <td>1.137855</td>\n",
       "      <td>14.792109</td>\n",
       "      <td>['1983.01.19' '1983.01.20' '1983.01.21' '1983....</td>\n",
       "      <td>[0.846815 2.002577 1.19209  0.916884 0.81514  ...</td>\n",
       "      <td>[41.446815 42.602577 41.79209  41.516884 41.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22527</td>\n",
       "      <td>22527</td>\n",
       "      <td>5534</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "      <td>41.062670</td>\n",
       "      <td>0.462670</td>\n",
       "      <td>4.164027</td>\n",
       "      <td>['1983.02.05' '1983.02.06' '1983.02.07' '1983....</td>\n",
       "      <td>[0.137976 0.035193 0.511267 0.594824 1.123145 ...</td>\n",
       "      <td>[40.737976 40.635193 41.111267 41.194824 41.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22528</td>\n",
       "      <td>22528</td>\n",
       "      <td>5534</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>41.553627</td>\n",
       "      <td>0.953627</td>\n",
       "      <td>7.629014</td>\n",
       "      <td>['1983.02.16' '1983.02.17' '1983.02.18' '1983....</td>\n",
       "      <td>[0.600165 1.43894  1.109015 1.421606 1.34052  ...</td>\n",
       "      <td>[41.200165 42.03894  41.709015 42.021606 41.94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22529</td>\n",
       "      <td>22529</td>\n",
       "      <td>5534</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>84</td>\n",
       "      <td>43</td>\n",
       "      <td>42.115429</td>\n",
       "      <td>1.515429</td>\n",
       "      <td>65.163434</td>\n",
       "      <td>['1983.02.26' '1983.02.27' '1983.02.28' '1983....</td>\n",
       "      <td>[0.33683  1.354803 1.337897 1.908553 0.734724 ...</td>\n",
       "      <td>[40.93683  41.954803 41.937897 42.508553 41.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22530</td>\n",
       "      <td>22530</td>\n",
       "      <td>5534</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>84</td>\n",
       "      <td>10</td>\n",
       "      <td>41.332326</td>\n",
       "      <td>0.732326</td>\n",
       "      <td>7.323264</td>\n",
       "      <td>['1983.04.11' '1983.04.12' '1983.04.13' '1983....</td>\n",
       "      <td>[0.224825 0.785494 0.962283 1.486514 0.874148 ...</td>\n",
       "      <td>[40.824825 41.385494 41.562283 42.086514 41.47...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  ID_HDC_G0 CTR_MN_NM  total_days  duration   avg_temp  \\\n",
       "22525       22525       5534  Ethiopia          84         1  40.736885   \n",
       "22526       22526       5534  Ethiopia          84        13  41.737855   \n",
       "22527       22527       5534  Ethiopia          84         9  41.062670   \n",
       "22528       22528       5534  Ethiopia          84         8  41.553627   \n",
       "22529       22529       5534  Ethiopia          84        43  42.115429   \n",
       "22530       22530       5534  Ethiopia          84        10  41.332326   \n",
       "\n",
       "       avg_intensity  tot_intensity  \\\n",
       "22525       0.136885       0.136885   \n",
       "22526       1.137855      14.792109   \n",
       "22527       0.462670       4.164027   \n",
       "22528       0.953627       7.629014   \n",
       "22529       1.515429      65.163434   \n",
       "22530       0.732326       7.323264   \n",
       "\n",
       "                                             event_dates  \\\n",
       "22525                                     ['1983.01.05']   \n",
       "22526  ['1983.01.19' '1983.01.20' '1983.01.21' '1983....   \n",
       "22527  ['1983.02.05' '1983.02.06' '1983.02.07' '1983....   \n",
       "22528  ['1983.02.16' '1983.02.17' '1983.02.18' '1983....   \n",
       "22529  ['1983.02.26' '1983.02.27' '1983.02.28' '1983....   \n",
       "22530  ['1983.04.11' '1983.04.12' '1983.04.13' '1983....   \n",
       "\n",
       "                                               intensity  \\\n",
       "22525                                         [0.136885]   \n",
       "22526  [0.846815 2.002577 1.19209  0.916884 0.81514  ...   \n",
       "22527  [0.137976 0.035193 0.511267 0.594824 1.123145 ...   \n",
       "22528  [0.600165 1.43894  1.109015 1.421606 1.34052  ...   \n",
       "22529  [0.33683  1.354803 1.337897 1.908553 0.734724 ...   \n",
       "22530  [0.224825 0.785494 0.962283 1.486514 0.874148 ...   \n",
       "\n",
       "                                                    tmax  \n",
       "22525                                        [40.736885]  \n",
       "22526  [41.446815 42.602577 41.79209  41.516884 41.41...  \n",
       "22527  [40.737976 40.635193 41.111267 41.194824 41.72...  \n",
       "22528  [41.200165 42.03894  41.709015 42.021606 41.94...  \n",
       "22529  [40.93683  41.954803 41.937897 42.508553 41.33...  \n",
       "22530  [40.824825 41.385494 41.562283 42.086514 41.47...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/data_out_urbanheat/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open a raw file\n",
    "xr1983 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days1983 = tmax_days(xr1983, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = days1983[0:30]\n",
    "test\n",
    "\n",
    "# Maybe add in days_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build routine for loop through a csv\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "    \n",
    "    df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "    \n",
    "    df_out = df_out.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing code\n",
    "2019.10.19 Cascade Tuholkse\n",
    "\n",
    "Need to fix ```event split``` function\n",
    "\n",
    "Somewhere in 1984 is this event sequence: ['1984.01.01' '1984.01.02' '1984.01.07']\n",
    "\n",
    "\n",
    "**FOUND PROBLEM AND IT IS FIXED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/data_out_urbanheatv/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out_urbanheat/testout/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open a raw file\n",
    "xr1983 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the tmax days\n",
    "tmax1983 = tmax_days(xr1983, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset\n",
    "\n",
    "test = tmax1983[tmax1983['ID_HDC_G0'] == 6279]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to jul days\n",
    "jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "jul_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjd = 2445507.5 - 43200\n",
    "dt = julian.from_jd(mjd, fmt='mjd')\n",
    "print(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['1983.06.20', '1983.06.23', '1983.06.24', '1983.06.25',\n",
    "        '1983.06.26', '1983.06.27', '1983.06.28', '1983.06.29',\n",
    "        '1983.06.30', '1983.07.01', '1983.07.21', '1983.07.22',\n",
    "        '1983.07.23', '1983.08.01']\n",
    "\n",
    "pd_dates = pd.to_datetime(dates)\n",
    "df_dates = pd.DataFrame()\n",
    "df_dates['dates'] = pd_dates\n",
    "\n",
    "\n",
    "\n",
    "test = df_dates['dates'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "date.fromordinal(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = dates[0:10] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))\n",
    "\n",
    "event_dates = dates[10:13] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))\n",
    "\n",
    "event_dates = dates[13:14] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates_list = []\n",
    "counter = 0\n",
    "start = 0\n",
    "end = 0\n",
    "\n",
    "for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "    \n",
    "    len_dates = len(dates) # len of all Tmax dates for a given city\n",
    "#   print(len(dates))\n",
    "    \n",
    "    seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "    dur = len(seq) # duration of each event \n",
    "    \n",
    "    counter = counter + dur\n",
    "    end = counter\n",
    "    \n",
    "    print(end)\n",
    "    \n",
    "    event_dates = dates[start:end] # dates of tmax days during each event\n",
    "    print(event_dates)\n",
    "    \n",
    "    start = counter\n",
    "    \n",
    "# #     print('dur= ', dur)\n",
    "    \n",
    "#     event_dates = dates[0:10] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "#     event_dates = dates[11:13] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "#     event_dates = dates[:len_dates] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     counter = counter + dur\n",
    "\n",
    "#     print('counter = ', counter)\n",
    "    \n",
    "#     dif = dur - counter\n",
    "#     print('dif = ', dif)\n",
    "    \n",
    "#     start = start \n",
    "#     print('start = ',start)\n",
    "    \n",
    "# #     end = counter + dur\n",
    "# #     print(\"start = \",end)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     counter = counter + dur\n",
    "#     print(counter)\n",
    "#     end = counter + dur\n",
    "#     start\n",
    "#     event_dates = dates[start:end] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "# #     intense = intensity[0:dur] # intensity of each day during event\n",
    "#     temp = tmax[0:dur] # temp of each day during event\n",
    "#     avg_temp = mean(temp) # avg. temp during event\n",
    "#     avg_int = mean(intense) # avg. intensity during event\n",
    "#     tot_int = intense.sum() # total intensity during event\n",
    "    \n",
    "#     event_dates_list.append(event_dates)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['event_dates'] = event_dates_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tmax stats ------> CLEARLY NOTE WORKING\n",
    "\n",
    "# tmax1983_sub_stats = tmax_stats(tmax1983_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmax1983['dates'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = tmax1983_sub['dates']\n",
    "#jul_days = pd.to_datetime(tmax1983['dates']).to_julian_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to break up events\n",
    "\n",
    "for index, row in tmax1983_sub.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "\n",
    "#     df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "\n",
    "#     df_out = df_out.append(df)\n",
    "\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_out['events'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
