{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Plots\n",
    "\n",
    "Notebook to make probability density plots of tmax events\n",
    "\n",
    "Cascade Tuholske 2019-10-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib as mpl\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Files and Isolate India for Density\n",
    "\n",
    "def event_stack_loop(dir_in):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs of tmax events for each year and\n",
    "    stack them into one data frame. Current file name is CHIRTS-GHS-Events-StatsXXXX.csv\n",
    "    \n",
    "    Args:\n",
    "        dir_in = dir path to loop through\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get File list\n",
    "    fn_list = glob.glob(dir_in+'*.csv')\n",
    "    \n",
    "    # Data frame to fill\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "    \n",
    "        # Likely need to change year to int ... df['purchase'].astype(str).astype(int) <<<<---- FIX \n",
    "        year = fn.split('CHIRTS-GHS-Events-Stats')[2].split('.csv')[0] # for some reason it's 2...?\n",
    "        print(year)\n",
    "        \n",
    "        # open csv \n",
    "        stats = pd.read_csv(fn)\n",
    "        \n",
    "        stats['year'] = year\n",
    "        \n",
    "        print(len(df_out))\n",
    "        \n",
    "        df_out = df_out.append(stats)\n",
    "    \n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "\n",
    "DATA_IN = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983\n",
      "0\n",
      "1984\n",
      "22697\n",
      "1985\n",
      "45973\n",
      "1986\n",
      "68052\n",
      "1987\n",
      "90782\n",
      "1988\n",
      "118152\n",
      "1989\n",
      "141253\n",
      "1990\n",
      "165683\n",
      "1991\n",
      "188246\n",
      "1992\n",
      "210758\n",
      "1993\n",
      "233690\n",
      "1994\n",
      "256043\n",
      "1995\n",
      "277151\n",
      "1996\n",
      "302703\n",
      "1997\n",
      "327548\n",
      "1998\n",
      "349972\n",
      "1999\n",
      "377141\n",
      "2000\n",
      "405013\n",
      "2001\n",
      "429536\n",
      "2002\n",
      "451902\n",
      "2003\n",
      "479397\n",
      "2004\n",
      "505665\n",
      "2005\n",
      "532560\n",
      "2006\n",
      "561806\n",
      "2007\n",
      "587661\n",
      "2008\n",
      "612509\n",
      "2009\n",
      "638375\n",
      "2010\n",
      "671454\n",
      "2011\n",
      "707812\n",
      "2012\n",
      "733383\n",
      "2013\n",
      "763002\n",
      "2014\n",
      "789451\n",
      "2015\n",
      "819600\n",
      "2016\n",
      "849829\n"
     ]
    }
   ],
   "source": [
    "# Run script\n",
    "event_stack = event_stack_loop(DATA_IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_stack.to_csv('All_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type\n",
    "\n",
    "event_stack['year'] = event_stack['year'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Select years and country\n",
    "\n",
    "def event_subset(df, country, start, end):\n",
    "    \"\"\" ADD THIS\"\"\"\n",
    "    \n",
    "    country_df = event_stack[event_stack['CTR_MN_NM'] == country].copy()\n",
    "    range_df = country_df[(country_df['year'] >= start) & (country_df['year'] <= end)]\n",
    "    \n",
    "    return range_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select years and country\n",
    "\n",
    "india86_95 = event_subset(event_stack, 'Nigeria', start = 1986, end = 1995)\n",
    "india96_05 = event_subset(event_stack, 'Nigeria', start = 1996, end = 2005)\n",
    "india06_15 = event_subset(event_stack, 'Nigeria', start = 2006, end = 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Void this later\n",
    "\n",
    "india86_95  = event_stack[(event_stack['year'] >= 1986) & (event_stack['year'] <= 1995)]\n",
    "india96_05  = event_stack[(event_stack['year'] >= 1996) & (event_stack['year'] <= 2005)]\n",
    "india06_15  = event_stack[(event_stack['year'] >= 2006) & (event_stack['year'] <= 2015)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Culm Dist Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Culm dist ordering\n",
    "# prob event duration is larger than each duration in rank order \n",
    "\n",
    "def p_X_gt_x(data, X=None):\n",
    "    \n",
    "    \"\"\"Makes probabiliy distribution of data, data must be sorted first\"\"\"\n",
    "    n_data = len(data)\n",
    "    if X is None:\n",
    "        X = data.unique()\n",
    "    return X, pd.Series([sum(data>=x)/n_data for x in X ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values & make dist\n",
    "\n",
    "data8695 = india86_95['duration'].sort_values()\n",
    "X8695, Y8605 = p_X_gt_x(data8695)\n",
    "\n",
    "data9605 = india96_05['duration'].sort_values()\n",
    "X9605, Y9605 = p_X_gt_x(data9605)\n",
    "\n",
    "data0615 = india06_15['duration'].sort_values()\n",
    "X0615, Y0615 = p_X_gt_x(data0615)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# style and size\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(figsize=[10,8])\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# plots\n",
    "plt.plot(X8695, Y8605, 'o', color='red', alpha = 0.5)\n",
    "plt.plot(X9605, Y9605, '*', color='blue', alpha = 0.5)\n",
    "plt.plot(X0615, Y0615, '.', color='green', alpha = 0.5)\n",
    "\n",
    "# titles\n",
    "plt.title('Inverse cumulative distribution of heat wave duration', fontsize = 20)\n",
    "plt.xlabel('Event Duration, Days', fontsize = 15)\n",
    "plt.ylabel('P(Event duration)', fontsize = 15)\n",
    "\n",
    "# legend\n",
    "leg_labels = ['86-95', '95-06', '06 - 15']\n",
    "plt.legend(leg_labels, fontsize = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# np.random.seed(19680801)\n",
    "\n",
    "# mu = 200\n",
    "# sigma = 25\n",
    "# n_bins = 50\n",
    "# x = np.random.normal(mu, sigma, size=100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "# plot the cumulative histogram\n",
    "n, bins, patches = ax.hist(india86_95['avg_temp'], n_bins, density=True, histtype='step',\n",
    "                           cumulative=True, label='Empirical')\n",
    "\n",
    "n, bins, patches = ax.hist(india96_05['avg_temp'], n_bins, density=True, histtype='step',\n",
    "                           cumulative=True, label='Empirical')\n",
    "\n",
    "n, bins, patches = ax.hist(india06_15['avg_temp'], n_bins, density=True, histtype='step',\n",
    "                           cumulative=True, label='Empirical')\n",
    "\n",
    "# Add a line showing the expected distribution.\n",
    "# y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "#      np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "# y = y.cumsum()\n",
    "# y /= y[-1]\n",
    "\n",
    "# ax.plot(bins, y, 'k--', linewidth=1.5, label='Theoretical')\n",
    "\n",
    "# Overlay a reversed cumulative histogram.\n",
    "# ax.hist(india06_15['duration'], bins=bins, density=True, histtype='step', cumulative=-1,\n",
    "#         label='Reversed emp.')\n",
    "\n",
    "# tidy up the figure\n",
    "ax.grid(True)\n",
    "ax.legend(loc='lower center', labels = ['86-95', '96-05', '06-15'], fontsize = 15)\n",
    "ax.set_title('Cumulative step histograms, Globally', fontsize = 15)\n",
    "ax.set_xlabel('Avg. temp of heat event(Tmax >40.6C)', fontsize = 15)\n",
    "#ax.set_xlabel('Duration of Tmax event (Tmax >40.6C)', fontsize = 15)\n",
    "ax.set_ylabel('Likelihood of occurrence', fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if it is a pareto dist\n",
    "\n",
    "dist = st.pareto\n",
    "params = dist.fit(data) # , 1)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a hist\n",
    "\n",
    "y, x = np.histogram(data, bins = 30, density = True) # check bins\n",
    "\n",
    "# ASK KELLY <<<<<-----\n",
    "x = (x+np.roll(x, -1))[:-1] / 2.0 # center x in middle of bins \n",
    "\n",
    "# exp\n",
    "#pdf = dist.pdf(x, loc = params[-2], scale = params[-1])\n",
    "\n",
    "# pareto \n",
    "pdf = dist.pdf(x, 1, loc = params[-2], scale = params[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get errors\n",
    "\n",
    "ss_error = np.sum(np.power(y - pdf, 2.0))\n",
    "ss_yy = np.sum(np.power(y - y.mean(), 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodness of fit\n",
    "\n",
    "r_2 = 1 - (ss_error / ss_yy)\n",
    "print(r_2)\n",
    "\n",
    "# https://stackoverflow.com/questions/42260519/defining-pareto-distribution-in-python-scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KELLY MAKE A PLOT ??? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Files and Isolate India for Density\n",
    "\n",
    "def event_stack_loop(dir_in, country):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs of tmax events for each year and\n",
    "    stack them into one data frame. Current file name is CHIRTS-GHS-Events-StatsXXXX.csv\n",
    "    \n",
    "    Args:\n",
    "        dir_in = dir path to loop through\n",
    "        country = country to subset\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get File list\n",
    "    fn_list = glob.glob(dir_in+'*.csv')\n",
    "    \n",
    "    # Data frame to fill\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "        \n",
    "        #print(fn)\n",
    "    \n",
    "        # Likely need to change year to int ... df['purchase'].astype(str).astype(int) <<<<---- FIX \n",
    "        year = fn.split('CHIRTS-GHS-Events-Stats')[2].split('.csv')[0] # for some reason it's 2...?\n",
    "        print(year)\n",
    "        \n",
    "        # open csv \n",
    "        stats = pd.read_csv(fn)\n",
    "        \n",
    "        # isloate country \n",
    "        country = stats[stats['CTR_MN_NM']==country].copy()\n",
    "        print(country.shape)\n",
    "        \n",
    "        # add year column \n",
    "        country['year'] = year\n",
    "        \n",
    "        df_out = df_out.append(country)\n",
    "    \n",
    "    df_out['year'] = df_out['year'].astype(str).astype(int)\n",
    "    \n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open csv \n",
    "stats1 = pd.read_csv(DATA_IN+'CHIRTS-GHS-Events-Stats1985.csv')\n",
    "stats2 = pd.read_csv(DATA_IN+'CHIRTS-GHS-Events-Stats1986.csv')\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "\n",
    "country1 = stats1[stats1['CTR_MN_NM'] == 'India']\n",
    "country1['year'] = 1985\n",
    "country2 = stats2[stats2['CTR_MN_NM'] == 'India']\n",
    "country2['year'] = 1986\n",
    "\n",
    "\n",
    "df_out = df_out.append(country1)\n",
    "print(len(df_out))\n",
    "df_out = df_out.append(country2)\n",
    "print(len(df_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset \n",
    "# https://stackoverflow.com/questions/38884466/how-to-select-a-range-of-values-in-a-pandas-dataframe-column\n",
    "\n",
    "def year_subset(df, start, end):\n",
    "    \n",
    "\n",
    "india_stack[(india_stack['year'] >= 1986) & (india_stack['year'] >= 1995)]\n",
    "india_stack[(india_stack['year'] >= 1986) & (india_stack['year'] >= 1995)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india86_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(india86_95['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open csv \n",
    "stats1 = pd.read_csv(DATA_IN+'CHIRTS-GHS-Events-Stats1985.csv')\n",
    "stats2 = pd.read_csv(DATA_IN+'CHIRTS-GHS-Events-Stats1986.csv')\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "\n",
    "country1 = stats1[stats1['CTR_MN_NM'] == 'India']\n",
    "country1['year'] = 1985\n",
    "country2 = stats2[stats2['CTR_MN_NM'] == 'India']\n",
    "country2['year'] = 1986\n",
    "\n",
    "\n",
    "df_out = df_out.append(country1)\n",
    "print(len(df_out))\n",
    "df_out = df_out.append(country2)\n",
    "print(len(df_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = event_stack[event_stack['CTR_MN_NM'] == 'Vietnam'].copy()\n",
    "country['year'] = country['year'].astype(str).astype(int)\n",
    "country83 = country[country['year']== 1983]\n",
    "country15 = country[country['year']== 2015]\n",
    "# country86_95 = country[(country['year'] >= 1986) & (country['year'] <= 1995)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country83.duration.max())\n",
    "print(country15.duration.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "india = event_stack[event_stack['CTR_MN_NM'] == 'India'].copy()\n",
    "india['year'] = india['year'].astype(str).astype(int)\n",
    "india83 = india[india['year']== 1983]\n",
    "india15 = india[india['year']== 1990]\n",
    "# india86_95 = india[(india['year'] >= 1986) & (india['year'] <= 1995)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india = event_stack[event_stack['CTR_MN_NM'] == 'India'].copy()\n",
    "india['year'] = india['year'].astype(str).astype(int)\n",
    "india86_95 = india[(india['year'] >= 1986) & (india['year'] <= 1995)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "india86_95.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india = event_stack[event_stack['CTR_MN_NM'] == 'India'].copy()\n",
    "india['year'] = india['year'].astype(str).astype(int)\n",
    "india96_05 = india[(india['year'] >= 1996) & (india['year'] <= 2005)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india = event_stack[event_stack['CTR_MN_NM'] == 'India'].copy()\n",
    "india['year'] = india['year'].astype(str).astype(int)\n",
    "india06_15 = india[(india['year'] >= 2006) & (india['year'] <= 2015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig = plt.subplots(figsize=[10,10])\n",
    "\n",
    "sns.distplot(india86_95['duration'], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 2})\n",
    "\n",
    "sns.distplot(india96_05['duration'], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'orange', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 2})\n",
    "\n",
    "sns.distplot(india06_15['duration'], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'green', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 2})\n",
    "\n",
    "# Look for events L = 0 ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
