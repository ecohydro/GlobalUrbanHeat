{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS Calculations\n",
    "\n",
    "Notebook to crunch numbers for the MS.\n",
    "\n",
    "by Cascade Tuholske 2020.02.23 \n",
    "\n",
    "Updated 2020.08.27 - CPT\n",
    "Was run on ERA5 RH with CHIRTS-Daily Tmax from ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Depdencies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import matplotlib.dates as mdates\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Regressions, no intercept addition is needed because we're using SK LEARN HERE \n",
    "\n",
    "def lm_func(df, col):\n",
    "    \n",
    "    \"simple linear model of a time series data, returns coef\"\n",
    "    \n",
    "    # Get Data\n",
    "    X_year = np.array(df.groupby('year')['ID_HDC_G0'].mean().index).reshape((-1, 1))\n",
    "    Y_stats = np.array(df.groupby('year')[col].sum()).reshape((-1, 1))\n",
    "\n",
    "    # Add Intercept\n",
    "    X_year_2 = sm.add_constant(X_year)\n",
    "\n",
    "    # Regress\n",
    "    model = sm.OLS(Y_stats, X_year_2).fit() \n",
    "        \n",
    "    coef = int(model.params[1])\n",
    "    #coef = int(coef)\n",
    "            \n",
    "    # R2 and P\n",
    "    r2 = model.rsquared_adj\n",
    "    p = model.pvalues[0]\n",
    "    \n",
    "    return coef, round(r2, 2), round(p, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Data\n",
    "DATA = 'wbgtmax30' # UPDATE \n",
    "\n",
    "# file paths\n",
    "DATA_IN = \"/scratch/cascade/UEH-daily/stats/\"  \n",
    "FIG_OUT = \"/home/cascade/projects/UrbanHeat/figures/\"\n",
    "FN_IN = os.path.join(DATA_IN,DATA+'_EXP.json')\n",
    "HI_STATS = pd.read_json(FN_IN, orient = 'split')\n",
    "\n",
    "# Set scale\n",
    "scale = 10**9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303178\n",
      "303178\n"
     ]
    }
   ],
   "source": [
    "# Drop cites where 1983 had 1 day and none elsewhere\n",
    "\n",
    "print(len(HI_STATS))\n",
    "only83 = HI_STATS.groupby('ID_HDC_G0')['tot_days'].sum() == 1 # sum up total days and find those with 1 day\n",
    "only83 = list(only83[only83 == True].index) # make a list of IDs\n",
    "sub = HI_STATS[HI_STATS['ID_HDC_G0'].isin(only83)] # subset those IDs\n",
    "bad_ids = sub[(sub['year'] == 1983) & (sub['tot_days'] == 1)] # drop those from 1983 only\n",
    "drop_list = list(bad_ids['ID_HDC_G0']) # make a list\n",
    "HI_STATS= HI_STATS[~HI_STATS['ID_HDC_G0'].isin(drop_list)] # drop those from the list\n",
    "print(len(HI_STATS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Add In Meta Data (e.g. geographic data)\n",
    "meta_fn = os.path.join('/home/cascade/projects/UrbanHeat/data/interim/','GHS-UCDB-IDS.csv')\n",
    "meta_data = pd.read_csv(meta_fn)\n",
    "\n",
    "#### Merge in meta\n",
    "HI_STATS = HI_STATS.merge(meta_data, on = 'ID_HDC_G0', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>year</th>\n",
       "      <th>tot_days</th>\n",
       "      <th>P</th>\n",
       "      <th>P1983</th>\n",
       "      <th>P2016</th>\n",
       "      <th>people_days</th>\n",
       "      <th>people_days_heat</th>\n",
       "      <th>people_days_pop</th>\n",
       "      <th>CTR_MN_NM</th>\n",
       "      <th>UC_NM_MN</th>\n",
       "      <th>GCPNT_LAT</th>\n",
       "      <th>GCPNT_LON</th>\n",
       "      <th>region</th>\n",
       "      <th>sub-region</th>\n",
       "      <th>intermediate-region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>622283.428656</td>\n",
       "      <td>494664.495616</td>\n",
       "      <td>661553.577433</td>\n",
       "      <td>1.244567e+06</td>\n",
       "      <td>989328.991233</td>\n",
       "      <td>255237.866079</td>\n",
       "      <td>United States</td>\n",
       "      <td>Concord [USA]</td>\n",
       "      <td>37.913946</td>\n",
       "      <td>-122.048318</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Northern America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>70915.650551</td>\n",
       "      <td>52064.452435</td>\n",
       "      <td>73006.671133</td>\n",
       "      <td>1.418313e+05</td>\n",
       "      <td>104128.904869</td>\n",
       "      <td>37702.396233</td>\n",
       "      <td>United States</td>\n",
       "      <td>Livermore [USA]</td>\n",
       "      <td>37.688409</td>\n",
       "      <td>-121.753980</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Northern America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>247944.032154</td>\n",
       "      <td>194088.886834</td>\n",
       "      <td>268055.635628</td>\n",
       "      <td>7.438321e+05</td>\n",
       "      <td>582266.660503</td>\n",
       "      <td>161565.435959</td>\n",
       "      <td>United States</td>\n",
       "      <td>Antioch [USA]</td>\n",
       "      <td>37.985433</td>\n",
       "      <td>-121.797516</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Northern America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>90805.062622</td>\n",
       "      <td>80540.779940</td>\n",
       "      <td>93335.494324</td>\n",
       "      <td>1.816101e+05</td>\n",
       "      <td>161081.559880</td>\n",
       "      <td>20528.565365</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fairfield [USA]</td>\n",
       "      <td>38.264013</td>\n",
       "      <td>-122.030253</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Northern America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>68062.052369</td>\n",
       "      <td>59320.971209</td>\n",
       "      <td>91449.606255</td>\n",
       "      <td>6.806205e+04</td>\n",
       "      <td>59320.971209</td>\n",
       "      <td>8741.081160</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tracy [USA]</td>\n",
       "      <td>37.730079</td>\n",
       "      <td>-121.431413</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Northern America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303173</td>\n",
       "      <td>13135</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132501.788370</td>\n",
       "      <td>211650.696320</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>Suva [FJI]</td>\n",
       "      <td>-18.104802</td>\n",
       "      <td>178.461255</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>Melanesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303174</td>\n",
       "      <td>13135</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132501.788370</td>\n",
       "      <td>211650.696320</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>Suva [FJI]</td>\n",
       "      <td>-18.104802</td>\n",
       "      <td>178.461255</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>Melanesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303175</td>\n",
       "      <td>13135</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132501.788370</td>\n",
       "      <td>211650.696320</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>Suva [FJI]</td>\n",
       "      <td>-18.104802</td>\n",
       "      <td>178.461255</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>Melanesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303176</td>\n",
       "      <td>13135</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132501.788370</td>\n",
       "      <td>211650.696320</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>Suva [FJI]</td>\n",
       "      <td>-18.104802</td>\n",
       "      <td>178.461255</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>Melanesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303177</td>\n",
       "      <td>13135</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132501.788370</td>\n",
       "      <td>211650.696320</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>Suva [FJI]</td>\n",
       "      <td>-18.104802</td>\n",
       "      <td>178.461255</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>Melanesia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303178 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_HDC_G0  year  tot_days              P          P1983  \\\n",
       "0              18  2006         2  622283.428656  494664.495616   \n",
       "1              22  2006         2   70915.650551   52064.452435   \n",
       "2              26  2006         3  247944.032154  194088.886834   \n",
       "3              27  2006         2   90805.062622   80540.779940   \n",
       "4              28  1998         1   68062.052369   59320.971209   \n",
       "...           ...   ...       ...            ...            ...   \n",
       "303173      13135  2010         0            NaN  132501.788370   \n",
       "303174      13135  2011         0            NaN  132501.788370   \n",
       "303175      13135  2012         0            NaN  132501.788370   \n",
       "303176      13135  2013         0            NaN  132501.788370   \n",
       "303177      13135  2014         0            NaN  132501.788370   \n",
       "\n",
       "                P2016   people_days  people_days_heat  people_days_pop  \\\n",
       "0       661553.577433  1.244567e+06     989328.991233    255237.866079   \n",
       "1        73006.671133  1.418313e+05     104128.904869     37702.396233   \n",
       "2       268055.635628  7.438321e+05     582266.660503    161565.435959   \n",
       "3        93335.494324  1.816101e+05     161081.559880     20528.565365   \n",
       "4        91449.606255  6.806205e+04      59320.971209      8741.081160   \n",
       "...               ...           ...               ...              ...   \n",
       "303173  211650.696320  0.000000e+00          0.000000         0.000000   \n",
       "303174  211650.696320  0.000000e+00          0.000000         0.000000   \n",
       "303175  211650.696320  0.000000e+00          0.000000         0.000000   \n",
       "303176  211650.696320  0.000000e+00          0.000000         0.000000   \n",
       "303177  211650.696320  0.000000e+00          0.000000         0.000000   \n",
       "\n",
       "            CTR_MN_NM         UC_NM_MN  GCPNT_LAT   GCPNT_LON    region  \\\n",
       "0       United States    Concord [USA]  37.913946 -122.048318  Americas   \n",
       "1       United States  Livermore [USA]  37.688409 -121.753980  Americas   \n",
       "2       United States    Antioch [USA]  37.985433 -121.797516  Americas   \n",
       "3       United States  Fairfield [USA]  38.264013 -122.030253  Americas   \n",
       "4       United States      Tracy [USA]  37.730079 -121.431413  Americas   \n",
       "...               ...              ...        ...         ...       ...   \n",
       "303173           Fiji       Suva [FJI] -18.104802  178.461255   Oceania   \n",
       "303174           Fiji       Suva [FJI] -18.104802  178.461255   Oceania   \n",
       "303175           Fiji       Suva [FJI] -18.104802  178.461255   Oceania   \n",
       "303176           Fiji       Suva [FJI] -18.104802  178.461255   Oceania   \n",
       "303177           Fiji       Suva [FJI] -18.104802  178.461255   Oceania   \n",
       "\n",
       "              sub-region intermediate-region  \n",
       "0       Northern America    Northern America  \n",
       "1       Northern America    Northern America  \n",
       "2       Northern America    Northern America  \n",
       "3       Northern America    Northern America  \n",
       "4       Northern America    Northern America  \n",
       "...                  ...                 ...  \n",
       "303173         Melanesia           Melanesia  \n",
       "303174         Melanesia           Melanesia  \n",
       "303175         Melanesia           Melanesia  \n",
       "303176         Melanesia           Melanesia  \n",
       "303177         Melanesia           Melanesia  \n",
       "\n",
       "[303178 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " HI_STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTR_MN_NM</th>\n",
       "      <th>UC_NM_MN</th>\n",
       "      <th>year</th>\n",
       "      <th>tot_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>52805</td>\n",
       "      <td>Eritrea</td>\n",
       "      <td>Mits'Iwa [ERI]</td>\n",
       "      <td>2016</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52791</td>\n",
       "      <td>Eritrea</td>\n",
       "      <td>Mits'Iwa [ERI]</td>\n",
       "      <td>2002</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52804</td>\n",
       "      <td>Eritrea</td>\n",
       "      <td>Mits'Iwa [ERI]</td>\n",
       "      <td>2015</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52799</td>\n",
       "      <td>Eritrea</td>\n",
       "      <td>Mits'Iwa [ERI]</td>\n",
       "      <td>2010</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52792</td>\n",
       "      <td>Eritrea</td>\n",
       "      <td>Mits'Iwa [ERI]</td>\n",
       "      <td>2003</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CTR_MN_NM        UC_NM_MN  year  tot_days\n",
       "52805   Eritrea  Mits'Iwa [ERI]  2016       255\n",
       "52791   Eritrea  Mits'Iwa [ERI]  2002       254\n",
       "52804   Eritrea  Mits'Iwa [ERI]  2015       248\n",
       "52799   Eritrea  Mits'Iwa [ERI]  2010       244\n",
       "52792   Eritrea  Mits'Iwa [ERI]  2003       243"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Check to num days per year greatest > 32\n",
    "check = HI_STATS.sort_values('tot_days', ascending = False)\n",
    "check[['CTR_MN_NM', 'UC_NM_MN', 'year', 'tot_days']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person days in 2016 was 118.6608238905162 billion\n",
      "person days in 1983 was 39.691073649233786 billion\n",
      "pct increase in people days 83 - 16 is  198.960982862722\n"
     ]
    }
   ],
   "source": [
    "#### Total Change in people Days\n",
    "data = HI_STATS.groupby('year')['people_days'].sum()\n",
    "year = str(data.index[33])\n",
    "value = str(data.values[33]/10**9)\n",
    "print('person days in 2016 was '+value+' billion')\n",
    "\n",
    "year = str(data.index[0])\n",
    "value = str(data.values[0]/10**9)\n",
    "print('person days in 1983 was '+value+' billion')\n",
    "\n",
    "#### Pct Change in Poeple Days 1983 - 2016\n",
    "pdays16 = data.iloc[len(data) -1]\n",
    "pdays83 = data.iloc[0]\n",
    "out = (data.iloc[len(data) -1] - data.iloc[0]) / data.iloc[0] * 100\n",
    "print('pct increase in people days 83 - 16 is ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual increase in people days  was 2.108968631  p= 0.0\n",
      "annual increase in people days heat  was 0.716240045  p= 0.0\n",
      "annual increase in people days pop  was 1.392728586  p= 0.0\n",
      "attrib heat  was 33.96162628840922  p= 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Rate of change\n",
    "data = HI_STATS\n",
    "coef, r2, p = lm_func(data, 'people_days')\n",
    "print('annual increase in people days ', 'was', coef/10**9, ' p=', p)\n",
    "coef1, r21, p1 = lm_func(data, 'people_days_heat')\n",
    "print('annual increase in people days heat ', 'was', coef1/10**9, ' p=', p)\n",
    "coef2, r22, p2 = lm_func(data, 'people_days_pop')\n",
    "print('annual increase in people days pop ', 'was', coef2/10**9, ' p=', p)\n",
    "print('attrib heat ', 'was', coef1 / coef *100, ' p=', p, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warming is what pct of total? 33.96162628840922\n"
     ]
    }
   ],
   "source": [
    "#### Pct Pday Annual Increase from Heat\n",
    "coef_pdays, r2_pdays, p_pdays = lm_func(HI_STATS, 'people_days') # regress pdays\n",
    "coef_heat, r2_heat, p_heat = lm_func(HI_STATS, 'people_days_heat') # regreas heat\n",
    "\n",
    "print('warming is what pct of total?', coef_heat/coef_pdays *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct of heat vs pop 51.42710878485551\n"
     ]
    }
   ],
   "source": [
    "#### Pct heat vs pop\n",
    "coef_pop, r2_pdays, p_pdays = lm_func(HI_STATS, 'people_days_pop') # regress pdays\n",
    "coef_heat, r2_heat, p_heat = lm_func(HI_STATS, 'people_days_heat') # regreas heat\n",
    "\n",
    "print('pct of heat vs pop', coef_heat/coef_pop *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Largest cities compared to global total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Top cities\n",
    "cities = pd.read_csv(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_EXP-TOP50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = cities.sort_values('coef_pdays', ascending = False).head(25) # get the top ten cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What pct of the global annual increase comes from the top 25 cities?\n",
    "ans = top['coef_pdays'].sum() / coef # coef comes from rate of change cell\n",
    "print('Top 25 cities of total annual increase', ans * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coefs = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_EXP05.json', orient = 'split')\n",
    "GHS = gpd.read_file('/home/cascade/projects/UrbanHeat/data/raw/GHS_UCDB/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(city_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Number of cities w/ sig increase in exposure?\n",
    "print('The pct of cities w/ increases in exposure: ', len(city_coefs)/len(GHS)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(city_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans = len(city_coefs[(city_coefs['GCPNT_LAT'] < 23.5) & (city_coefs['GCPNT_LAT'] > -23.5)]) / len(city_coefs)\n",
    "print('what pct of pday cities are low lat?', ans*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('what pct of global pop are cities with sig pdays?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_search(country, data_set):\n",
    "    \"what pct of cities had a p-day increase?\"\n",
    "    print('Num of Cities in '+country+' ', len(data_set[data_set['CTR_MN_NM'] == country]) / len(GHS[GHS['CTR_MN_NM'] == country]) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = city_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_search('Senegal', data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_search('Nigeria', data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_search('India', data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pct of global population exposured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coefs = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_EXP05.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(DATA_IN+'interim/GHS-UCDB-Interp.csv')\n",
    "p16 = pop[['ID_HDC_G0', 'P2016']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(p16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdays_pop = pd.merge(city_coefs[['ID_HDC_G0']], p16, on = 'ID_HDC_G0', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pdays_pop['P2016'].sum() / p16['P2016'].sum() * 100 \n",
    "print('What is the global urban population in 2016', p16['P2016'].sum())\n",
    "print('How many people live in cities with increasing exp in 2016', pdays_pop['P2016'].sum())\n",
    "print('What pct of total urban pop has sig increase exp in 2015', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From UN-DESA 2018 estimates for total global pop in 2015\n",
    "ans =  pdays_pop['P2016'].sum() / 7383009000 * 100\n",
    "print('What pct of total world pop has sig increase exp in 2016', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UN-DESA Urban pop in 2015 was  3 981 498\n",
    "p16['P2016'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Heat Days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_totdays = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_HEATP05.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('What pct of all cities had sig increase in days/yr > WBGT32 C ?')\n",
    "print(len(city_totdays)/len(GHS))\n",
    "print(len(city_totdays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('What pct of all cities >1 day / yr in days/yr > WBGT32 C ?')\n",
    "print(len(city_totdays[city_totdays['coef_totDays'] >= 1])/len(GHS))\n",
    "print(len(city_totdays[city_totdays['coef_totDays'] >= 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many cities day increase per year ... 1, 3\n",
    "top = len(city_totdays)\n",
    "bottom = len(city_totdays[city_totdays['coef_totDays'] >= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(top)\n",
    "print(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are some big cities (>1m people)?\n",
    "hot1m = city_totdays[(city_totdays['coef_totDays'] >= 1.5) & (city_totdays['P2016'] >= 10**6)][['coef_totDays', 'UC_NM_MN', 'P2016']].sort_values('coef_totDays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hot1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dehli & Kolkata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi 6955 & Kolkata 9691\n",
    "K = city_coefs[city_coefs['ID_HDC_G0']== 9691]\n",
    "D = city_coefs[city_coefs['ID_HDC_G0']== 6955]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Share of heat Kolkata', K.coef_heat / K.coef_pdays * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Share of heat Delhi', D.coef_heat / D.coef_pdays * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populations of specific cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(DATA_IN+'interim/GHS-UCDB-Interp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9691, Kolkata 1998\n",
    "# 2046, Paris 2003\n",
    "# 4417, Aleppo 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pop[pop['ID_HDC_G0'] == 9691]['P2015'] / 10**3\n",
    "print('Pop of Kolkata in 1998', ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WBGT 32 vs 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbgt32 = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_EXP05.json', orient = 'split')\n",
    "wbgt28 = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT28_1D_TREND_EXP05.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('how many cities wbgt 32?', len(wbgt32))\n",
    "print('how many cities wbgt 28?', len(wbgt28))\n",
    "print('no trend', len(meta_data) - 8510)\n",
    "print('dif is', 8510 - 6022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Annual Rates\n",
    "\n",
    "scale = 10**6\n",
    "geog = 'sub-region'\n",
    "\n",
    "for label in np.unique(HI_STATS[geog]):\n",
    "    label = label\n",
    "    data = HI_STATS[HI_STATS[geog] == label]\n",
    "    \n",
    "    #### Rate of change\n",
    "    coef, r2, p = lm_func(data, 'people_days')\n",
    "    print('annual increase in people days '+label, 'was', coef/scale, ' p=', p)\n",
    "    coef1, r21, p1 = lm_func(data, 'people_days_heat')\n",
    "    print('annual increase in people days heat '+label, 'was', coef1/scale, ' p=', p)\n",
    "    coef2, r22, p2 = lm_func(data, 'people_days_pop')\n",
    "    print('annual increase in people days pop '+label, 'was', coef2/scale, ' p=', p)\n",
    "    print('attrib heat '+label, 'was', coef1 / coef *100, ' p=', p, '\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Trends for Africa, N & SS\n",
    "geog = 'region'\n",
    "location = 'Africa'\n",
    "data = HI_STATS[HI_STATS[geog] == location]\n",
    "print(location)\n",
    "\n",
    "#### Total Change in people Days\n",
    "data = data.groupby('year')['people_days'].sum()\n",
    "year = str(data.index[33])\n",
    "value = str(data.values[33]/10**9)\n",
    "print('person days in 2016 was '+value+' billion')\n",
    "\n",
    "year = str(data.index[0])\n",
    "value = str(data.values[0]/10**9)\n",
    "print('person days in 1983 was '+value+' billion')\n",
    "\n",
    "#### Pct Change in Poeple Days 1983 - 2016\n",
    "pdays16 = data.iloc[len(data) -1]\n",
    "pdays83 = data.iloc[0]\n",
    "out = (data.iloc[len(data) -1] - data.iloc[0]) / data.iloc[0] * 100\n",
    "print('pct increase in people days 83 - 16 is ', out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### S Asia as pct of total  global = 5.245146271 B \n",
    "\n",
    "print('pct of total pdays from S Asia is ', 1899.70765 / 10**3 / 5.245146271 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Median Slope\n",
    "region = 'Europe'\n",
    "col = 'coef_heat'\n",
    "geog = 'region'\n",
    "scale = 10**3\n",
    "result = city_coefs[city_coefs[geog]== region][col].median()\n",
    "print(region, col, 'is ', result/scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Waves\n",
    "\n",
    "- 9691 Kolkata 1998\n",
    "- 2046 Paris 2003\n",
    "- 4417, Aleppo 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dir_in, geog, location):\n",
    "    \"\"\"Function makes data to plot daily city-level HI Max and average\n",
    "    Args:\n",
    "        dir_in = directory to get data\n",
    "        geog = column for geography, city-level = 'ID_HDC_G0'\n",
    "        location = usually a city id\n",
    "    \"\"\"\n",
    "    \n",
    "    fn_list = sorted(glob.glob(dir_in+'*.csv')) # get data\n",
    "    df_out = pd.DataFrame() # to write dataframe\n",
    "    \n",
    "     # get leap year cols from 2016\n",
    "    hi16 = pd.read_csv(fn_list[33]) \n",
    "    cols = list(hi16.iloc[:,3:].columns)\n",
    "    cols = [year[5:] for year in cols] # cols for data frame\n",
    "    \n",
    "    temp_list = [] # empty list for temps\n",
    "    \n",
    "    # loop through dir and get data\n",
    "    for i, fn in enumerate(fn_list):\n",
    "        df = pd.read_csv(fn) # open data frame\n",
    "        year_label = [(df.columns[3]).split('.')[0]] # get year\n",
    "        row = df[df[geog] == location]\n",
    "        temp = row.iloc[:,3:] # get only temp columns\n",
    "        \n",
    "        # add in col for leap years\n",
    "        if temp.shape[1] == 365:\n",
    "            temp.insert(loc = 59, column = year_label[0]+'.02.29', value = np.nan, allow_duplicates=False)\n",
    "\n",
    "        # Set Index & Columns\n",
    "        temp.index = year_label\n",
    "        temp.columns = cols # revalue to m.d\n",
    "    \n",
    "        # add to list\n",
    "        temp_list.append(temp)\n",
    "    \n",
    "    df_out = pd.concat(temp_list) # make one big dataframe\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, year, start, end):#, start, end):\n",
    "    \"\"\" Make the data for a plot\n",
    "    Args: \n",
    "        df = df w/ daily HI max for a given city\n",
    "        year = year you want to plot against average\n",
    "        start = start of plot in julian days (e.g 1 - 365/366)\n",
    "        end = end of plot in julian days\n",
    "    \"\"\"\n",
    "\n",
    "    # Deal with leap year\n",
    "    if year % 4 !=0:\n",
    "        df.drop(columns ='02.29', inplace = True)\n",
    "    \n",
    "    # Subset data\n",
    "    start = start - 1 # zero indexing \n",
    "    subset = df.iloc[:,start:end]\n",
    "    \n",
    "    # HI Max for year\n",
    "    hi_year = subset.loc[str(year)]\n",
    "    \n",
    "    # make 34-avg daily hi\n",
    "    means = subset.mean(axis = 0)\n",
    "    \n",
    "    # make colums to date time\n",
    "    cols = pd.to_datetime([str(year)+'.'+date for date in hi_year.index])\n",
    "    \n",
    "    return hi_year, means, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Heat Wave From All DATA\n",
    "def select_city_year(df, city_id, year):\n",
    "    \"Quick search to find city and years within HI_STATS\"\n",
    "    df_out = df[(df['ID_HDC_G0'] == city_id) & (df['year'] == year)]\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "# open heat events data\n",
    "events_fn = '/home/cascade/projects/UrbanHeat/data/processed/PNAS-DATA-v2/HI461_1D_STATS.json'\n",
    "events = pd.read_json(events_fn, orient = 'split')\n",
    "\n",
    "# [4417, 'Aleppo'] [2046, 'Paris'] [9691, 'Kolkata'] \n",
    "city = select_city_year(events, 4417, 2010)\n",
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select event and compare to long term means\n",
    "# Kolkata 1998 UID-2920905, Aleppo 2010 \n",
    "event_id = 'UID-2920905'\n",
    "event = city[city['UID'] == event_id]\n",
    "tmax = list(event['tmax'])[0]\n",
    "dates = list(event['event_dates'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Heat Index Data\n",
    "data = 'HI'\n",
    "DATA_IN = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS_DAILY/'+data+'/' # output from avg temp\n",
    "t = 46.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get long term means\n",
    "# Args\n",
    "#[4417, 'Aleppo'] 2010 [2046, 'Paris'] 2003 [9691, 'Kolkata'] 1998 ['6955, Dehli']\n",
    "\n",
    "# Args\n",
    "city_list = [4417, 'Aleppo'] \n",
    "year = 2010\n",
    "\n",
    "# April 1 to Sep 30 (Use Julian Days), or 1 - 182 lagos\n",
    "start = 91 \n",
    "end = 273\n",
    "\n",
    "# Make Data \n",
    "df = make_data(DATA_IN, 'ID_HDC_G0', city_list[0])\n",
    "years, means, cols = plot_data(df, year, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df\n",
    "df = pd.DataFrame()\n",
    "df['dates'] = cols\n",
    "df['max']  = years.to_list()\n",
    "df['avg'] = means.to_list()\n",
    "df['dif'] = df['max'] - df['avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['dates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dates[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start and end of heat wave\n",
    "start = dates[0]\n",
    "end = dates[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df[(df['dates'] >= start) & (df['dates'] <= end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['dif'] == out['dif'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoenix Caclulations\n",
    "1990-6-26 Phoenix, AZ Weather History. https://www.wunderground.com/history/daily/KPHX/date/1990-6-26. Weather Underground. (June 10, 2021).<br>A. Minkler, At 118 degrees, Thursday heat in Phoenix breaks daily record set in 1934. The Arizona Republic (2020) (June 18, 2021).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def c_to_f(C):\n",
    "    \"Convert HI C to F\"\n",
    "    return 1.8 * C + 32 \n",
    "\n",
    "def hi_to_wbgt(HI):\n",
    "    \"\"\" Convert HI to WBGT using emprical relationship from Bernard and Iheanacho 2015\n",
    "    WBGT [◦C] = −0.0034 HI2 + 0.96 HI−34; for HI [◦F]\n",
    "    \"\"\"\n",
    "    \n",
    "    WBGT = -0.0034*HI**2 + 0.96*HI - 34\n",
    "    \n",
    "    return WBGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmax was 122, rh was 11 using https://www.wpc.ncep.noaa.gov/html/heatindex.shtml\n",
    "# then HI was 49 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_city_year(df, city_id, year):\n",
    "    \"Quick search to find city and years within HI_STATS\"\n",
    "    df_out = df[(df['ID_HDC_G0'] == city_id) & (df['year'] == year)]\n",
    "    \n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = select_city_year(ALL_DATA, 4417, 2010)\n",
    "city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = '/home/cascade/projects/UrbanHeat/data/interim/ERA5_HI/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'GHS-ERA5-HI_2009.csv'\n",
    "data = pd.read_csv(dir_list+fn)\n",
    "city = data[data['ID_HDC_G0'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_list = []\n",
    "dates_list = []\n",
    "for fn in sorted(os.listdir(dir_list)):\n",
    "    data = pd.read_csv(dir_list+fn)\n",
    "    city = data[data['ID_HDC_G0'] == 14]\n",
    "    dates = list(city.iloc[:,3:])\n",
    "    temps = list(city.iloc[:,3:].values[0])\n",
    "    dates_list.extend(dates)\n",
    "    temps_list.extend(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(dates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dependencies\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dir_in, geog, location):\n",
    "    \"\"\"Function makes data to plot daily city-level HI Max and average\n",
    "    Args:\n",
    "        dir_in = directory to get data\n",
    "        geog = column for geography, city-level = 'ID_HDC_G0'\n",
    "        location = usually a city id\n",
    "    \"\"\"\n",
    "    \n",
    "    fn_list = sorted(glob.glob(dir_in+'*.csv')) # get data\n",
    "    df_out = pd.DataFrame() # to write dataframe\n",
    "    \n",
    "     # get leap year cols from 2016\n",
    "    hi16 = pd.read_csv(fn_list[33]) \n",
    "    cols = list(hi16.iloc[:,3:].columns)\n",
    "    cols = [year[5:] for year in cols] # cols for data frame\n",
    "    \n",
    "    temp_list = [] # empty list for temps\n",
    "    \n",
    "    # loop through dir and get data\n",
    "    for i, fn in enumerate(fn_list):\n",
    "        df = pd.read_csv(fn) # open data frame\n",
    "        year_label = [(df.columns[3]).split('.')[0]] # get year\n",
    "        row = df[df[geog] == location]\n",
    "        temp = row.iloc[:,3:] # get only temp columns\n",
    "        \n",
    "        # add in col for leap years\n",
    "        if temp.shape[1] == 365:\n",
    "            temp.insert(loc = 59, column = year_label[0]+'.02.29', value = np.nan, allow_duplicates=False)\n",
    "\n",
    "        # Set Index & Columns\n",
    "        temp.index = year_label\n",
    "        temp.columns = cols # revalue to m.d\n",
    "    \n",
    "        # add to list\n",
    "        temp_list.append(temp)\n",
    "    \n",
    "    df_out = pd.concat(temp_list) # make one big dataframe\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, year, start, end):#, start, end):\n",
    "    \"\"\" Make the data for a plot\n",
    "    Args: \n",
    "        df = df w/ daily HI max for a given city\n",
    "        year = year you want to plot against average\n",
    "        start = start of plot in julian days (e.g 1 - 365/366)\n",
    "        end = end of plot in julian days\n",
    "    \"\"\"\n",
    "\n",
    "    # Deal with leap year\n",
    "    if year % 4 !=0:\n",
    "        df.drop(columns ='02.29', inplace = True)\n",
    "    \n",
    "    # Subset data\n",
    "    start = start - 1 # zero indexing \n",
    "    subset = df.iloc[:,start:end]\n",
    "    \n",
    "    # HI Max for year\n",
    "    hi_year = subset.loc[str(year)]\n",
    "    \n",
    "    # make 34-avg daily hi\n",
    "    means = subset.mean(axis = 0)\n",
    "    \n",
    "    # make colums to date time\n",
    "    cols = pd.to_datetime([str(year)+'.'+date for date in hi_year.index])\n",
    "    \n",
    "    return hi_year, means, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "#[3342, 'Cairo'] #[1910, 'Accra'] 3268, Cape Town\n",
    "#[4417, 'Aleppo'] 2010 [2046, 'Paris'] 2003 [9691, 'Kolkata'] 1998 ['6955, Dehli']\n",
    "\n",
    "# Args\n",
    "city_list = [9691, 'Kolkata'] \n",
    "year = 1998\n",
    "font_size = 10\n",
    "\n",
    "\n",
    "# April 1 to Sep 30 (Use Julian Days), or 1 - 182 lagos\n",
    "start = 91 \n",
    "end = 273\n",
    "\n",
    "# Labels\n",
    "hi_label = str(year)+' '+data\n",
    "labels =  ['avg. '+data, hi_label, str(t)+''+DS+'C']  # <<<<<------------ Be sure to update! \n",
    "\n",
    "# Make Data \n",
    "df = make_data(DATA_IN, 'ID_HDC_G0', city_list[0])\n",
    "years, means, cols = plot_data(df, year, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend First vs. Second Half of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Share of exposure due to heat by 17 year split\n",
    "\n",
    "## 1983 - 1999\n",
    "data1 = HI_STATS[(HI_STATS['year'] >= 1983) & (HI_STATS['year'] < 2000)]\n",
    "coef1pop , r21pop, p1pop  = lm_func(data1 , 'people_days_pop')\n",
    "coef1heat , r21heat, p1heat = lm_func(data1 , 'people_days_heat')\n",
    "\n",
    "years = list(np.unique(data1['year']))\n",
    "plt.plot(years, data1.groupby('year')['people_days_heat'].sum())\n",
    "sns.regplot(years, data1.groupby('year')['people_days_heat'].sum(), \n",
    "            color = 'blue', scatter = False, truncate = True)\n",
    "\n",
    "## 2000 - 2016\n",
    "data2 = HI_STATS[(HI_STATS['year'] >= 2000) & (HI_STATS['year'] <= 2016)]\n",
    "coef2heat , r22heat, p2heat = lm_func(data2 , 'people_days_heat')\n",
    "coef2pop , r22pop, p1pop  = lm_func(data2 , 'people_days_pop')\n",
    "\n",
    "years = list(np.unique(data1['year']))\n",
    "plt.plot(years, data2.groupby('year')['people_days_heat'].sum())\n",
    "sns.regplot(years, data2.groupby('year')['people_days_heat'].sum(), \n",
    "            color = 'orange', scatter = False, truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2000 - 2016\n",
    "data2pop = HI_STATS[(HI_STATS['year'] >= 1983) & (HI_STATS['year'] < 2000)]\n",
    "coef2pop , r22pop, p1pop  = lm_func(data2pop , 'people_days_pop')\n",
    "\n",
    "data2heat = HI_STATS[(HI_STATS['year'] >= 2000) & (HI_STATS['year'] <= 2016)]\n",
    "coef2heat , r22heat, p2heat = lm_func(data2heat , 'people_days_heat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Estimates\n",
    "print('From 83 - 99, contribution from heat was', coef1heat/(coef1pop+coef1heat))\n",
    "print('From 00 - 16, contribution from heat was', coef2heat/(coef2pop+coef2heat))\n",
    "print('From 83 - 00, heat was', coef1heat/10**9, round(p1heat, 3))\n",
    "print('From 00 - 16, heat was', coef2heat/10**9)\n",
    "print('From 83 - 00, pop was', coef1pop/10**9)\n",
    "print('From 00 - 16, pop was', coef2pop/10**9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
