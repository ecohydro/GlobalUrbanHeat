{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS Calculations\n",
    "\n",
    "Notebook to crunch numbers for the MS.\n",
    "\n",
    "by Cascade Tuholske 2020.02.23 \n",
    "\n",
    "Updated 2020.08.27 - CPT\n",
    "Was run on ERA5 RH with CHIRTS-Daily Tmax from ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Depdencies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Regressions, no intercept addition is needed because we're using SK LEARN HERE \n",
    "\n",
    "def lm_func(df, col):\n",
    "    \n",
    "    \"simple linear model of a time series data, returns coef\"\n",
    "    \n",
    "    # Get Data\n",
    "    X_year = np.array(df.groupby('year')['ID_HDC_G0'].mean().index).reshape((-1, 1))\n",
    "    Y_stats = np.array(df.groupby('year')[col].sum()).reshape((-1, 1))\n",
    "\n",
    "    # Add Intercept\n",
    "    X_year_2 = sm.add_constant(X_year)\n",
    "\n",
    "    # Regress\n",
    "    model = sm.OLS(Y_stats, X_year_2).fit() \n",
    "        \n",
    "    coef = int(model.params[1])\n",
    "    #coef = int(coef)\n",
    "            \n",
    "    # R2 and P\n",
    "    r2 = model.rsquared_adj\n",
    "    p = model.pvalues[0]\n",
    "    \n",
    "    return coef, round(r2, 2), round(p, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Data\n",
    "DATA = 'WBGT32_1D' # UPDATE \n",
    "\n",
    "# file paths\n",
    "DATA_IN = \"/home/cascade/projects/UrbanHeat/data/\"  \n",
    "FIG_OUT = \"/home/cascade/projects/UrbanHeat/figures/\"\n",
    "FN_IN = 'processed/PNAS-DATA-v2/'+DATA+'_EXP.json'\n",
    "HI_STATS = pd.read_json(DATA_IN+FN_IN, orient = 'split')\n",
    "\n",
    "# Set scale\n",
    "scale = 10**9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322082\n",
      "321538\n"
     ]
    }
   ],
   "source": [
    "# Drop cites where 1983 had 1 day and none elsewhere\n",
    "\n",
    "print(len(HI_STATS))\n",
    "only83 = HI_STATS.groupby('ID_HDC_G0')['tot_days'].sum() == 1 # sum up total days and find those with 1 day\n",
    "only83 = list(only83[only83 == True].index) # make a list of IDs\n",
    "sub = HI_STATS[HI_STATS['ID_HDC_G0'].isin(only83)] # subset those IDs\n",
    "bad_ids = sub[(sub['year'] == 1983) & (sub['tot_days'] == 1)] # drop those from 1983 only\n",
    "drop_list = list(bad_ids['ID_HDC_G0']) # make a list\n",
    "HI_STATS= HI_STATS[~HI_STATS['ID_HDC_G0'].isin(drop_list)] # drop those from the list\n",
    "print(len(HI_STATS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Add In Meta Data (e.g. geographic data)\n",
    "meta_fn = DATA_IN+'interim/GHS-UCDB-IDS.csv'\n",
    "meta_data = pd.read_csv(meta_fn)\n",
    "\n",
    "#### Merge in meta\n",
    "HI_STATS = HI_STATS.merge(meta_data, on = 'ID_HDC_G0', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTR_MN_NM</th>\n",
       "      <th>UC_NM_MN</th>\n",
       "      <th>year</th>\n",
       "      <th>tot_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>215647</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Pekan Baru [IDN]</td>\n",
       "      <td>2016</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67759</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Samitah [SAU]</td>\n",
       "      <td>2002</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67770</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Samitah [SAU]</td>\n",
       "      <td>2013</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217682</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Telukkepik [IDN]</td>\n",
       "      <td>2016</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67843</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>Harad [YEM]</td>\n",
       "      <td>2002</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CTR_MN_NM          UC_NM_MN  year  tot_days\n",
       "215647     Indonesia  Pekan Baru [IDN]  2016       228\n",
       "67759   Saudi Arabia     Samitah [SAU]  2002       223\n",
       "67770   Saudi Arabia     Samitah [SAU]  2013       222\n",
       "217682     Indonesia  Telukkepik [IDN]  2016       221\n",
       "67843          Yemen       Harad [YEM]  2002       220"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Check to num days per year greatest > 32\n",
    "check = HI_STATS.sort_values('tot_days', ascending = False)\n",
    "check[['CTR_MN_NM', 'UC_NM_MN', 'year', 'tot_days']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person days in 2016 was 125.6137485348937 billion\n",
      "person days in 1983 was 44.458472045749346 billion\n",
      "pct increase in people days 83 - 16 is  182.54175808298746\n"
     ]
    }
   ],
   "source": [
    "#### Total Change in people Days\n",
    "data = HI_STATS.groupby('year')['people_days'].sum()\n",
    "year = str(data.index[33])\n",
    "value = str(data.values[33]/10**9)\n",
    "print('person days in 2016 was '+value+' billion')\n",
    "\n",
    "year = str(data.index[0])\n",
    "value = str(data.values[0]/10**9)\n",
    "print('person days in 1983 was '+value+' billion')\n",
    "\n",
    "#### Pct Change in Poeple Days 1983 - 2016\n",
    "pdays16 = data.iloc[len(data) -1]\n",
    "pdays83 = data.iloc[0]\n",
    "out = (data.iloc[len(data) -1] - data.iloc[0]) / data.iloc[0] * 100\n",
    "print('pct increase in people days 83 - 16 is ', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual increase in people days  was 2.217374507  p= 0.0\n",
      "annual increase in people days heat  was 0.727456266  p= 0.0\n",
      "annual increase in people days pop  was 1.48991824  p= 0.0\n",
      "attrib heat  was 32.807099734551066  p= 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Rate of change\n",
    "data = HI_STATS\n",
    "coef, r2, p = lm_func(data, 'people_days')\n",
    "print('annual increase in people days ', 'was', coef/10**9, ' p=', p)\n",
    "coef1, r21, p1 = lm_func(data, 'people_days_heat')\n",
    "print('annual increase in people days heat ', 'was', coef1/10**9, ' p=', p)\n",
    "coef2, r22, p2 = lm_func(data, 'people_days_pop')\n",
    "print('annual increase in people days pop ', 'was', coef2/10**9, ' p=', p)\n",
    "print('attrib heat ', 'was', coef1 / coef *100, ' p=', p, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warming is what pct of total? 32.807099734551066\n"
     ]
    }
   ],
   "source": [
    "#### Pct Pday Annual Increase from Heat\n",
    "coef_pdays, r2_pdays, p_pdays = lm_func(HI_STATS, 'people_days') # regress pdays\n",
    "coef_heat, r2_heat, p_heat = lm_func(HI_STATS, 'people_days_heat') # regreas heat\n",
    "\n",
    "print('warming is what pct of total?', coef_heat/coef_pdays *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct of heat vs pop 48.82524735048548\n"
     ]
    }
   ],
   "source": [
    "#### Pct heat vs pop\n",
    "coef_pop, r2_pdays, p_pdays = lm_func(HI_STATS, 'people_days_pop') # regress pdays\n",
    "coef_heat, r2_heat, p_heat = lm_func(HI_STATS, 'people_days_heat') # regreas heat\n",
    "\n",
    "print('pct of heat vs pop', coef_heat/coef_pop *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Largest cities compared to global total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Top cities\n",
    "cities = pd.read_csv(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_EXP-TOP50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = cities.sort_values('coef_pdays', ascending = False).head(25) # get the top ten cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 cities of total annual increase 24.507137475575398\n"
     ]
    }
   ],
   "source": [
    "# What pct of the global annual increase comes from the top 25 cities?\n",
    "ans = top['coef_pdays'].sum() / coef # coef comes from rate of change cell\n",
    "print('Top 25 cities of total annual increase', ans * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coefs = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_EXP05.json', orient = 'split')\n",
    "GHS = gpd.read_file('/home/cascade/projects/UrbanHeat/data/raw/GHS_UCDB/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pct of cities w/ increases in exposure:  45.84697373429768\n"
     ]
    }
   ],
   "source": [
    "#### Number of cities w/ sig increase in exposure?\n",
    "print('The pct of cities w/ increases in exposure: ', len(city_coefs)/len(GHS)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6022"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what pct of pday cities are low lat? 50.94652939222849\n"
     ]
    }
   ],
   "source": [
    "ans = len(city_coefs[(city_coefs['GCPNT_LAT'] < 23.5) & (city_coefs['GCPNT_LAT'] > -23.5)]) / len(city_coefs)\n",
    "print('what pct of pday cities are low lat?', ans*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what pct of global pop are cities with sig pdays?\n"
     ]
    }
   ],
   "source": [
    "print('what pct of global pop are cities with sig pdays?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_search(country, data_set):\n",
    "    \"what pct of cities had a p-day increase?\"\n",
    "    print('Num of Cities in '+country+' ', len(data_set[data_set['CTR_MN_NM'] == country]) / len(GHS[GHS['CTR_MN_NM'] == country]) *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = city_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Cities in Senegal  93.93939393939394\n"
     ]
    }
   ],
   "source": [
    "country_search('Senegal', data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Cities in Nigeria  91.92546583850931\n"
     ]
    }
   ],
   "source": [
    "country_search('Nigeria', data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Cities in India  86.48399014778325\n"
     ]
    }
   ],
   "source": [
    "country_search('India', data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pct of global population exposured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coefs = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_EXP05.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(DATA_IN+'interim/GHS-UCDB-Interp.csv')\n",
    "p16 = pop[['ID_HDC_G0', 'P2016']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13135"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdays_pop = pd.merge(city_coefs[['ID_HDC_G0']], p16, on = 'ID_HDC_G0', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the global urban population in 2016 3535326298.5424414\n",
      "How many people live in cities with increasing exp in 2016 1661009084.2793088\n",
      "What pct of total urban pop has sig increase exp in 2015 46.983190348345396\n"
     ]
    }
   ],
   "source": [
    "ans = pdays_pop['P2016'].sum() / p16['P2016'].sum() * 100 \n",
    "print('What is the global urban population in 2016', p16['P2016'].sum())\n",
    "print('How many people live in cities with increasing exp in 2016', pdays_pop['P2016'].sum())\n",
    "print('What pct of total urban pop has sig increase exp in 2015', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What pct of total world pop has sig increase exp in 2016 22.49772530792403\n"
     ]
    }
   ],
   "source": [
    "# From UN-DESA 2018 estimates for total global pop in 2015\n",
    "ans =  pdays_pop['P2016'].sum() / 7383009000 * 100\n",
    "print('What pct of total world pop has sig increase exp in 2016', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3535326298.5424414"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UN-DESA Urban pop in 2015 was  3 981 498\n",
    "p16['P2016'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Heat Days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_totdays = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_HEATP05.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What pct of all cities had sig increase in days/yr > WBGT32 C ?\n",
      "0.38797106966121053\n",
      "5096\n"
     ]
    }
   ],
   "source": [
    "print('What pct of all cities had sig increase in days/yr > WBGT32 C ?')\n",
    "print(len(city_totdays)/len(GHS))\n",
    "print(len(city_totdays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What pct of all cities >1 day / yr in days/yr > WBGT32 C ?\n",
      "0.1884278644842025\n",
      "2475\n"
     ]
    }
   ],
   "source": [
    "print('What pct of all cities >1 day / yr in days/yr > WBGT32 C ?')\n",
    "print(len(city_totdays[city_totdays['coef_totDays'] >= 1])/len(GHS))\n",
    "print(len(city_totdays[city_totdays['coef_totDays'] >= 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many cities day increase per year ... 1, 3\n",
    "top = len(city_totdays)\n",
    "bottom = len(city_totdays[city_totdays['coef_totDays'] >= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print(top)\n",
    "print(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are some big cities (>1m people)?\n",
    "hot1m = city_totdays[(city_totdays['coef_totDays'] >= 1.5) & (city_totdays['P2016'] >= 10**6)][['coef_totDays', 'UC_NM_MN', 'P2016']].sort_values('coef_totDays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hot1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_totDays</th>\n",
       "      <th>UC_NM_MN</th>\n",
       "      <th>P2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5777</td>\n",
       "      <td>1.506952</td>\n",
       "      <td>Dhaka [BGD]</td>\n",
       "      <td>2.394235e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4872</td>\n",
       "      <td>1.519328</td>\n",
       "      <td>Patna [IND]</td>\n",
       "      <td>2.771973e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.522231</td>\n",
       "      <td>Ad-Dammam [SAU]</td>\n",
       "      <td>1.564432e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4871</td>\n",
       "      <td>1.528037</td>\n",
       "      <td>Muzaffarpur [IND]</td>\n",
       "      <td>1.435602e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3830</td>\n",
       "      <td>1.529412</td>\n",
       "      <td>Hardoi [IND]</td>\n",
       "      <td>1.185764e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3911</td>\n",
       "      <td>1.530634</td>\n",
       "      <td>Kanpur [IND]</td>\n",
       "      <td>3.773461e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>1.543468</td>\n",
       "      <td>Maiduguri [NGA]</td>\n",
       "      <td>1.069539e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1232</td>\n",
       "      <td>1.554927</td>\n",
       "      <td>Ihiala [NGA]</td>\n",
       "      <td>1.713471e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2403</td>\n",
       "      <td>1.558136</td>\n",
       "      <td>Ahvaz [IRN]</td>\n",
       "      <td>1.232269e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5824</td>\n",
       "      <td>1.565470</td>\n",
       "      <td>Brahman Bariya [BGD]</td>\n",
       "      <td>1.874156e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3733</td>\n",
       "      <td>1.569290</td>\n",
       "      <td>Farrukhabad [IND]</td>\n",
       "      <td>1.013702e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4363</td>\n",
       "      <td>1.575707</td>\n",
       "      <td>Madurai [IND]</td>\n",
       "      <td>1.872298e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1282</td>\n",
       "      <td>1.631016</td>\n",
       "      <td>Aba [NGA]</td>\n",
       "      <td>1.195860e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5634</td>\n",
       "      <td>1.637128</td>\n",
       "      <td>Bogra [BGD]</td>\n",
       "      <td>1.284400e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5599</td>\n",
       "      <td>1.674255</td>\n",
       "      <td>Kolkata (Calcutta) [IND]</td>\n",
       "      <td>2.162029e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5565</td>\n",
       "      <td>1.693659</td>\n",
       "      <td>Tamluk [IND]</td>\n",
       "      <td>1.540714e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5335</td>\n",
       "      <td>1.714897</td>\n",
       "      <td>Asansol [IND]</td>\n",
       "      <td>3.167486e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5687</td>\n",
       "      <td>1.753705</td>\n",
       "      <td>Sirajganj [BGD]</td>\n",
       "      <td>1.771424e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>1.782582</td>\n",
       "      <td>Al-Manamah (Manama) [BHR]</td>\n",
       "      <td>1.247787e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6003</td>\n",
       "      <td>1.786402</td>\n",
       "      <td>Mandalay [MMR]</td>\n",
       "      <td>1.825592e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5536</td>\n",
       "      <td>1.811459</td>\n",
       "      <td>Baharampur [IND]</td>\n",
       "      <td>1.131547e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6225</td>\n",
       "      <td>1.915050</td>\n",
       "      <td>Krung Thep (Bangkok) [THA]</td>\n",
       "      <td>1.473084e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>1.951719</td>\n",
       "      <td>Touba [SEN]</td>\n",
       "      <td>1.002133e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1137</td>\n",
       "      <td>1.974637</td>\n",
       "      <td>Benin City [NGA]</td>\n",
       "      <td>1.550239e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>2.695187</td>\n",
       "      <td>Maracaibo [VEN]</td>\n",
       "      <td>2.141737e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coef_totDays                    UC_NM_MN         P2016\n",
       "5777      1.506952                 Dhaka [BGD]  2.394235e+07\n",
       "4872      1.519328                 Patna [IND]  2.771973e+06\n",
       "2450      1.522231             Ad-Dammam [SAU]  1.564432e+06\n",
       "4871      1.528037           Muzaffarpur [IND]  1.435602e+06\n",
       "3830      1.529412                Hardoi [IND]  1.185764e+06\n",
       "3911      1.530634                Kanpur [IND]  3.773461e+06\n",
       "1580      1.543468             Maiduguri [NGA]  1.069539e+06\n",
       "1232      1.554927                Ihiala [NGA]  1.713471e+06\n",
       "2403      1.558136                 Ahvaz [IRN]  1.232269e+06\n",
       "5824      1.565470        Brahman Bariya [BGD]  1.874156e+06\n",
       "3733      1.569290           Farrukhabad [IND]  1.013702e+06\n",
       "4363      1.575707               Madurai [IND]  1.872298e+06\n",
       "1282      1.631016                   Aba [NGA]  1.195860e+06\n",
       "5634      1.637128                 Bogra [BGD]  1.284400e+06\n",
       "5599      1.674255    Kolkata (Calcutta) [IND]  2.162029e+07\n",
       "5565      1.693659                Tamluk [IND]  1.540714e+06\n",
       "5335      1.714897               Asansol [IND]  3.167486e+06\n",
       "5687      1.753705             Sirajganj [BGD]  1.771424e+06\n",
       "2460      1.782582   Al-Manamah (Manama) [BHR]  1.247787e+06\n",
       "6003      1.786402              Mandalay [MMR]  1.825592e+06\n",
       "5536      1.811459            Baharampur [IND]  1.131547e+06\n",
       "6225      1.915050  Krung Thep (Bangkok) [THA]  1.473084e+07\n",
       "648       1.951719                 Touba [SEN]  1.002133e+06\n",
       "1137      1.974637            Benin City [NGA]  1.550239e+06\n",
       "246       2.695187             Maracaibo [VEN]  2.141737e+06"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dehli & Kolkata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi 6955 & Kolkata 9691\n",
    "K = city_coefs[city_coefs['ID_HDC_G0']== 9691]\n",
    "D = city_coefs[city_coefs['ID_HDC_G0']== 6955]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of heat Kolkata 5599    50.402206\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Share of heat Kolkata', K.coef_heat / K.coef_pdays * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of heat Delhi 3201    23.607115\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Share of heat Delhi', D.coef_heat / D.coef_pdays * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populations of specific cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(DATA_IN+'interim/GHS-UCDB-Interp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9691, Kolkata 1998\n",
    "# 2046, Paris 2003\n",
    "# 4417, Aleppo 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop of Kolkata in 1998 7475    21620.289279\n",
      "Name: P2015, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ans = pop[pop['ID_HDC_G0'] == 9691]['P2015'] / 10**3\n",
    "print('Pop of Kolkata in 1998', ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WBGT 32 vs 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbgt32 = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT32_1D_TREND_EXP05.json', orient = 'split')\n",
    "wbgt28 = pd.read_json(DATA_IN+'processed/PNAS-DATA-v2/WBGT28_1D_TREND_EXP05.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many cities wbgt 32? 6022\n",
      "how many cities wbgt 28? 8510\n",
      "no trend 4625\n",
      "dif is 2488\n"
     ]
    }
   ],
   "source": [
    "print('how many cities wbgt 32?', len(wbgt32))\n",
    "print('how many cities wbgt 28?', len(wbgt28))\n",
    "print('no trend', len(meta_data) - 8510)\n",
    "print('dif is', 8510 - 6022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annual increase in people days Australia and New Zealand was 0.145165  p= 0.09\n",
      "annual increase in people days heat Australia and New Zealand was 0.062207  p= 0.09\n",
      "annual increase in people days pop Australia and New Zealand was 0.082957  p= 0.09\n",
      "attrib heat Australia and New Zealand was 42.85261598870251  p= 0.09 \n",
      "\n",
      "annual increase in people days Central Asia was 0.097638  p= 0.576\n",
      "annual increase in people days heat Central Asia was -0.059772  p= 0.576\n",
      "annual increase in people days pop Central Asia was 0.15741  p= 0.576\n",
      "attrib heat Central Asia was -61.21796841393719  p= 0.576 \n",
      "\n",
      "annual increase in people days Eastern Asia was 130.729143  p= 0.0\n",
      "annual increase in people days heat Eastern Asia was 34.095827  p= 0.0\n",
      "annual increase in people days pop Eastern Asia was 96.633316  p= 0.0\n",
      "attrib heat Eastern Asia was 26.081274777422813  p= 0.0 \n",
      "\n",
      "annual increase in people days Eastern Europe was 0.132212  p= 0.339\n",
      "annual increase in people days heat Eastern Europe was 0.098434  p= 0.339\n",
      "annual increase in people days pop Eastern Europe was 0.033778  p= 0.339\n",
      "attrib heat Eastern Europe was 74.45163827791728  p= 0.339 \n",
      "\n",
      "annual increase in people days Latin America and the Caribbean was 61.737378  p= 0.0\n",
      "annual increase in people days heat Latin America and the Caribbean was 23.639277  p= 0.0\n",
      "annual increase in people days pop Latin America and the Caribbean was 38.098101  p= 0.0\n",
      "attrib heat Latin America and the Caribbean was 38.290056633114546  p= 0.0 \n",
      "\n",
      "annual increase in people days Melanesia was 0.232979  p= 0.0\n",
      "annual increase in people days heat Melanesia was 0.035371  p= 0.0\n",
      "annual increase in people days pop Melanesia was 0.197608  p= 0.0\n",
      "attrib heat Melanesia was 15.182055035003156  p= 0.0 \n",
      "\n",
      "annual increase in people days Northern Africa was 37.754289  p= 0.0\n",
      "annual increase in people days heat Northern Africa was 11.206433  p= 0.0\n",
      "annual increase in people days pop Northern Africa was 26.547856  p= 0.0\n",
      "attrib heat Northern Africa was 29.682542823147855  p= 0.0 \n",
      "\n",
      "annual increase in people days Northern America was 8.324716  p= 0.016\n",
      "annual increase in people days heat Northern America was 0.898785  p= 0.016\n",
      "annual increase in people days pop Northern America was 7.42593  p= 0.016\n",
      "attrib heat Northern America was 10.796584532132988  p= 0.016 \n",
      "\n",
      "annual increase in people days Northern Europe was 0.005353  p= 0.117\n",
      "annual increase in people days heat Northern Europe was 0.0043  p= 0.117\n",
      "annual increase in people days pop Northern Europe was 0.001053  p= 0.117\n",
      "attrib heat Northern Europe was 80.3287875957407  p= 0.117 \n",
      "\n",
      "annual increase in people days South-eastern Asia was 223.781597  p= 0.0\n",
      "annual increase in people days heat South-eastern Asia was 75.28235  p= 0.0\n",
      "annual increase in people days pop South-eastern Asia was 148.499246  p= 0.0\n",
      "attrib heat South-eastern Asia was 33.64099238240756  p= 0.0 \n",
      "\n",
      "annual increase in people days Southern Asia was 1254.153766  p= 0.0\n",
      "annual increase in people days heat Southern Asia was 434.368615  p= 0.0\n",
      "annual increase in people days pop Southern Asia was 819.785151  p= 0.0\n",
      "attrib heat Southern Asia was 34.63439864996586  p= 0.0 \n",
      "\n",
      "annual increase in people days Southern Europe was 0.116258  p= 0.345\n",
      "annual increase in people days heat Southern Europe was 0.098266  p= 0.345\n",
      "annual increase in people days pop Southern Europe was 0.017992  p= 0.345\n",
      "attrib heat Southern Europe was 84.52407576252817  p= 0.345 \n",
      "\n",
      "annual increase in people days Sub-Saharan Africa was 219.38533  p= 0.0\n",
      "annual increase in people days heat Sub-Saharan Africa was 63.804134  p= 0.0\n",
      "annual increase in people days pop Sub-Saharan Africa was 155.581196  p= 0.0\n",
      "attrib heat Sub-Saharan Africa was 29.083136051075066  p= 0.0 \n",
      "\n",
      "annual increase in people days Western Asia was 280.718397  p= 0.0\n",
      "annual increase in people days heat Western Asia was 83.870925  p= 0.0\n",
      "annual increase in people days pop Western Asia was 196.847471  p= 0.0\n",
      "attrib heat Western Asia was 29.87724562989721  p= 0.0 \n",
      "\n",
      "annual increase in people days Western Europe was 0.060278  p= 0.449\n",
      "annual increase in people days heat Western Europe was 0.051108  p= 0.449\n",
      "annual increase in people days pop Western Europe was 0.00917  p= 0.449\n",
      "attrib heat Western Europe was 84.78715285842264  p= 0.449 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Annual Rates\n",
    "\n",
    "scale = 10**6\n",
    "geog = 'sub-region'\n",
    "\n",
    "for label in np.unique(HI_STATS[geog]):\n",
    "    label = label\n",
    "    data = HI_STATS[HI_STATS[geog] == label]\n",
    "    \n",
    "    #### Rate of change\n",
    "    coef, r2, p = lm_func(data, 'people_days')\n",
    "    print('annual increase in people days '+label, 'was', coef/scale, ' p=', p)\n",
    "    coef1, r21, p1 = lm_func(data, 'people_days_heat')\n",
    "    print('annual increase in people days heat '+label, 'was', coef1/scale, ' p=', p)\n",
    "    coef2, r22, p2 = lm_func(data, 'people_days_pop')\n",
    "    print('annual increase in people days pop '+label, 'was', coef2/scale, ' p=', p)\n",
    "    print('attrib heat '+label, 'was', coef1 / coef *100, ' p=', p, '\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Africa\n",
      "person days in 2016 was 13.220664862528546 billion\n",
      "person days in 1983 was 3.0001575378206344 billion\n",
      "pct increase in people days 83 - 16 is  340.6656882468999\n"
     ]
    }
   ],
   "source": [
    "#### Trends for Africa, N & SS\n",
    "geog = 'region'\n",
    "location = 'Africa'\n",
    "data = HI_STATS[HI_STATS[geog] == location]\n",
    "print(location)\n",
    "\n",
    "#### Total Change in people Days\n",
    "data = data.groupby('year')['people_days'].sum()\n",
    "year = str(data.index[33])\n",
    "value = str(data.values[33]/10**9)\n",
    "print('person days in 2016 was '+value+' billion')\n",
    "\n",
    "year = str(data.index[0])\n",
    "value = str(data.values[0]/10**9)\n",
    "print('person days in 1983 was '+value+' billion')\n",
    "\n",
    "#### Pct Change in Poeple Days 1983 - 2016\n",
    "pdays16 = data.iloc[len(data) -1]\n",
    "pdays83 = data.iloc[0]\n",
    "out = (data.iloc[len(data) -1] - data.iloc[0]) / data.iloc[0] * 100\n",
    "print('pct increase in people days 83 - 16 is ', out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct of total pdays from S Asia is  36.218392240142734\n"
     ]
    }
   ],
   "source": [
    "#### S Asia as pct of total  global = 5.245146271 B \n",
    "\n",
    "print('pct of total pdays from S Asia is ', 1899.70765 / 10**3 / 5.245146271 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe coef_heat is  8.1737798383928\n"
     ]
    }
   ],
   "source": [
    "#### Median Slope\n",
    "region = 'Europe'\n",
    "col = 'coef_heat'\n",
    "geog = 'region'\n",
    "scale = 10**3\n",
    "result = city_coefs[city_coefs[geog]== region][col].median()\n",
    "print(region, col, 'is ', result/scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Waves\n",
    "\n",
    "- 9691 Kolkata 1998\n",
    "- 2046 Paris 2003\n",
    "- 4417, Aleppo 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dir_in, geog, location):\n",
    "    \"\"\"Function makes data to plot daily city-level HI Max and average\n",
    "    Args:\n",
    "        dir_in = directory to get data\n",
    "        geog = column for geography, city-level = 'ID_HDC_G0'\n",
    "        location = usually a city id\n",
    "    \"\"\"\n",
    "    \n",
    "    fn_list = sorted(glob.glob(dir_in+'*.csv')) # get data\n",
    "    df_out = pd.DataFrame() # to write dataframe\n",
    "    \n",
    "     # get leap year cols from 2016\n",
    "    hi16 = pd.read_csv(fn_list[33]) \n",
    "    cols = list(hi16.iloc[:,3:].columns)\n",
    "    cols = [year[5:] for year in cols] # cols for data frame\n",
    "    \n",
    "    temp_list = [] # empty list for temps\n",
    "    \n",
    "    # loop through dir and get data\n",
    "    for i, fn in enumerate(fn_list):\n",
    "        df = pd.read_csv(fn) # open data frame\n",
    "        year_label = [(df.columns[3]).split('.')[0]] # get year\n",
    "        row = df[df[geog] == location]\n",
    "        temp = row.iloc[:,3:] # get only temp columns\n",
    "        \n",
    "        # add in col for leap years\n",
    "        if temp.shape[1] == 365:\n",
    "            temp.insert(loc = 59, column = year_label[0]+'.02.29', value = np.nan, allow_duplicates=False)\n",
    "\n",
    "        # Set Index & Columns\n",
    "        temp.index = year_label\n",
    "        temp.columns = cols # revalue to m.d\n",
    "    \n",
    "        # add to list\n",
    "        temp_list.append(temp)\n",
    "    \n",
    "    df_out = pd.concat(temp_list) # make one big dataframe\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, year, start, end):#, start, end):\n",
    "    \"\"\" Make the data for a plot\n",
    "    Args: \n",
    "        df = df w/ daily HI max for a given city\n",
    "        year = year you want to plot against average\n",
    "        start = start of plot in julian days (e.g 1 - 365/366)\n",
    "        end = end of plot in julian days\n",
    "    \"\"\"\n",
    "\n",
    "    # Deal with leap year\n",
    "    if year % 4 !=0:\n",
    "        df.drop(columns ='02.29', inplace = True)\n",
    "    \n",
    "    # Subset data\n",
    "    start = start - 1 # zero indexing \n",
    "    subset = df.iloc[:,start:end]\n",
    "    \n",
    "    # HI Max for year\n",
    "    hi_year = subset.loc[str(year)]\n",
    "    \n",
    "    # make 34-avg daily hi\n",
    "    means = subset.mean(axis = 0)\n",
    "    \n",
    "    # make colums to date time\n",
    "    cols = pd.to_datetime([str(year)+'.'+date for date in hi_year.index])\n",
    "    \n",
    "    return hi_year, means, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Heat Wave From All DATA\n",
    "def select_city_year(df, city_id, year):\n",
    "    \"Quick search to find city and years within HI_STATS\"\n",
    "    df_out = df[(df['ID_HDC_G0'] == city_id) & (df['year'] == year)]\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "# open heat events data\n",
    "events_fn = '/home/cascade/projects/UrbanHeat/data/processed/PNAS-DATA-v2/HI461_1D_STATS.json'\n",
    "events = pd.read_json(events_fn, orient = 'split')\n",
    "\n",
    "# [4417, 'Aleppo'] [2046, 'Paris'] [9691, 'Kolkata'] \n",
    "city = select_city_year(events, 4417, 2010)\n",
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select event and compare to long term means\n",
    "# Kolkata 1998 UID-2920905, Aleppo 2010 \n",
    "event_id = 'UID-2920905'\n",
    "event = city[city['UID'] == event_id]\n",
    "tmax = list(event['tmax'])[0]\n",
    "dates = list(event['event_dates'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Heat Index Data\n",
    "data = 'HI'\n",
    "DATA_IN = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS_DAILY/'+data+'/' # output from avg temp\n",
    "t = 46.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get long term means\n",
    "# Args\n",
    "#[4417, 'Aleppo'] 2010 [2046, 'Paris'] 2003 [9691, 'Kolkata'] 1998 ['6955, Dehli']\n",
    "\n",
    "# Args\n",
    "city_list = [4417, 'Aleppo'] \n",
    "year = 2010\n",
    "\n",
    "# April 1 to Sep 30 (Use Julian Days), or 1 - 182 lagos\n",
    "start = 91 \n",
    "end = 273\n",
    "\n",
    "# Make Data \n",
    "df = make_data(DATA_IN, 'ID_HDC_G0', city_list[0])\n",
    "years, means, cols = plot_data(df, year, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df\n",
    "df = pd.DataFrame()\n",
    "df['dates'] = cols\n",
    "df['max']  = years.to_list()\n",
    "df['avg'] = means.to_list()\n",
    "df['dif'] = df['max'] - df['avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['dates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dates[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start and end of heat wave\n",
    "start = dates[0]\n",
    "end = dates[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df[(df['dates'] >= start) & (df['dates'] <= end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[out['dif'] == out['dif'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoenix Caclulations\n",
    "1990-6-26 Phoenix, AZ Weather History. https://www.wunderground.com/history/daily/KPHX/date/1990-6-26. Weather Underground. (June 10, 2021).<br>A. Minkler, At 118 degrees, Thursday heat in Phoenix breaks daily record set in 1934. The Arizona Republic (2020) (June 18, 2021).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def c_to_f(C):\n",
    "    \"Convert HI C to F\"\n",
    "    return 1.8 * C + 32 \n",
    "\n",
    "def hi_to_wbgt(HI):\n",
    "    \"\"\" Convert HI to WBGT using emprical relationship from Bernard and Iheanacho 2015\n",
    "    WBGT [◦C] = −0.0034 HI2 + 0.96 HI−34; for HI [◦F]\n",
    "    \"\"\"\n",
    "    \n",
    "    WBGT = -0.0034*HI**2 + 0.96*HI - 34\n",
    "    \n",
    "    return WBGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmax was 122, rh was 11 using https://www.wpc.ncep.noaa.gov/html/heatindex.shtml\n",
    "# then HI was 49 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_city_year(df, city_id, year):\n",
    "    \"Quick search to find city and years within HI_STATS\"\n",
    "    df_out = df[(df['ID_HDC_G0'] == city_id) & (df['year'] == year)]\n",
    "    \n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = select_city_year(ALL_DATA, 4417, 2010)\n",
    "city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = '/home/cascade/projects/UrbanHeat/data/interim/ERA5_HI/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'GHS-ERA5-HI_2009.csv'\n",
    "data = pd.read_csv(dir_list+fn)\n",
    "city = data[data['ID_HDC_G0'] == 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_list = []\n",
    "dates_list = []\n",
    "for fn in sorted(os.listdir(dir_list)):\n",
    "    data = pd.read_csv(dir_list+fn)\n",
    "    city = data[data['ID_HDC_G0'] == 14]\n",
    "    dates = list(city.iloc[:,3:])\n",
    "    temps = list(city.iloc[:,3:].values[0])\n",
    "    dates_list.extend(dates)\n",
    "    temps_list.extend(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(dates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dependencies\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dir_in, geog, location):\n",
    "    \"\"\"Function makes data to plot daily city-level HI Max and average\n",
    "    Args:\n",
    "        dir_in = directory to get data\n",
    "        geog = column for geography, city-level = 'ID_HDC_G0'\n",
    "        location = usually a city id\n",
    "    \"\"\"\n",
    "    \n",
    "    fn_list = sorted(glob.glob(dir_in+'*.csv')) # get data\n",
    "    df_out = pd.DataFrame() # to write dataframe\n",
    "    \n",
    "     # get leap year cols from 2016\n",
    "    hi16 = pd.read_csv(fn_list[33]) \n",
    "    cols = list(hi16.iloc[:,3:].columns)\n",
    "    cols = [year[5:] for year in cols] # cols for data frame\n",
    "    \n",
    "    temp_list = [] # empty list for temps\n",
    "    \n",
    "    # loop through dir and get data\n",
    "    for i, fn in enumerate(fn_list):\n",
    "        df = pd.read_csv(fn) # open data frame\n",
    "        year_label = [(df.columns[3]).split('.')[0]] # get year\n",
    "        row = df[df[geog] == location]\n",
    "        temp = row.iloc[:,3:] # get only temp columns\n",
    "        \n",
    "        # add in col for leap years\n",
    "        if temp.shape[1] == 365:\n",
    "            temp.insert(loc = 59, column = year_label[0]+'.02.29', value = np.nan, allow_duplicates=False)\n",
    "\n",
    "        # Set Index & Columns\n",
    "        temp.index = year_label\n",
    "        temp.columns = cols # revalue to m.d\n",
    "    \n",
    "        # add to list\n",
    "        temp_list.append(temp)\n",
    "    \n",
    "    df_out = pd.concat(temp_list) # make one big dataframe\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, year, start, end):#, start, end):\n",
    "    \"\"\" Make the data for a plot\n",
    "    Args: \n",
    "        df = df w/ daily HI max for a given city\n",
    "        year = year you want to plot against average\n",
    "        start = start of plot in julian days (e.g 1 - 365/366)\n",
    "        end = end of plot in julian days\n",
    "    \"\"\"\n",
    "\n",
    "    # Deal with leap year\n",
    "    if year % 4 !=0:\n",
    "        df.drop(columns ='02.29', inplace = True)\n",
    "    \n",
    "    # Subset data\n",
    "    start = start - 1 # zero indexing \n",
    "    subset = df.iloc[:,start:end]\n",
    "    \n",
    "    # HI Max for year\n",
    "    hi_year = subset.loc[str(year)]\n",
    "    \n",
    "    # make 34-avg daily hi\n",
    "    means = subset.mean(axis = 0)\n",
    "    \n",
    "    # make colums to date time\n",
    "    cols = pd.to_datetime([str(year)+'.'+date for date in hi_year.index])\n",
    "    \n",
    "    return hi_year, means, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "#[3342, 'Cairo'] #[1910, 'Accra'] 3268, Cape Town\n",
    "#[4417, 'Aleppo'] 2010 [2046, 'Paris'] 2003 [9691, 'Kolkata'] 1998 ['6955, Dehli']\n",
    "\n",
    "# Args\n",
    "city_list = [9691, 'Kolkata'] \n",
    "year = 1998\n",
    "font_size = 10\n",
    "\n",
    "\n",
    "# April 1 to Sep 30 (Use Julian Days), or 1 - 182 lagos\n",
    "start = 91 \n",
    "end = 273\n",
    "\n",
    "# Labels\n",
    "hi_label = str(year)+' '+data\n",
    "labels =  ['avg. '+data, hi_label, str(t)+''+DS+'C']  # <<<<<------------ Be sure to update! \n",
    "\n",
    "# Make Data \n",
    "df = make_data(DATA_IN, 'ID_HDC_G0', city_list[0])\n",
    "years, means, cols = plot_data(df, year, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend First vs. Second Half of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Share of exposure due to heat by 17 year split\n",
    "\n",
    "## 1983 - 1999\n",
    "data1 = HI_STATS[(HI_STATS['year'] >= 1983) & (HI_STATS['year'] < 2000)]\n",
    "coef1pop , r21pop, p1pop  = lm_func(data1 , 'people_days_pop')\n",
    "coef1heat , r21heat, p1heat = lm_func(data1 , 'people_days_heat')\n",
    "\n",
    "years = list(np.unique(data1['year']))\n",
    "plt.plot(years, data1.groupby('year')['people_days_heat'].sum())\n",
    "sns.regplot(years, data1.groupby('year')['people_days_heat'].sum(), \n",
    "            color = 'blue', scatter = False, truncate = True)\n",
    "\n",
    "## 2000 - 2016\n",
    "data2 = HI_STATS[(HI_STATS['year'] >= 2000) & (HI_STATS['year'] <= 2016)]\n",
    "coef2heat , r22heat, p2heat = lm_func(data2 , 'people_days_heat')\n",
    "coef2pop , r22pop, p1pop  = lm_func(data2 , 'people_days_pop')\n",
    "\n",
    "years = list(np.unique(data1['year']))\n",
    "plt.plot(years, data2.groupby('year')['people_days_heat'].sum())\n",
    "sns.regplot(years, data2.groupby('year')['people_days_heat'].sum(), \n",
    "            color = 'orange', scatter = False, truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2000 - 2016\n",
    "data2pop = HI_STATS[(HI_STATS['year'] >= 1983) & (HI_STATS['year'] < 2000)]\n",
    "coef2pop , r22pop, p1pop  = lm_func(data2pop , 'people_days_pop')\n",
    "\n",
    "data2heat = HI_STATS[(HI_STATS['year'] >= 2000) & (HI_STATS['year'] <= 2016)]\n",
    "coef2heat , r22heat, p2heat = lm_func(data2heat , 'people_days_heat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Estimates\n",
    "print('From 83 - 99, contribution from heat was', coef1heat/(coef1pop+coef1heat))\n",
    "print('From 00 - 16, contribution from heat was', coef2heat/(coef2pop+coef2heat))\n",
    "print('From 83 - 00, heat was', coef1heat/10**9, round(p1heat, 3))\n",
    "print('From 00 - 16, heat was', coef2heat/10**9)\n",
    "print('From 83 - 00, pop was', coef1pop/10**9)\n",
    "print('From 00 - 16, pop was', coef2pop/10**9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
