{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Head Index\n",
    "\n",
    "By Cascade Tuholske 2020.01.21\n",
    "\n",
    "Notebook is designed to take areal-averaged CHIRTS Tmax for each GHS-UCDB and down-scaled MERRA-2 humidity data and calculate the heat index for each city with a Tmax >80F.\n",
    "\n",
    "[NOAA Heat Index Equation](https://www.wpc.ncep.noaa.gov/html/heatindex_equation.shtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THINGS I WILL NEED TO CODE**\n",
    "- C to F function\n",
    "- Rothfusz regression and adjustments\n",
    "- Steadman's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from random import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import geopandas as gpd \n",
    "import glob\n",
    "from statistics import mean\n",
    "import julian\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_to_F(Tmax_C):\n",
    "    \"Function converts temp in c to f\"\n",
    "    Tmax_F = (Tmax_C * (9/5)) + 32\n",
    "    \n",
    "    return Tmax_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steadman_hi(Tmax_F, RH):\n",
    "    \"Simple heat index calculation\"\n",
    "    \n",
    "    HI_steadman = 0.5 * (Tmax_F + 61.0 + ((Tmax_F-68.0)*1.2) + (RH*0.094))\n",
    "    \n",
    "    HI_steadman = (HI_steadman + Tmax_F) / 2\n",
    "    \n",
    "    return HI_steadman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-5-a415c133adac>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-a415c133adac>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    HI_rothfusz = -42.379 + 2.04901523*Tmax_F + 10.14333127*RH - .22475541*Tmax_F*RH - .00683783*Tmax_F*Tmax_F - .05481717*RH*RH + .00122874*Tmax_F*Tmax_F*RH + .00085282*Tmax_F*RH*RH - .00000199*Tmax_F*Tmax_F*RH*RH\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def rothfusz_hi(HI_steadman, Tmax_F, RH):\n",
    "    \n",
    "    \"Heat Index applied to Steadman's heat index >80F\"\n",
    "    \n",
    "    #if HI_steadman > 80:\n",
    "    \n",
    "        HI_rothfusz = -42.379 + 2.04901523*Tmax_F + 10.14333127*RH - .22475541*Tmax_F*RH - .00683783*Tmax_F*Tmax_F - .05481717*RH*RH + .00122874*Tmax_F*Tmax_F*RH + .00085282*Tmax_F*RH*RH - .00000199*Tmax_F*Tmax_F*RH*RH\n",
    "    \n",
    "    if RH < 13 and Tmax_F > 80 and Tmax_F < 112:\n",
    "        adjustment = ((13-RH)/4)*math.sqrt((17-abs(Tmax_F-95))/17)\n",
    "        HI_rothfusz = HI_rothfusz - adjustment \n",
    "    \n",
    "    \"If the RH is greater than 85% and the temperature is between 80 and 87 degrees F\" \n",
    "    if RH > 85 and Tmax_F > 80 and Tmax_F < 87:\n",
    "        adjustment = ((RH-85)/10) * ((87-Tmax_F)/5)\n",
    "        HI_rothfusz = HI_rothfusz + adjustment \n",
    "    \n",
    "    return HI_rothfusz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hi(Tmax_F, RH):\n",
    "    \"Calculates the heat index for a CHIRTS Tmax value\"\n",
    "    Tmax_F = C_to_F(Tmax_C)\n",
    "#     print('F is ', Tmax_F)\n",
    "#     print('H is ', RH)\n",
    "    HI_steadman = steadman_hi(Tmax_F, RH)\n",
    "#     print('HI_steadman is ', HI_steadman)\n",
    "    HI_rothfusz = rothfusz_hi(HI_steadman, Tmax_F, RH)\n",
    "#     print('HI_rothfusz is ', HI_rothfusz)\n",
    "    \n",
    "    return HI_rothfusz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Heat Index\n",
    "\n",
    "Get some paired values from the [NOAA CHART](https://www.weather.gov/safety/heat-index) and test the output. \n",
    "\n",
    "These results seem to be working well, though 104 F and 60 RH produced a higher number than the chart ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [25, 27, 35, 40, 41] # temp C\n",
    "RH = 60\n",
    "test = pd.DataFrame()\n",
    "test['temp'] = temp\n",
    "test['RH'] = RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, row in test.iterrows():\n",
    "    out = make_hi(row['temp'], row['RH'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we need to read in the csv files and quickly calculate the HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_RH = '/home/cascade/projects/UrbanHeat/data/interim/RH-GHS-DIALY/'\n",
    "DIR_RAW = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-RAW/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_RH = 'GHS-Tmax-RH_1983.csv'\n",
    "FN_RAW = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH = pd.read_csv(DIR_RH+FN_RH)\n",
    "RAW = pd.read_csv(DIR_RAW+FN_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13067\n"
     ]
    }
   ],
   "source": [
    "df_temp_id = RAW['ID_HDC_G0'] # get IDs\n",
    "df_temp = RAW.iloc[:,3:] # get only temp columns\n",
    "df_temp.index = df_temp_id # set index values\n",
    "df_temp_drop = df_temp.dropna() # Drop cities w/ no temp record \n",
    "print(len(df_temp_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1983.01.01</th>\n",
       "      <th>1983.01.02</th>\n",
       "      <th>1983.01.03</th>\n",
       "      <th>1983.01.04</th>\n",
       "      <th>1983.01.05</th>\n",
       "      <th>1983.01.06</th>\n",
       "      <th>1983.01.07</th>\n",
       "      <th>1983.01.08</th>\n",
       "      <th>1983.01.09</th>\n",
       "      <th>1983.01.10</th>\n",
       "      <th>...</th>\n",
       "      <th>1983.12.22</th>\n",
       "      <th>1983.12.23</th>\n",
       "      <th>1983.12.24</th>\n",
       "      <th>1983.12.25</th>\n",
       "      <th>1983.12.26</th>\n",
       "      <th>1983.12.27</th>\n",
       "      <th>1983.12.28</th>\n",
       "      <th>1983.12.29</th>\n",
       "      <th>1983.12.30</th>\n",
       "      <th>1983.12.31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5782</td>\n",
       "      <td>-43.921947</td>\n",
       "      <td>-33.713450</td>\n",
       "      <td>-33.054974</td>\n",
       "      <td>-25.376320</td>\n",
       "      <td>-23.129280</td>\n",
       "      <td>-21.466286</td>\n",
       "      <td>-19.981667</td>\n",
       "      <td>-15.222391</td>\n",
       "      <td>-16.233010</td>\n",
       "      <td>-16.017557</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.950730</td>\n",
       "      <td>-35.233840</td>\n",
       "      <td>-26.349930</td>\n",
       "      <td>-17.329056</td>\n",
       "      <td>-12.715102</td>\n",
       "      <td>-12.801040</td>\n",
       "      <td>-15.181746</td>\n",
       "      <td>-12.416152</td>\n",
       "      <td>-13.232986</td>\n",
       "      <td>-15.403823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3316</td>\n",
       "      <td>-4.804248</td>\n",
       "      <td>-3.914425</td>\n",
       "      <td>-7.533999</td>\n",
       "      <td>-12.615092</td>\n",
       "      <td>-7.848448</td>\n",
       "      <td>-6.586810</td>\n",
       "      <td>-5.604166</td>\n",
       "      <td>-5.210299</td>\n",
       "      <td>-7.793556</td>\n",
       "      <td>-5.328217</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.624672</td>\n",
       "      <td>-17.263590</td>\n",
       "      <td>-6.157263</td>\n",
       "      <td>-7.405956</td>\n",
       "      <td>-11.043344</td>\n",
       "      <td>-15.030403</td>\n",
       "      <td>-13.661594</td>\n",
       "      <td>-5.186461</td>\n",
       "      <td>-10.945722</td>\n",
       "      <td>-16.295160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5645</td>\n",
       "      <td>-23.904118</td>\n",
       "      <td>-17.422953</td>\n",
       "      <td>-13.182008</td>\n",
       "      <td>-14.080582</td>\n",
       "      <td>-15.031302</td>\n",
       "      <td>-17.476360</td>\n",
       "      <td>-21.271954</td>\n",
       "      <td>-12.573436</td>\n",
       "      <td>-7.619316</td>\n",
       "      <td>-9.144251</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.022259</td>\n",
       "      <td>-21.562733</td>\n",
       "      <td>-12.196519</td>\n",
       "      <td>-3.379593</td>\n",
       "      <td>-5.561025</td>\n",
       "      <td>-8.924066</td>\n",
       "      <td>-11.111601</td>\n",
       "      <td>-12.788978</td>\n",
       "      <td>-11.337886</td>\n",
       "      <td>-10.009390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>-0.145468</td>\n",
       "      <td>-0.141592</td>\n",
       "      <td>-4.062948</td>\n",
       "      <td>-2.354636</td>\n",
       "      <td>-1.533712</td>\n",
       "      <td>-0.494162</td>\n",
       "      <td>0.049387</td>\n",
       "      <td>0.149454</td>\n",
       "      <td>-1.632070</td>\n",
       "      <td>-4.892538</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.276704</td>\n",
       "      <td>-3.720002</td>\n",
       "      <td>-3.007447</td>\n",
       "      <td>-8.143495</td>\n",
       "      <td>-9.042634</td>\n",
       "      <td>-3.481507</td>\n",
       "      <td>-3.199769</td>\n",
       "      <td>-6.058533</td>\n",
       "      <td>-9.540711</td>\n",
       "      <td>-8.047456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3539</td>\n",
       "      <td>-6.093382</td>\n",
       "      <td>-6.081639</td>\n",
       "      <td>-15.774755</td>\n",
       "      <td>-13.649839</td>\n",
       "      <td>-9.780418</td>\n",
       "      <td>-2.830632</td>\n",
       "      <td>1.321785</td>\n",
       "      <td>1.234120</td>\n",
       "      <td>-0.136949</td>\n",
       "      <td>-3.587718</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.097543</td>\n",
       "      <td>-1.184109</td>\n",
       "      <td>-0.788187</td>\n",
       "      <td>-0.913870</td>\n",
       "      <td>-6.033908</td>\n",
       "      <td>-8.862185</td>\n",
       "      <td>-8.945712</td>\n",
       "      <td>-7.596188</td>\n",
       "      <td>-6.915255</td>\n",
       "      <td>-9.641947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 365 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1983.01.01  1983.01.02  1983.01.03  1983.01.04  1983.01.05  \\\n",
       "ID_HDC_G0                                                               \n",
       "5782       -43.921947  -33.713450  -33.054974  -25.376320  -23.129280   \n",
       "3316        -4.804248   -3.914425   -7.533999  -12.615092   -7.848448   \n",
       "5645       -23.904118  -17.422953  -13.182008  -14.080582  -15.031302   \n",
       "3185        -0.145468   -0.141592   -4.062948   -2.354636   -1.533712   \n",
       "3539        -6.093382   -6.081639  -15.774755  -13.649839   -9.780418   \n",
       "\n",
       "           1983.01.06  1983.01.07  1983.01.08  1983.01.09  1983.01.10  ...  \\\n",
       "ID_HDC_G0                                                              ...   \n",
       "5782       -21.466286  -19.981667  -15.222391  -16.233010  -16.017557  ...   \n",
       "3316        -6.586810   -5.604166   -5.210299   -7.793556   -5.328217  ...   \n",
       "5645       -17.476360  -21.271954  -12.573436   -7.619316   -9.144251  ...   \n",
       "3185        -0.494162    0.049387    0.149454   -1.632070   -4.892538  ...   \n",
       "3539        -2.830632    1.321785    1.234120   -0.136949   -3.587718  ...   \n",
       "\n",
       "           1983.12.22  1983.12.23  1983.12.24  1983.12.25  1983.12.26  \\\n",
       "ID_HDC_G0                                                               \n",
       "5782       -24.950730  -35.233840  -26.349930  -17.329056  -12.715102   \n",
       "3316       -11.624672  -17.263590   -6.157263   -7.405956  -11.043344   \n",
       "5645       -20.022259  -21.562733  -12.196519   -3.379593   -5.561025   \n",
       "3185        -9.276704   -3.720002   -3.007447   -8.143495   -9.042634   \n",
       "3539        -4.097543   -1.184109   -0.788187   -0.913870   -6.033908   \n",
       "\n",
       "           1983.12.27  1983.12.28  1983.12.29  1983.12.30  1983.12.31  \n",
       "ID_HDC_G0                                                              \n",
       "5782       -12.801040  -15.181746  -12.416152  -13.232986  -15.403823  \n",
       "3316       -15.030403  -13.661594   -5.186461  -10.945722  -16.295160  \n",
       "5645        -8.924066  -11.111601  -12.788978  -11.337886  -10.009390  \n",
       "3185        -3.481507   -3.199769   -6.058533   -9.540711   -8.047456  \n",
       "3539        -8.862185   -8.945712   -7.596188   -6.915255   -9.641947  \n",
       "\n",
       "[5 rows x 365 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13067\n"
     ]
    }
   ],
   "source": [
    "df_RH_id = RH['ID_HDC_G0'] # get IDs\n",
    "df_RH = RH.iloc[:,3:] # get only temp columns\n",
    "df_RH.index = df_RH_id # set index values\n",
    "df_RH_drop = df_RH.dropna() # Drop cities w/ no temp record \n",
    "print(len(df_RH_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make them into a data array\n",
    "\n",
    "temp_xr_da = xr.DataArray(df_temp_drop, coords=[df_temp_drop.index, df_temp_drop.columns], \n",
    "                            dims=['ID_HDC_G0', 'date'])\n",
    "RH_xr_da = xr.DataArray(df_RH_drop, coords=[df_RH_drop.index, df_RH_drop.columns], \n",
    "                            dims=['ID_HDC_G0', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the temp x array from C to F\n",
    "\n",
    "temp_xr_da = C_to_F(temp_xr_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (ID_HDC_G0: 13067, date: 365)>\n",
       "array([[-47.059505, -28.68421 , -27.498953, ...,   9.650926,   8.180626,\n",
       "          4.273119],\n",
       "       [ 23.352354,  24.954035,  18.438803, ...,  22.664369,  12.2977  ,\n",
       "          2.668712],\n",
       "       [-11.027412,   0.638685,   8.272386, ...,   8.97984 ,  11.591805,\n",
       "         13.983098],\n",
       "       ...,\n",
       "       [ 60.850441,  63.924854,  68.887929, ...,  58.206958,  59.28933 ,\n",
       "         59.331243],\n",
       "       [ 61.556995,  64.168556,  72.535413, ...,  60.225735,  61.105519,\n",
       "         60.870522],\n",
       "       [ 62.04974 ,  63.606612,  70.665654, ...,  58.002894,  59.424084,\n",
       "         57.210064]])\n",
       "Coordinates:\n",
       "  * ID_HDC_G0  (ID_HDC_G0) int64 5782 3316 5645 3185 ... 1116 1114 1161 1169\n",
       "  * date       (date) object '1983.01.01' '1983.01.02' ... '1983.12.31'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_xr_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply steadman's\n",
    "\n",
    "HI_steadman = steadman_hi(temp_xr_da, RH_xr_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (ID_HDC_G0: 13067, date: 365)>\n",
       "array([[-52.79085 , -33.209534, -32.424601, ...,   7.333473,   5.723379,\n",
       "          1.411044],\n",
       "       [ 21.612108,  23.401737,  16.560743, ...,  20.97596 ,   9.666459,\n",
       "         -0.359718],\n",
       "       [-15.149145,  -2.844831,   5.225676, ...,   5.991969,   8.79311 ,\n",
       "         11.260339],\n",
       "       ...,\n",
       "       [ 60.131937,  63.263469,  68.54139 , ...,  57.353674,  58.46652 ,\n",
       "         58.646119],\n",
       "       [ 60.943873,  63.562727,  72.311917, ...,  59.511969,  60.38539 ,\n",
       "         60.219069],\n",
       "       [ 61.211956,  62.817895,  70.245043, ...,  57.073305,  58.541903,\n",
       "         56.282076]])\n",
       "Coordinates:\n",
       "  * ID_HDC_G0  (ID_HDC_G0) int64 5782 3316 5645 3185 ... 1116 1114 1161 1169\n",
       "  * date       (date) object '1983.01.01' '1983.01.02' ... '1983.12.31'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HI_steadman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hi(Tmax_F, RH):\n",
    "    \n",
    "    \"Heat Index applied to Steadman's heat index >80F\"\n",
    "    \n",
    "    USE_STEAD = (0.5 * (Tmax_F + 61.0 + ((Tmax_F-68.0)*1.2) + (RH*0.094)) + Tmax_F)/2 < 80  \n",
    "    STEAD = 0.5 * (Tmax_F + 61.0 + ((Tmax_F-68.0)*1.2) + (RH*0.094)) * USE_STEAD.astype(int)\n",
    "    \n",
    "    ROTHFUZ = -42.379 + 2.04901523*Tmax_F + 10.14333127*RH - .22475541*Tmax_F*RH - .00683783*Tmax_F*Tmax_F - .05481717*RH*RH + .00122874*Tmax_F*Tmax_F*RH + .00085282*Tmax_F*RH*RH - .00000199*Tmax_F*Tmax_F*RH*RH\n",
    "    ADJ1 = ((13-RH)/4)*np.sqrt((17-abs(Tmax_F-95))/17)\n",
    "    ADJ2 = ((RH-85)/10) * ((87-Tmax_F)/5)\n",
    "    ADJ = ADJ1*((Tmax_F < 112) & (RH < 13)).astype(int) + ADJ2*((Tmax_F < 87) & (RH > 85)).astype(int)\n",
    "    ANS = STEAD + (ROTHFUZ + ADJ) * np.logical_not(USE_STEAD).astype(int)\n",
    "    return ANS\n",
    "#    HI_steadman = \n",
    "#     if RH < 13 and Tmax_F > 80 and Tmax_F < 112:\n",
    "#         adjustment = ((13-RH)/4)*math.sqrt((17-abs(Tmax_F-95))/17)\n",
    "#         HI_rothfusz = HI_rothfusz - adjustment \n",
    "    \n",
    "#     \"If the RH is greater than 85% and the temperature is between 80 and 87 degrees F\" \n",
    "#     if RH > 85 and Tmax_F > 80 and Tmax_F < 87:\n",
    "#         adjustment = ((RH-85)/10) * ((87-Tmax_F)/5)\n",
    "#         HI_rothfusz = HI_rothfusz + adjustment \n",
    "#    \n",
    "#    return HI_steadman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cascade/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/computation.py:564: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result_data = func(*input_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (ID_HDC_G0: 13067, date: 365)>\n",
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])\n",
       "Coordinates:\n",
       "  * ID_HDC_G0  (ID_HDC_G0) int64 5782 3316 5645 3185 ... 1116 1114 1161 1169\n",
       "  * date       (date) object '1983.01.01' '1983.01.02' ... '1983.12.31'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi(Tmax_F, RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax_F = temp_xr_da\n",
    "RH = RH_xr_da\n",
    "USE_STEAD = (0.5 * (Tmax_F + 61.0 + ((Tmax_F-68.0)*1.2) + (RH*0.094)) + Tmax_F)/2 < 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID_HDC_G0',\n",
       " 'T',\n",
       " '_DataArray__default',\n",
       " '_DataArray__default_name',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__dask_graph__',\n",
       " '__dask_keys__',\n",
       " '__dask_layers__',\n",
       " '__dask_optimize__',\n",
       " '__dask_postcompute__',\n",
       " '__dask_postpersist__',\n",
       " '__dask_scheduler__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_all_compat',\n",
       " '_attr_sources',\n",
       " '_binary_op',\n",
       " '_calc_assign_results',\n",
       " '_coarsen_cls',\n",
       " '_copy_attrs_from',\n",
       " '_cum_extra_args_docstring',\n",
       " '_dask_finalize',\n",
       " '_from_temp_dataset',\n",
       " '_get_axis_num',\n",
       " '_getitem_coord',\n",
       " '_groupby_cls',\n",
       " '_in_memory',\n",
       " '_initialized',\n",
       " '_inplace_binary_op',\n",
       " '_ipython_key_completions_',\n",
       " '_item_key_to_dict',\n",
       " '_item_sources',\n",
       " '_iter',\n",
       " '_level_coords',\n",
       " '_reduce_extra_args_docstring',\n",
       " '_reduce_method',\n",
       " '_replace',\n",
       " '_replace_indexes',\n",
       " '_replace_maybe_drop_dims',\n",
       " '_resample_cls',\n",
       " '_result_name',\n",
       " '_rolling_cls',\n",
       " '_rolling_exp_cls',\n",
       " '_title_for_slice',\n",
       " '_to_dataset_split',\n",
       " '_to_dataset_whole',\n",
       " '_to_temp_dataset',\n",
       " '_unary_op',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'assign_attrs',\n",
       " 'assign_coords',\n",
       " 'astype',\n",
       " 'attrs',\n",
       " 'bfill',\n",
       " 'broadcast_equals',\n",
       " 'chunk',\n",
       " 'chunks',\n",
       " 'clip',\n",
       " 'close',\n",
       " 'coarsen',\n",
       " 'combine_first',\n",
       " 'compute',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'coords',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'date',\n",
       " 'diff',\n",
       " 'differentiate',\n",
       " 'dims',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'dropna',\n",
       " 'dt',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'equals',\n",
       " 'expand_dims',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'from_cdms2',\n",
       " 'from_dict',\n",
       " 'from_iris',\n",
       " 'from_series',\n",
       " 'get_axis_num',\n",
       " 'get_index',\n",
       " 'groupby',\n",
       " 'groupby_bins',\n",
       " 'identical',\n",
       " 'imag',\n",
       " 'indexes',\n",
       " 'integrate',\n",
       " 'interp',\n",
       " 'interp_like',\n",
       " 'interpolate_na',\n",
       " 'isel',\n",
       " 'isel_points',\n",
       " 'isin',\n",
       " 'isnull',\n",
       " 'item',\n",
       " 'load',\n",
       " 'loc',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'min',\n",
       " 'name',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'notnull',\n",
       " 'persist',\n",
       " 'pipe',\n",
       " 'plot',\n",
       " 'prod',\n",
       " 'quantile',\n",
       " 'rank',\n",
       " 'real',\n",
       " 'reduce',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'reorder_levels',\n",
       " 'resample',\n",
       " 'reset_coords',\n",
       " 'reset_index',\n",
       " 'roll',\n",
       " 'rolling',\n",
       " 'rolling_exp',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'sel',\n",
       " 'sel_points',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'sizes',\n",
       " 'sortby',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'str',\n",
       " 'sum',\n",
       " 'swap_dims',\n",
       " 'to_cdms2',\n",
       " 'to_dataframe',\n",
       " 'to_dataset',\n",
       " 'to_dict',\n",
       " 'to_index',\n",
       " 'to_iris',\n",
       " 'to_masked_array',\n",
       " 'to_netcdf',\n",
       " 'to_pandas',\n",
       " 'to_series',\n",
       " 'to_unstacked_dataset',\n",
       " 'transpose',\n",
       " 'unstack',\n",
       " 'values',\n",
       " 'var',\n",
       " 'variable',\n",
       " 'where']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(USE_STEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_not(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_xr(file_in, time_dim, space_dim):\n",
    "    \n",
    "    \"\"\" Function reads in a csv w/ GHS-UCDB IDs and temp, isolates the temp\n",
    "    and returns a xarray data array with dims set to city ids and dates\n",
    "    \n",
    "    Args:\n",
    "        file_in = file name and path\n",
    "        time_dim = name for time dim as a str ... use date :-)\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_in) # read the file in as a df\n",
    "    print(df.shape)\n",
    "    \n",
    "    df_id = df[space_dim] # get IDs\n",
    "    df_temp = df.iloc[:,3:] # get only temp columns\n",
    "    df_temp.index = df_id # set index values\n",
    "    df_temp_drop = df_temp.dropna() # Drop cities w/ no temp record \n",
    "    print(len(df_temp_drop))\n",
    "    \n",
    "    temp_np = df_temp_drop.to_numpy() # turn temp cols into an np array\n",
    "    \n",
    "    # make xr Data Array w/ data as temp and dims as spece (e.g. id)\n",
    "    \n",
    "    # Note 2019 09 17 changed to xr.Dataset from xr.Dataarray\n",
    "    temp_xr_da = xr.DataArray(temp_np, coords=[df_temp_drop.index, df_temp_drop.columns], \n",
    "                            dims=[space_dim, time_dim])\n",
    "    \n",
    "    return temp_xr_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2 Function finds all the Tmax Events and writes it to a dateframe w/ dates for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_days(xarray, Tthresh):\n",
    "    \"\"\" Function finds all the tmax days in a year and sums total days per year \n",
    "    greater than a threshold within a year where Tmax > Tthresh for each city. Returns the total number of days,\n",
    "    the dates, the tempatures, and the intensity (daily Tmax - Tthresh)\n",
    "    \n",
    "    Args: \n",
    "        xarray = an xarray object with dims = (space, times)\n",
    "        Tthresh = int of temp threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty lists & df\n",
    "    id_list = []\n",
    "    date_list = []\n",
    "    dayTot_list = []\n",
    "    tmax_list = []\n",
    "    intensity_list = []\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # subset xarray\n",
    "    out = xarray.where(xarray > Tthresh, drop = True)\n",
    "\n",
    "    # start loop \n",
    "    for index, loc in enumerate(out.ID_HDC_G0):\n",
    "        id_list.append(out.ID_HDC_G0.values[index]) # get IDS\n",
    "        date_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values) # get event dates\n",
    "        \n",
    "        # this is actually getting the total events of all, 2019-09-22\n",
    "        dayTot_list.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values)) # get event totals\n",
    "        \n",
    "        tmax_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values) # get temp values\n",
    "        intensity_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values - Tthresh) # get severity\n",
    "\n",
    "    # write to a data frame\n",
    "    df_out['ID_HDC_G0'] = id_list\n",
    "    df_out['total_days'] = dayTot_list\n",
    "    df_out['dates'] = date_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "    df_out['tmax_tntensity'] = intensity_list\n",
    "\n",
    "    # return df_out\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #3 Function splits the dataset into Tmax events (continuous days >Tmax) for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jul_convert(dates):\n",
    "    \"Function turn days into julian datetime\"\n",
    "    jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "    \n",
    "    return jul_days\n",
    "\n",
    "def event_split(dates, ID_HDC_G0, intensity, tmax, total_days):\n",
    "    \"\"\" Searchs a list of dates and isolates sequential dates as a list, then calculates event stats.\n",
    "    See comments in code for more details. \n",
    "    \n",
    "    Args:\n",
    "        dates: pandas.core.index as julian dates\n",
    "        ID_HDC_G0: city ID as string\n",
    "        country: country for each city as string\n",
    "        intensity: numpy.ndarray of intensities values\n",
    "        tmax: numpy.ndarray of intensities values of tmax values\n",
    "        total_days: total number of tmax days in a year for a given city\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # city id\n",
    "    city_id = ID_HDC_G0\n",
    "    tot_days = total_days\n",
    "    \n",
    "    # lists to fill\n",
    "    city_id_list = []\n",
    "    tot_days_list = []\n",
    "    event_dates_list = []\n",
    "    dur_list = []\n",
    "    intensity_list = []\n",
    "    tmax_list = []\n",
    "    avg_temp_list = []\n",
    "    avg_int_list = []\n",
    "    tot_int_list = []\n",
    "    \n",
    "    # data frame out\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # turn days into julian days\n",
    "    jul_days = jul_convert(dates)\n",
    "    \n",
    "    # Counters to make sure we write the correct event dates to a list, don't want julian days in output\n",
    "    counter = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    # Loop through dur list and isolate seq days, temps, and intensities\n",
    "    for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "        \n",
    "        seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "        dur = len(seq) # duration of each event\n",
    "        \n",
    "        counter = counter + dur # add duration to counter\n",
    "        end = counter # end of current event\n",
    "        \n",
    "        event_dates = dates[start:end] # dates of tmax days during each event\n",
    "        intense = intensity[start:end] # intensity of each day during event\n",
    "        temp = tmax[start:end] # temp of each day during event\n",
    "        avg_temp = mean(temp) # avg. temp during event\n",
    "        avg_int = mean(intense) # avg. intensity during event\n",
    "        tot_int = intense.sum() # total intensity during event\n",
    "        \n",
    "        start = counter # reset start to current end (e.g. counter)\n",
    "        \n",
    "        # fill lists\n",
    "        city_id_list.append(city_id)\n",
    "        tot_days_list.append(tot_days)\n",
    "        dur_list.append(dur)\n",
    "        event_dates_list.append(event_dates)\n",
    "        intensity_list.append(intense)\n",
    "        tmax_list.append(temp)\n",
    "        avg_temp_list.append(avg_temp)\n",
    "        avg_int_list.append(avg_int)\n",
    "        tot_int_list.append(tot_int)\n",
    "\n",
    "    # write out as a dateframe\n",
    "    df_out['ID_HDC_G0'] = city_id_list\n",
    "    df_out['total_days'] = tot_days_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['avg_temp'] = avg_temp_list\n",
    "    df_out['avg_intensity'] = avg_int_list\n",
    "    df_out['tot_intensity'] = tot_int_list\n",
    "    df_out['event_dates'] = event_dates_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['intensity'] = intensity_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #4 Function feeds output from function 2 into function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_stats(df_in):\n",
    "    \"\"\" runs event_split functionon a dataframe to produce desired tmax stats\n",
    "    \n",
    "        NOTE - If you add arguments to event_split to make more states, \n",
    "        be sure to update this function\n",
    "    \n",
    "        args:\n",
    "            df: input dataframe\n",
    "        \n",
    "    \"\"\"\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # NOTE - If you add arguments to event_split to make more stats, \n",
    "    # be sure to update this function\n",
    "    \n",
    "    for index, row in df_in.iterrows():\n",
    "        dates = row['dates'] # Get event dates\n",
    "        intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "        tmax = row['tmax'] # Get tmax for each day\n",
    "        ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "        total_days = row['total_days'] # get total number of tmax days\n",
    "\n",
    "        df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "\n",
    "        df_out = df_out.append(df)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #5 Loops through a file list and applies functions 1 - 4 to the data to produce Tmax stats for all tmax events in a given year across all cities in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_loop(dir_in, dir_out, fn_out, time_dim, space_dim, Tthresh):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs to apply csv_to_xr and\n",
    "    tmax_stats function and save out a .csv for each year\n",
    "    \n",
    "    Args:\n",
    "        dir_in = dir path to loop through\n",
    "        dir_out = dir path to save files out\n",
    "        fn_out = string to label out files\n",
    "        time_dim = name for time dim as a str ... use date :-) for csv_to_xr function\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0) for csv_to_xr function\n",
    "        Tthresh = int of temp threshold for temp_event function -- 40.6 is used\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the GHS-ID List with GeoPANDAS read_file\n",
    "    ghs_ids_fn = 'GHS-UCSB-IDS.csv'\n",
    "    ghs_ids_df = pd.read_csv(DATA_INTERIM+ghs_ids_fn)\n",
    "        \n",
    "    # Git File list\n",
    "    fn_list = glob.glob(dir_in+'*.csv')\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "        \n",
    "        # Get year for arg for temp_event function\n",
    "        year = fn.split('GHS-Tmax-DAILY_')[1].split('.csv')[0]\n",
    "        print(year)\n",
    "        \n",
    "        # read csv as a data array\n",
    "        temp_xr_da = csv_to_xr(fn, time_dim, space_dim)\n",
    "        \n",
    "        # data array to tmax events, out as df\n",
    "        df_days = tmax_days(temp_xr_da, Tthresh)\n",
    "        \n",
    "        # tmax events stats, out as df\n",
    "        df_out = tmax_stats(df_days)\n",
    "        \n",
    "        # merge to get countries\n",
    "        ghs_ids_df_out = ghs_ids_df.merge(df_out, on='ID_HDC_G0', how = 'inner') \n",
    "        \n",
    "        # write it all out\n",
    "        ghs_ids_df_out.to_csv(dir_out+fn_out+year+'.csv')\n",
    "\n",
    "        print(year, 'SAVED!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/' # ghs ID list\n",
    "dir_out = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'\n",
    "fn_out = 'CHIRTS-GHS-Events-Stats'\n",
    "time_dim = 'date'\n",
    "space_dim = 'ID_HDC_G0'\n",
    "Tthresh = 40.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stats_loop(dir_in, dir_out, fn_out, time_dim, space_dim, Tthresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA/QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "\n",
    "dir_out = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'\n",
    "fn_out = 'CHIRTS-GHS-Events-Stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_df = pd.read_csv(dir_out+fn_out+'1983.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_city = qc_df[qc_df['ID_HDC_G0'] == 5534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/data_out_urbanheat/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open a raw file\n",
    "xr1983 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days1983 = tmax_days(xr1983, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = days1983[0:30]\n",
    "test\n",
    "\n",
    "# Maybe add in days_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build routine for loop through a csv\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "    \n",
    "    df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "    \n",
    "    df_out = df_out.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing code\n",
    "2019.10.19 Cascade Tuholkse\n",
    "\n",
    "Need to fix ```event split``` function\n",
    "\n",
    "Somewhere in 1984 is this event sequence: ['1984.01.01' '1984.01.02' '1984.01.07']\n",
    "\n",
    "\n",
    "**FOUND PROBLEM AND IT IS FIXED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/data_out_urbanheatv/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out_urbanheat/testout/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open a raw file\n",
    "xr1983 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the tmax days\n",
    "tmax1983 = tmax_days(xr1983, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset\n",
    "\n",
    "test = tmax1983[tmax1983['ID_HDC_G0'] == 6279]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to jul days\n",
    "jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "jul_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjd = 2445507.5 - 43200\n",
    "dt = julian.from_jd(mjd, fmt='mjd')\n",
    "print(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['1983.06.20', '1983.06.23', '1983.06.24', '1983.06.25',\n",
    "        '1983.06.26', '1983.06.27', '1983.06.28', '1983.06.29',\n",
    "        '1983.06.30', '1983.07.01', '1983.07.21', '1983.07.22',\n",
    "        '1983.07.23', '1983.08.01']\n",
    "\n",
    "pd_dates = pd.to_datetime(dates)\n",
    "df_dates = pd.DataFrame()\n",
    "df_dates['dates'] = pd_dates\n",
    "\n",
    "\n",
    "\n",
    "test = df_dates['dates'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "date.fromordinal(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = dates[0:10] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))\n",
    "\n",
    "event_dates = dates[10:13] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))\n",
    "\n",
    "event_dates = dates[13:14] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates_list = []\n",
    "counter = 0\n",
    "start = 0\n",
    "end = 0\n",
    "\n",
    "for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "    \n",
    "    len_dates = len(dates) # len of all Tmax dates for a given city\n",
    "#   print(len(dates))\n",
    "    \n",
    "    seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "    dur = len(seq) # duration of each event \n",
    "    \n",
    "    counter = counter + dur\n",
    "    end = counter\n",
    "    \n",
    "    print(end)\n",
    "    \n",
    "    event_dates = dates[start:end] # dates of tmax days during each event\n",
    "    print(event_dates)\n",
    "    \n",
    "    start = counter\n",
    "    \n",
    "# #     print('dur= ', dur)\n",
    "    \n",
    "#     event_dates = dates[0:10] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "#     event_dates = dates[11:13] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "#     event_dates = dates[:len_dates] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     counter = counter + dur\n",
    "\n",
    "#     print('counter = ', counter)\n",
    "    \n",
    "#     dif = dur - counter\n",
    "#     print('dif = ', dif)\n",
    "    \n",
    "#     start = start \n",
    "#     print('start = ',start)\n",
    "    \n",
    "# #     end = counter + dur\n",
    "# #     print(\"start = \",end)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     counter = counter + dur\n",
    "#     print(counter)\n",
    "#     end = counter + dur\n",
    "#     start\n",
    "#     event_dates = dates[start:end] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "# #     intense = intensity[0:dur] # intensity of each day during event\n",
    "#     temp = tmax[0:dur] # temp of each day during event\n",
    "#     avg_temp = mean(temp) # avg. temp during event\n",
    "#     avg_int = mean(intense) # avg. intensity during event\n",
    "#     tot_int = intense.sum() # total intensity during event\n",
    "    \n",
    "#     event_dates_list.append(event_dates)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['event_dates'] = event_dates_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tmax stats ------> CLEARLY NOTE WORKING\n",
    "\n",
    "# tmax1983_sub_stats = tmax_stats(tmax1983_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmax1983['dates'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = tmax1983_sub['dates']\n",
    "#jul_days = pd.to_datetime(tmax1983['dates']).to_julian_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to break up events\n",
    "\n",
    "for index, row in tmax1983_sub.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "\n",
    "#     df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "\n",
    "#     df_out = df_out.append(df)\n",
    "\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_out['events'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
