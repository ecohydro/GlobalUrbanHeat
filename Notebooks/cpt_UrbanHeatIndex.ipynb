{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Head Index\n",
    "\n",
    "By Cascade Tuholske 2020.01.21\n",
    "\n",
    "Notebook is designed to take areal-averaged CHIRTS Tmax for each GHS-UCDB and down-scaled MERRA-2 humidity data and calculate the heat index for each city with a Tmax >80F.\n",
    "\n",
    "[NOAA Heat Index Equation](https://www.wpc.ncep.noaa.gov/html/heatindex_equation.shtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THINGS I WILL NEED TO CODE**\n",
    "- C to F function\n",
    "- Rothfusz regression and adjustments\n",
    "- Steadman's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from random import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import geopandas as gpd \n",
    "import glob\n",
    "from statistics import mean\n",
    "import julian\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_to_F(Tmax_C):\n",
    "    \"Function converts temp in c to f\"\n",
    "    Tmax_F = (Tmax_C * (9/5)) + 32\n",
    "    \n",
    "    return Tmax_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steadman_hi(Tmax_F, RH):\n",
    "    \"Simple heat index calculation\"\n",
    "    \n",
    "    HI_steadman = 0.5 * (Tmax_F + 61.0 + ((Tmax_F-68.0)*1.2) + (RH*0.094))\n",
    "    \n",
    "    HI_steadman = (HI_steadman + Tmax_F) / 2\n",
    "    \n",
    "    return HI_steadman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rothfusz_hi(HI_steadman, Tmax_F, RH):\n",
    "    \n",
    "    \"Heat Index applied to Steadman's heat index >80F\"\n",
    "    \n",
    "    if (HI_steadman > 80):\n",
    "    \n",
    "        HI_rothfusz = -42.379 + 2.04901523*Tmax_F + 10.14333127*RH - .22475541*Tmax_F*RH - .00683783*Tmax_F*Tmax_F - .05481717*RH*RH + .00122874*Tmax_F*Tmax_F*RH + .00085282*Tmax_F*RH*RH - .00000199*Tmax_F*Tmax_F*RH*RH\n",
    "    \n",
    "    if (RH < 13) & (Tmax_F > 80) & (Tmax_F < 112):\n",
    "        adjustment = ((13-RH)/4)*math.sqrt((17-abs(Tmax_F-95))/17)\n",
    "        HI_rothfusz = HI_rothfusz - adjustment \n",
    "    \n",
    "    \"If the RH is greater than 85% and the temperature is between 80 and 87 degrees F\" \n",
    "    if (RH > 85) & (Tmax_F > 80) & (Tmax_F < 87):\n",
    "        adjustment = ((RH-85)/10) * ((87-Tmax_F)/5)\n",
    "        HI_rothfusz = HI_rothfusz + adjustment \n",
    "    \n",
    "    return HI_rothfusz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hi(Tmax_F, RH):\n",
    "    \"Calculates the heat index for a CHIRTS Tmax value\"\n",
    "    Tmax_F = C_to_F(Tmax_C)\n",
    "#     print('F is ', Tmax_F)\n",
    "#     print('H is ', RH)\n",
    "    HI_steadman = steadman_hi(Tmax_F, RH)\n",
    "#     print('HI_steadman is ', HI_steadman)\n",
    "    HI_rothfusz = rothfusz_hi(HI_steadman, Tmax_F, RH)\n",
    "#     print('HI_rothfusz is ', HI_rothfusz)\n",
    "    \n",
    "    return HI_rothfusz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we need to read in the csv files and quickly calculate the HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_RH = '/home/cascade/projects/UrbanHeat/data/interim/RH-GHS-DAILY/'\n",
    "DIR_RAW = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-RAW/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_RH = 'GHS-Tmax-RH_1983.csv'\n",
    "FN_RAW = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH = pd.read_csv(DIR_RH+FN_RH)\n",
    "RAW = pd.read_csv(DIR_RAW+FN_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13067\n"
     ]
    }
   ],
   "source": [
    "df_temp_id = RAW['ID_HDC_G0'] # get IDs\n",
    "df_temp = RAW.iloc[:,3:] # get only temp columns\n",
    "df_temp.index = df_temp_id # set index values\n",
    "df_temp_drop = df_temp.dropna() # Drop cities w/ no temp record \n",
    "print(len(df_temp_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1983.01.01</th>\n",
       "      <th>1983.01.02</th>\n",
       "      <th>1983.01.03</th>\n",
       "      <th>1983.01.04</th>\n",
       "      <th>1983.01.05</th>\n",
       "      <th>1983.01.06</th>\n",
       "      <th>1983.01.07</th>\n",
       "      <th>1983.01.08</th>\n",
       "      <th>1983.01.09</th>\n",
       "      <th>1983.01.10</th>\n",
       "      <th>...</th>\n",
       "      <th>1983.12.22</th>\n",
       "      <th>1983.12.23</th>\n",
       "      <th>1983.12.24</th>\n",
       "      <th>1983.12.25</th>\n",
       "      <th>1983.12.26</th>\n",
       "      <th>1983.12.27</th>\n",
       "      <th>1983.12.28</th>\n",
       "      <th>1983.12.29</th>\n",
       "      <th>1983.12.30</th>\n",
       "      <th>1983.12.31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5782</td>\n",
       "      <td>-43.921947</td>\n",
       "      <td>-33.713450</td>\n",
       "      <td>-33.054974</td>\n",
       "      <td>-25.376320</td>\n",
       "      <td>-23.129280</td>\n",
       "      <td>-21.466286</td>\n",
       "      <td>-19.981667</td>\n",
       "      <td>-15.222391</td>\n",
       "      <td>-16.233010</td>\n",
       "      <td>-16.017557</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.950730</td>\n",
       "      <td>-35.233840</td>\n",
       "      <td>-26.349930</td>\n",
       "      <td>-17.329056</td>\n",
       "      <td>-12.715102</td>\n",
       "      <td>-12.801040</td>\n",
       "      <td>-15.181746</td>\n",
       "      <td>-12.416152</td>\n",
       "      <td>-13.232986</td>\n",
       "      <td>-15.403823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3316</td>\n",
       "      <td>-4.804248</td>\n",
       "      <td>-3.914425</td>\n",
       "      <td>-7.533999</td>\n",
       "      <td>-12.615092</td>\n",
       "      <td>-7.848448</td>\n",
       "      <td>-6.586810</td>\n",
       "      <td>-5.604166</td>\n",
       "      <td>-5.210299</td>\n",
       "      <td>-7.793556</td>\n",
       "      <td>-5.328217</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.624672</td>\n",
       "      <td>-17.263590</td>\n",
       "      <td>-6.157263</td>\n",
       "      <td>-7.405956</td>\n",
       "      <td>-11.043344</td>\n",
       "      <td>-15.030403</td>\n",
       "      <td>-13.661594</td>\n",
       "      <td>-5.186461</td>\n",
       "      <td>-10.945722</td>\n",
       "      <td>-16.295160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5645</td>\n",
       "      <td>-23.904118</td>\n",
       "      <td>-17.422953</td>\n",
       "      <td>-13.182008</td>\n",
       "      <td>-14.080582</td>\n",
       "      <td>-15.031302</td>\n",
       "      <td>-17.476360</td>\n",
       "      <td>-21.271954</td>\n",
       "      <td>-12.573436</td>\n",
       "      <td>-7.619316</td>\n",
       "      <td>-9.144251</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.022259</td>\n",
       "      <td>-21.562733</td>\n",
       "      <td>-12.196519</td>\n",
       "      <td>-3.379593</td>\n",
       "      <td>-5.561025</td>\n",
       "      <td>-8.924066</td>\n",
       "      <td>-11.111601</td>\n",
       "      <td>-12.788978</td>\n",
       "      <td>-11.337886</td>\n",
       "      <td>-10.009390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>-0.145468</td>\n",
       "      <td>-0.141592</td>\n",
       "      <td>-4.062948</td>\n",
       "      <td>-2.354636</td>\n",
       "      <td>-1.533712</td>\n",
       "      <td>-0.494162</td>\n",
       "      <td>0.049387</td>\n",
       "      <td>0.149454</td>\n",
       "      <td>-1.632070</td>\n",
       "      <td>-4.892538</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.276704</td>\n",
       "      <td>-3.720002</td>\n",
       "      <td>-3.007447</td>\n",
       "      <td>-8.143495</td>\n",
       "      <td>-9.042634</td>\n",
       "      <td>-3.481507</td>\n",
       "      <td>-3.199769</td>\n",
       "      <td>-6.058533</td>\n",
       "      <td>-9.540711</td>\n",
       "      <td>-8.047456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3539</td>\n",
       "      <td>-6.093382</td>\n",
       "      <td>-6.081639</td>\n",
       "      <td>-15.774755</td>\n",
       "      <td>-13.649839</td>\n",
       "      <td>-9.780418</td>\n",
       "      <td>-2.830632</td>\n",
       "      <td>1.321785</td>\n",
       "      <td>1.234120</td>\n",
       "      <td>-0.136949</td>\n",
       "      <td>-3.587718</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.097543</td>\n",
       "      <td>-1.184109</td>\n",
       "      <td>-0.788187</td>\n",
       "      <td>-0.913870</td>\n",
       "      <td>-6.033908</td>\n",
       "      <td>-8.862185</td>\n",
       "      <td>-8.945712</td>\n",
       "      <td>-7.596188</td>\n",
       "      <td>-6.915255</td>\n",
       "      <td>-9.641947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 365 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1983.01.01  1983.01.02  1983.01.03  1983.01.04  1983.01.05  \\\n",
       "ID_HDC_G0                                                               \n",
       "5782       -43.921947  -33.713450  -33.054974  -25.376320  -23.129280   \n",
       "3316        -4.804248   -3.914425   -7.533999  -12.615092   -7.848448   \n",
       "5645       -23.904118  -17.422953  -13.182008  -14.080582  -15.031302   \n",
       "3185        -0.145468   -0.141592   -4.062948   -2.354636   -1.533712   \n",
       "3539        -6.093382   -6.081639  -15.774755  -13.649839   -9.780418   \n",
       "\n",
       "           1983.01.06  1983.01.07  1983.01.08  1983.01.09  1983.01.10  ...  \\\n",
       "ID_HDC_G0                                                              ...   \n",
       "5782       -21.466286  -19.981667  -15.222391  -16.233010  -16.017557  ...   \n",
       "3316        -6.586810   -5.604166   -5.210299   -7.793556   -5.328217  ...   \n",
       "5645       -17.476360  -21.271954  -12.573436   -7.619316   -9.144251  ...   \n",
       "3185        -0.494162    0.049387    0.149454   -1.632070   -4.892538  ...   \n",
       "3539        -2.830632    1.321785    1.234120   -0.136949   -3.587718  ...   \n",
       "\n",
       "           1983.12.22  1983.12.23  1983.12.24  1983.12.25  1983.12.26  \\\n",
       "ID_HDC_G0                                                               \n",
       "5782       -24.950730  -35.233840  -26.349930  -17.329056  -12.715102   \n",
       "3316       -11.624672  -17.263590   -6.157263   -7.405956  -11.043344   \n",
       "5645       -20.022259  -21.562733  -12.196519   -3.379593   -5.561025   \n",
       "3185        -9.276704   -3.720002   -3.007447   -8.143495   -9.042634   \n",
       "3539        -4.097543   -1.184109   -0.788187   -0.913870   -6.033908   \n",
       "\n",
       "           1983.12.27  1983.12.28  1983.12.29  1983.12.30  1983.12.31  \n",
       "ID_HDC_G0                                                              \n",
       "5782       -12.801040  -15.181746  -12.416152  -13.232986  -15.403823  \n",
       "3316       -15.030403  -13.661594   -5.186461  -10.945722  -16.295160  \n",
       "5645        -8.924066  -11.111601  -12.788978  -11.337886  -10.009390  \n",
       "3185        -3.481507   -3.199769   -6.058533   -9.540711   -8.047456  \n",
       "3539        -8.862185   -8.945712   -7.596188   -6.915255   -9.641947  \n",
       "\n",
       "[5 rows x 365 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13067\n"
     ]
    }
   ],
   "source": [
    "df_RH_id = RH['ID_HDC_G0'] # get IDs\n",
    "df_RH = RH.iloc[:,3:] # get only temp columns\n",
    "df_RH.index = df_RH_id # set index values\n",
    "df_RH_drop = df_RH.dropna() # Drop cities w/ no temp record \n",
    "print(len(df_RH_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make them into a data array\n",
    "\n",
    "temp_xr_da = xr.DataArray(df_temp_drop, coords=[df_temp_drop.index, df_temp_drop.columns], \n",
    "                            dims=['ID_HDC_G0', 'date'])\n",
    "RH_xr_da = xr.DataArray(df_RH_drop, coords=[df_RH_drop.index, df_RH_drop.columns], \n",
    "                            dims=['ID_HDC_G0', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hi(Tmax, RH, unit):\n",
    "    \n",
    "    \"\"\"Make Heat Index from 2m air and relative humidity following NOAA's guidelines: \n",
    "    https://www.wpc.ncep.noaa.gov/html/heatindex_equation.shtml. It is assumed that the\n",
    "    tempatures and RH are geographically and temporally aligned in the x-arrays and can be stacked\n",
    "    to the funciton.\n",
    "    \n",
    "    --- update as needed cpt 2020.02.17\n",
    "    \n",
    "    Args:\n",
    "        Tmax = x-array of tempatures\n",
    "        RH = x-array of realtive humitity\n",
    "        unit = F or C\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Make all data as float\n",
    "    Tmax = Tmax.astype('float')\n",
    "    RH = RH.astype('float')\n",
    "    \n",
    "    # 1 convert C to F if needed\n",
    "    if unit == 'C':\n",
    "        Tmax = C_to_F(Tmax)\n",
    "        \n",
    "    # 2 Apply Steadman's and average with Tmax\n",
    "    USE_STEADMAN = (0.5 * (Tmax + 61.0 + ((Tmax-68.0)*1.2) + (RH*0.094)) + Tmax) / 2 < 80\n",
    "    STEADMAN = 0.5 * (Tmax + 61.0 + ((Tmax-68.0)*1.2) + (RH*0.094)) * USE_STEADMAN.astype(int)\n",
    "    \n",
    "    # 3 Use Rothfusz if (STEADMAN + Tmax) / 2 > 80\n",
    "    USE_ROTH = (0.5 * (Tmax + 61.0 + ((Tmax-68.0)*1.2) + (RH*0.094)) + Tmax) / 2 > 80\n",
    "    ROTH = USE_ROTH * (-42.379 + 2.04901523*Tmax + 10.14333127*RH - .22475541*Tmax *RH - .00683783*Tmax*Tmax - .05481717*RH*RH + .00122874*Tmax*Tmax*RH + .00085282*Tmax*RH*RH - .00000199*Tmax*Tmax*RH*RH)\n",
    "\n",
    "    # 3 Adjust Roth 1\n",
    "    USE_ADJ1 = (RH < 13) & (Tmax > 80) & (Tmax < 112)\n",
    "    ADJ1_RH = USE_ADJ1.astype(int) * RH\n",
    "    ADJ1_RH[ADJ1_RH == 0] = np.nan\n",
    "    ADJ1_Tmax = USE_ADJ1.astype(int) * Tmax\n",
    "    ADJ1_Tmax[ADJ1_Tmax == 0] = np.nan\n",
    "    ADJ1 = ((13-ADJ1_RH)/4)*np.sqrt((17-abs(ADJ1_Tmax-95.))/17)\n",
    "    ADJ1 = np.nan_to_num(ADJ1, 0)\n",
    "    \n",
    "    ADJ1_ROTH = ROTH * USE_ADJ1\n",
    "    ADJ1_ROTH = ADJ1_ROTH - ADJ1\n",
    "    \n",
    "    # 4 Adjust Roth 2\n",
    "    USE_ADJ2 = (RH > 85) & (Tmax > 80) & (Tmax < 87)\n",
    "    ADJ2_RH = USE_ADJ2.astype(int) * RH\n",
    "    ADJ2_RH[ADJ2_RH == 0] = np.nan\n",
    "    ADJ2_Tmax = USE_ADJ2.astype(int) * Tmax\n",
    "    ADJ2_Tmax[ADJ2_Tmax == 0] = np.nan\n",
    "    ADJ2 = ((ADJ2_RH-85)/10) * ((87-ADJ2_Tmax)/5)\n",
    "    ADJ2 = np.nan_to_num(ADJ2, 0)\n",
    "    \n",
    "    ADJ2_ROTH = ROTH * USE_ADJ2\n",
    "    ADJ2_ROTH = ADJ2_ROTH + ADJ2\n",
    "    \n",
    "    # Roth w/o adjustments\n",
    "    ROTH = ROTH * ~USE_ADJ1 * ~USE_ADJ2\n",
    "    \n",
    "    HI = ROTH + STEADMAN + ADJ1_ROTH +  ADJ2_ROTH \n",
    "\n",
    "    return STEADMAN, ADJ1_ROTH, ADJ2_ROTH, ROTH, HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stead  [66.935  0.     0.     0.   ]\n",
      "Adj1 [ 0.         94.12248266  0.          0.        ]\n",
      "Adj2 [  0.          0.        101.7808036   0.       ]\n",
      "Roth [ 0.         0.         0.        97.4739604]\n",
      "All HI values [ 66.935       94.12248266 101.7808036   97.4739604 ]\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([70, 100, 85, 100])\n",
    "rh = np.array([5, 10, 90, 20])\n",
    "a,b,c,d, e = hi(temp, rh, 'F')\n",
    "print('Stead ', a)\n",
    "print('Adj1', b)\n",
    "print('Adj2', c)\n",
    "print('Roth', d)\n",
    "print('All HI values', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "2-dimensional boolean indexing is not supported. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-fa13a61c7b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_xr_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRH_xr_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-204-9ca1548aa33b>\u001b[0m in \u001b[0;36mhi\u001b[0;34m(Tmax, RH, unit)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mUSE_ADJ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mRH\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTmax\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTmax\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mADJ1_RH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUSE_ADJ1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mRH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mADJ1_RH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mADJ1_RH\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mADJ1_Tmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUSE_ADJ1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mADJ1_Tmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mADJ1_Tmax\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0;31m# TODO Coordinate consistency in key is checked here, but it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;31m# causes unnecessary indexing. It should be optimized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0massert_coordinate_consistent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;31m# xarray-style array indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_key_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36misel\u001b[0;34m(self, indexers, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meither_dict_or_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'isel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_temp_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_temp_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36misel\u001b[0;34m(self, indexers, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m                 new_var, new_index = isel_variable_and_index(\n\u001b[0;32m-> 1709\u001b[0;31m                     name, var, self.indexes[name], var_indexers)\n\u001b[0m\u001b[1;32m   1710\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                     \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/indexes.py\u001b[0m in \u001b[0;36misel_variable_and_index\u001b[0;34m(name, variable, index, indexers)\u001b[0m\n\u001b[1;32m     75\u001b[0m             'supported yet')\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mnew_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36misel\u001b[0;34m(self, indexers, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0marray\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \"\"\"\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36m_broadcast_indexes\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_indexes_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;31m# Detect it can be mapped as an outer indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# If all key is unlabeled, or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36m_validate_indexers\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    530\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                         raise IndexError(\"{}-dimensional boolean indexing is \"\n\u001b[0;32m--> 532\u001b[0;31m                                          \"not supported. \".format(k.ndim))\n\u001b[0m\u001b[1;32m    533\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dims'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                         raise IndexError(\n",
      "\u001b[0;31mIndexError\u001b[0m: 2-dimensional boolean indexing is not supported. "
     ]
    }
   ],
   "source": [
    "out = hi(temp_xr_da, RH_xr_da, 'C') # STILL THROWS ERROR FIX IT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (ID_HDC_G0: 13067, date: 365)>\n",
       "array([[-58.522195, -37.734858, -37.350249, ...,   5.016019,   3.266131,\n",
       "         -1.451031],\n",
       "       [ 19.871862,  21.849438,  14.682683, ...,  19.287551,   7.035218,\n",
       "         -3.388148],\n",
       "       [-19.270878,  -6.328346,   2.178967, ...,   3.004099,   5.994415,\n",
       "          8.53758 ],\n",
       "       ...,\n",
       "       [ 59.413433,  62.602085,  68.19485 , ...,  56.50039 ,  57.643709,\n",
       "         57.960996],\n",
       "       [ 60.330751,  62.956897,  72.088421, ...,  58.798203,  59.665261,\n",
       "         59.567616],\n",
       "       [ 60.374171,  62.029178,  69.824431, ...,  56.143717,  57.659722,\n",
       "         55.354089]])\n",
       "Coordinates:\n",
       "  * ID_HDC_G0  (ID_HDC_G0) int64 5782 3316 5645 3185 ... 1116 1114 1161 1169\n",
       "  * date       (date) object '1983.01.01' '1983.01.02' ... '1983.12.31'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_xr(file_in, time_dim, space_dim):\n",
    "    \n",
    "    \"\"\" Function reads in a csv w/ GHS-UCDB IDs and temp, isolates the temp\n",
    "    and returns a xarray data array with dims set to city ids and dates\n",
    "    \n",
    "    Args:\n",
    "        file_in = file name and path\n",
    "        time_dim = name for time dim as a str ... use date :-)\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_in) # read the file in as a df\n",
    "    print(df.shape)\n",
    "    \n",
    "    df_id = df[space_dim] # get IDs\n",
    "    df_temp = df.iloc[:,3:] # get only temp columns\n",
    "    df_temp.index = df_id # set index values\n",
    "    df_temp_drop = df_temp.dropna() # Drop cities w/ no temp record \n",
    "    print(len(df_temp_drop))\n",
    "    \n",
    "    temp_np = df_temp_drop.to_numpy() # turn temp cols into an np array\n",
    "    \n",
    "    # make xr Data Array w/ data as temp and dims as spece (e.g. id)\n",
    "    \n",
    "    # Note 2019 09 17 changed to xr.Dataset from xr.Dataarray\n",
    "    temp_xr_da = xr.DataArray(temp_np, coords=[df_temp_drop.index, df_temp_drop.columns], \n",
    "                            dims=[space_dim, time_dim])\n",
    "    \n",
    "    return temp_xr_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2 Function finds all the Tmax Events and writes it to a dateframe w/ dates for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_days(xarray, Tthresh):\n",
    "    \"\"\" Function finds all the tmax days in a year and sums total days per year \n",
    "    greater than a threshold within a year where Tmax > Tthresh for each city. Returns the total number of days,\n",
    "    the dates, the tempatures, and the intensity (daily Tmax - Tthresh)\n",
    "    \n",
    "    Args: \n",
    "        xarray = an xarray object with dims = (space, times)\n",
    "        Tthresh = int of temp threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty lists & df\n",
    "    id_list = []\n",
    "    date_list = []\n",
    "    dayTot_list = []\n",
    "    tmax_list = []\n",
    "    intensity_list = []\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # subset xarray\n",
    "    out = xarray.where(xarray > Tthresh, drop = True)\n",
    "\n",
    "    # start loop \n",
    "    for index, loc in enumerate(out.ID_HDC_G0):\n",
    "        id_list.append(out.ID_HDC_G0.values[index]) # get IDS\n",
    "        date_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values) # get event dates\n",
    "        \n",
    "        # this is actually getting the total events of all, 2019-09-22\n",
    "        dayTot_list.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values)) # get event totals\n",
    "        \n",
    "        tmax_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values) # get temp values\n",
    "        intensity_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values - Tthresh) # get severity\n",
    "\n",
    "    # write to a data frame\n",
    "    df_out['ID_HDC_G0'] = id_list\n",
    "    df_out['total_days'] = dayTot_list\n",
    "    df_out['dates'] = date_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "    df_out['tmax_tntensity'] = intensity_list\n",
    "\n",
    "    # return df_out\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #3 Function splits the dataset into Tmax events (continuous days >Tmax) for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jul_convert(dates):\n",
    "    \"Function turn days into julian datetime\"\n",
    "    jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "    \n",
    "    return jul_days\n",
    "\n",
    "def event_split(dates, ID_HDC_G0, intensity, tmax, total_days):\n",
    "    \"\"\" Searchs a list of dates and isolates sequential dates as a list, then calculates event stats.\n",
    "    See comments in code for more details. \n",
    "    \n",
    "    Args:\n",
    "        dates: pandas.core.index as julian dates\n",
    "        ID_HDC_G0: city ID as string\n",
    "        country: country for each city as string\n",
    "        intensity: numpy.ndarray of intensities values\n",
    "        tmax: numpy.ndarray of intensities values of tmax values\n",
    "        total_days: total number of tmax days in a year for a given city\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # city id\n",
    "    city_id = ID_HDC_G0\n",
    "    tot_days = total_days\n",
    "    \n",
    "    # lists to fill\n",
    "    city_id_list = []\n",
    "    tot_days_list = []\n",
    "    event_dates_list = []\n",
    "    dur_list = []\n",
    "    intensity_list = []\n",
    "    tmax_list = []\n",
    "    avg_temp_list = []\n",
    "    avg_int_list = []\n",
    "    tot_int_list = []\n",
    "    \n",
    "    # data frame out\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # turn days into julian days\n",
    "    jul_days = jul_convert(dates)\n",
    "    \n",
    "    # Counters to make sure we write the correct event dates to a list, don't want julian days in output\n",
    "    counter = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    # Loop through dur list and isolate seq days, temps, and intensities\n",
    "    for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "        \n",
    "        seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "        dur = len(seq) # duration of each event\n",
    "        \n",
    "        counter = counter + dur # add duration to counter\n",
    "        end = counter # end of current event\n",
    "        \n",
    "        event_dates = dates[start:end] # dates of tmax days during each event\n",
    "        intense = intensity[start:end] # intensity of each day during event\n",
    "        temp = tmax[start:end] # temp of each day during event\n",
    "        avg_temp = mean(temp) # avg. temp during event\n",
    "        avg_int = mean(intense) # avg. intensity during event\n",
    "        tot_int = intense.sum() # total intensity during event\n",
    "        \n",
    "        start = counter # reset start to current end (e.g. counter)\n",
    "        \n",
    "        # fill lists\n",
    "        city_id_list.append(city_id)\n",
    "        tot_days_list.append(tot_days)\n",
    "        dur_list.append(dur)\n",
    "        event_dates_list.append(event_dates)\n",
    "        intensity_list.append(intense)\n",
    "        tmax_list.append(temp)\n",
    "        avg_temp_list.append(avg_temp)\n",
    "        avg_int_list.append(avg_int)\n",
    "        tot_int_list.append(tot_int)\n",
    "\n",
    "    # write out as a dateframe\n",
    "    df_out['ID_HDC_G0'] = city_id_list\n",
    "    df_out['total_days'] = tot_days_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['avg_temp'] = avg_temp_list\n",
    "    df_out['avg_intensity'] = avg_int_list\n",
    "    df_out['tot_intensity'] = tot_int_list\n",
    "    df_out['event_dates'] = event_dates_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['intensity'] = intensity_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #4 Function feeds output from function 2 into function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_stats(df_in):\n",
    "    \"\"\" runs event_split functionon a dataframe to produce desired tmax stats\n",
    "    \n",
    "        NOTE - If you add arguments to event_split to make more states, \n",
    "        be sure to update this function\n",
    "    \n",
    "        args:\n",
    "            df: input dataframe\n",
    "        \n",
    "    \"\"\"\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # NOTE - If you add arguments to event_split to make more stats, \n",
    "    # be sure to update this function\n",
    "    \n",
    "    for index, row in df_in.iterrows():\n",
    "        dates = row['dates'] # Get event dates\n",
    "        intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "        tmax = row['tmax'] # Get tmax for each day\n",
    "        ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "        total_days = row['total_days'] # get total number of tmax days\n",
    "\n",
    "        df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "\n",
    "        df_out = df_out.append(df)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #5 Loops through a file list and applies functions 1 - 4 to the data to produce Tmax stats for all tmax events in a given year across all cities in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_loop(dir_in, dir_out, fn_out, time_dim, space_dim, Tthresh):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs to apply csv_to_xr and\n",
    "    tmax_stats function and save out a .csv for each year\n",
    "    \n",
    "    Args:\n",
    "        dir_in = dir path to loop through\n",
    "        dir_out = dir path to save files out\n",
    "        fn_out = string to label out files\n",
    "        time_dim = name for time dim as a str ... use date :-) for csv_to_xr function\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0) for csv_to_xr function\n",
    "        Tthresh = int of temp threshold for temp_event function -- 40.6 is used\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the GHS-ID List with GeoPANDAS read_file\n",
    "    ghs_ids_fn = 'GHS-UCSB-IDS.csv'\n",
    "    ghs_ids_df = pd.read_csv(DATA_INTERIM+ghs_ids_fn)\n",
    "        \n",
    "    # Git File list\n",
    "    fn_list = glob.glob(dir_in+'*.csv')\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "        \n",
    "        # Get year for arg for temp_event function\n",
    "        year = fn.split('GHS-Tmax-DAILY_')[1].split('.csv')[0]\n",
    "        print(year)\n",
    "        \n",
    "        # read csv as a data array\n",
    "        temp_xr_da = csv_to_xr(fn, time_dim, space_dim)\n",
    "        \n",
    "        # data array to tmax events, out as df\n",
    "        df_days = tmax_days(temp_xr_da, Tthresh)\n",
    "        \n",
    "        # tmax events stats, out as df\n",
    "        df_out = tmax_stats(df_days)\n",
    "        \n",
    "        # merge to get countries\n",
    "        ghs_ids_df_out = ghs_ids_df.merge(df_out, on='ID_HDC_G0', how = 'inner') \n",
    "        \n",
    "        # write it all out\n",
    "        ghs_ids_df_out.to_csv(dir_out+fn_out+year+'.csv')\n",
    "\n",
    "        print(year, 'SAVED!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/' # ghs ID list\n",
    "dir_out = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'\n",
    "fn_out = 'CHIRTS-GHS-Events-Stats'\n",
    "time_dim = 'date'\n",
    "space_dim = 'ID_HDC_G0'\n",
    "Tthresh = 40.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stats_loop(dir_in, dir_out, fn_out, time_dim, space_dim, Tthresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA/QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "\n",
    "dir_out = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'\n",
    "fn_out = 'CHIRTS-GHS-Events-Stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_df = pd.read_csv(dir_out+fn_out+'1983.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_city = qc_df[qc_df['ID_HDC_G0'] == 5534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/data_out_urbanheat/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open a raw file\n",
    "xr1983 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days1983 = tmax_days(xr1983, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = days1983[0:30]\n",
    "test\n",
    "\n",
    "# Maybe add in days_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build routine for loop through a csv\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "    \n",
    "    df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "    \n",
    "    df_out = df_out.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing code\n",
    "2019.10.19 Cascade Tuholkse\n",
    "\n",
    "Need to fix ```event split``` function\n",
    "\n",
    "Somewhere in 1984 is this event sequence: ['1984.01.01' '1984.01.02' '1984.01.07']\n",
    "\n",
    "\n",
    "**FOUND PROBLEM AND IT IS FIXED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/data_out_urbanheatv/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out_urbanheat/testout/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open a raw file\n",
    "xr1983 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the tmax days\n",
    "tmax1983 = tmax_days(xr1983, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset\n",
    "\n",
    "test = tmax1983[tmax1983['ID_HDC_G0'] == 6279]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to jul days\n",
    "jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "jul_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjd = 2445507.5 - 43200\n",
    "dt = julian.from_jd(mjd, fmt='mjd')\n",
    "print(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['1983.06.20', '1983.06.23', '1983.06.24', '1983.06.25',\n",
    "        '1983.06.26', '1983.06.27', '1983.06.28', '1983.06.29',\n",
    "        '1983.06.30', '1983.07.01', '1983.07.21', '1983.07.22',\n",
    "        '1983.07.23', '1983.08.01']\n",
    "\n",
    "pd_dates = pd.to_datetime(dates)\n",
    "df_dates = pd.DataFrame()\n",
    "df_dates['dates'] = pd_dates\n",
    "\n",
    "\n",
    "\n",
    "test = df_dates['dates'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "date.fromordinal(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = dates[0:10] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))\n",
    "\n",
    "event_dates = dates[10:13] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))\n",
    "\n",
    "event_dates = dates[13:14] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates_list = []\n",
    "counter = 0\n",
    "start = 0\n",
    "end = 0\n",
    "\n",
    "for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "    \n",
    "    len_dates = len(dates) # len of all Tmax dates for a given city\n",
    "#   print(len(dates))\n",
    "    \n",
    "    seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "    dur = len(seq) # duration of each event \n",
    "    \n",
    "    counter = counter + dur\n",
    "    end = counter\n",
    "    \n",
    "    print(end)\n",
    "    \n",
    "    event_dates = dates[start:end] # dates of tmax days during each event\n",
    "    print(event_dates)\n",
    "    \n",
    "    start = counter\n",
    "    \n",
    "# #     print('dur= ', dur)\n",
    "    \n",
    "#     event_dates = dates[0:10] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "#     event_dates = dates[11:13] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "#     event_dates = dates[:len_dates] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     counter = counter + dur\n",
    "\n",
    "#     print('counter = ', counter)\n",
    "    \n",
    "#     dif = dur - counter\n",
    "#     print('dif = ', dif)\n",
    "    \n",
    "#     start = start \n",
    "#     print('start = ',start)\n",
    "    \n",
    "# #     end = counter + dur\n",
    "# #     print(\"start = \",end)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     counter = counter + dur\n",
    "#     print(counter)\n",
    "#     end = counter + dur\n",
    "#     start\n",
    "#     event_dates = dates[start:end] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "# #     intense = intensity[0:dur] # intensity of each day during event\n",
    "#     temp = tmax[0:dur] # temp of each day during event\n",
    "#     avg_temp = mean(temp) # avg. temp during event\n",
    "#     avg_int = mean(intense) # avg. intensity during event\n",
    "#     tot_int = intense.sum() # total intensity during event\n",
    "    \n",
    "#     event_dates_list.append(event_dates)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['event_dates'] = event_dates_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tmax stats ------> CLEARLY NOTE WORKING\n",
    "\n",
    "# tmax1983_sub_stats = tmax_stats(tmax1983_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmax1983['dates'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = tmax1983_sub['dates']\n",
    "#jul_days = pd.to_datetime(tmax1983['dates']).to_julian_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to break up events\n",
    "\n",
    "for index, row in tmax1983_sub.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "\n",
    "#     df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "\n",
    "#     df_out = df_out.append(df)\n",
    "\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_out['events'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Heat Index\n",
    "\n",
    "Get some paired values from the [NOAA CHART](https://www.weather.gov/safety/heat-index) and test the output. \n",
    "\n",
    "These results seem to be working well, though 104 F and 60 RH produced a higher number than the chart ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [25, 27, 35, 40, 41] # temp C\n",
    "RH = 60\n",
    "test = pd.DataFrame()\n",
    "test['temp'] = temp\n",
    "test['RH'] = RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tmax_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-013aee025114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_hi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-11de9e2cba06>\u001b[0m in \u001b[0;36mmake_hi\u001b[0;34m(Tmax_F, RH)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_hi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTmax_F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"Calculates the heat index for a CHIRTS Tmax value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mTmax_F\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_to_F\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTmax_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print('F is ', Tmax_F)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print('H is ', RH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tmax_C' is not defined"
     ]
    }
   ],
   "source": [
    "for i, row in test.iterrows():\n",
    "    out = make_hi(row['temp'], row['RH'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the temp x array from C to F\n",
    "\n",
    "temp_xr_da = C_to_F(temp_xr_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply steadman's\n",
    "\n",
    "HI_steadman = steadman_hi(temp_xr_da, RH_xr_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## this doesn't work \n",
    "#HI_rothfusz = rothfusz_hi(HI_steadman, temp_xr_da, RH_xr_da)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
