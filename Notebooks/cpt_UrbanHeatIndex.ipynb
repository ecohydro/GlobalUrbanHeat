{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Heat Index\n",
    "\n",
    "By Cascade Tuholske 2020.01.21\n",
    "\n",
    "Notebook is designed to take areal-averaged CHIRTS Tmax for each GHS-UCDB and down-scaled MERRA-2 humidity data and calculate the heat index for each city with a Tmax >80F.\n",
    "\n",
    "[NOAA Heat Index Equation](https://www.wpc.ncep.noaa.gov/html/heatindex_equation.shtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THINGS I HAVE Coded**\n",
    "- C to F function\n",
    "- Rothfusz regression and adjustments\n",
    "- Steadman's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES**\n",
    "At first I thought the heat index values for the hottest areas were insane (> 140F), but I spot checked the results and the [NOAA Heat Index Table](https://www.kjrh.com/weather/weather-blog-what-exaclty-is-the-heat-index) simply reds out values where Tmax >40C and RH > 50%. So I guess were are on track ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from random import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import geopandas as gpd \n",
    "import glob\n",
    "from statistics import mean\n",
    "import julian\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_to_F(Tmax_C):\n",
    "    \"Function converts temp in C to F\"\n",
    "    Tmax_F = (Tmax_C * (9/5)) + 32\n",
    "    \n",
    "    return Tmax_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_to_C(Tmax_F):\n",
    "    \"Function converts temp in F to C\"\n",
    "    Tmax_C = (Tmax_F - 32) * (5/9)\n",
    "    \n",
    "    return Tmax_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_xr(file_in, time_dim, space_dim):\n",
    "    \n",
    "    \"\"\" Function reads in a csv w/ GHS-UCDB IDs and temp, isolates the temp\n",
    "    and returns a xarray data array with dims set to city ids and dates\n",
    "    \n",
    "    Args:\n",
    "        file_in = file name and path\n",
    "        time_dim = name for time dim as a str ... use date :-)\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_in) # read the file in as a df\n",
    "    print(df.shape)\n",
    "    \n",
    "    df_id = df[space_dim] # get IDs\n",
    "    df = df.iloc[:,3:] # get only temp columns\n",
    "    df.index = df_id # set index values\n",
    "    df_drop = df.dropna() # Drop cities w/ no temp record \n",
    "    print(len(df_drop))\n",
    "    \n",
    "    arr = df_drop.to_numpy() # turn temp cols into an np array\n",
    "    \n",
    "    # make xr Data Array w/ data as temp and dims as spece (e.g. id)\n",
    "    \n",
    "    # Note 2019 09 17 changed to xr.Dataset from xr.Dataarray\n",
    "    xr_da = xr.DataArray(arr, coords=[df_drop.index, df_drop.columns], \n",
    "                            dims=[space_dim, time_dim])\n",
    "    return xr_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatindex(Tmax, RH, unit_in, unit_out):\n",
    "    \n",
    "    \"\"\"Make Heat Index from 2m air and relative humidity following NOAA's guidelines: \n",
    "    https://www.wpc.ncep.noaa.gov/html/heatindex_equation.shtml. It is assumed that the\n",
    "    tempatures and RH are geographically and temporally aligned in the x-arrays and can be stacked\n",
    "    to the funciton.\n",
    "    \n",
    "    --- update as needed cpt 2020.02.17\n",
    "    \n",
    "    Args:\n",
    "        Tmax = x-array of tempatures\n",
    "        RH = x-array of realtive humitity\n",
    "        unit_in = F or C, will convert C to F to apply heat index\n",
    "        unit_out = If C is desired, will convert data to C\n",
    "        \n",
    "    Returns HI\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make all data as float\n",
    "    Tmax = Tmax.astype('float')\n",
    "    RH = RH.astype('float')\n",
    "    \n",
    "    # 1 convert C to F if needed\n",
    "    if unit_in == 'C':\n",
    "        Tmax = C_to_F(Tmax)\n",
    "        \n",
    "    # 2 Apply Steadman's and average with Tmax\n",
    "    USE_STEADMAN = (0.5 * (Tmax + 61.0 + ((Tmax-68.0)*1.2) + (RH*0.094)) + Tmax) / 2 < 80\n",
    "    STEADMAN = USE_STEADMAN * (0.5 * (Tmax + 61.0 + ((Tmax-68.0)*1.2) + (RH*0.094))) #.astype(int)\n",
    "    \n",
    "    # 3 Use Rothfusz if (STEADMAN + Tmax) / 2 > 80\n",
    "    USE_ROTH = (0.5 * (Tmax + 61.0 + ((Tmax-68.0)*1.2) + (RH*0.094)) + Tmax) / 2 > 80\n",
    "    ROTH = USE_ROTH * (-42.379 + 2.04901523*Tmax + 10.14333127*RH - .22475541*Tmax *RH - .00683783*Tmax*Tmax - .05481717*RH*RH + .00122874*Tmax*Tmax*RH + .00085282*Tmax*RH*RH - .00000199*Tmax*Tmax*RH*RH)\n",
    "\n",
    "    # 3 Adjust Roth 1\n",
    "    USE_ADJ1 = (RH < 13) & (Tmax > 80) & (Tmax < 112)\n",
    "    ADJ1_RH = USE_ADJ1 * RH #.astype(int)\n",
    "    ADJ1_RH = ADJ1_RH.where(ADJ1_RH != 0) #ADJ1_RH[ADJ1_RH == 0] = np.nan\n",
    "    ADJ1_Tmax = USE_ADJ1 * Tmax # .astype(int)\n",
    "    ADJ1_Tmax = ADJ1_Tmax.where(ADJ1_Tmax != 0) #ADJ1_Tmax[ADJ1_Tmax == 0] = np.nan\n",
    "    ADJ1 = ((13-ADJ1_RH)/4)*np.sqrt((17-abs(ADJ1_Tmax-95.))/17)\n",
    "    ADJ1 = np.nan_to_num(ADJ1, 0)\n",
    "    \n",
    "    ADJ1_ROTH = ROTH * USE_ADJ1\n",
    "    ADJ1_ROTH = ADJ1_ROTH - ADJ1\n",
    "    \n",
    "    # 4 Adjust Roth 2\n",
    "    USE_ADJ2 = (RH > 85) & (Tmax > 80) & (Tmax < 87)\n",
    "    ADJ2_RH = USE_ADJ2 * RH #.astype(int)\n",
    "    ADJ2_RH = ADJ2_RH.where(ADJ2_RH != 0) #ADJ2_RH[ADJ2_RH == 0] = np.nan\n",
    "    ADJ2_Tmax = USE_ADJ2.astype(int) * Tmax\n",
    "    ADJ2_Tmax = ADJ2_Tmax.where(ADJ2_Tmax != 0) #ADJ2_Tmax[ADJ2_Tmax == 0] = np.nan\n",
    "    ADJ2 = ((ADJ2_RH-85)/10) * ((87-ADJ2_Tmax)/5)\n",
    "    ADJ2 = np.nan_to_num(ADJ2, 0)\n",
    "    \n",
    "    ADJ2_ROTH = ROTH * USE_ADJ2\n",
    "    ADJ2_ROTH = ADJ2_ROTH + ADJ2\n",
    "    \n",
    "    # Roth w/o adjustments\n",
    "    ROTH = ROTH * ~USE_ADJ1 * ~USE_ADJ2\n",
    "    \n",
    "    # sum the stacked arrays\n",
    "    HI = ROTH + STEADMAN + ADJ1_ROTH +  ADJ2_ROTH \n",
    "    \n",
    "    # Convert HI to C if desired\n",
    "    if unit_out == 'C':\n",
    "        HI = F_to_C(HI)\n",
    "    \n",
    "    # return for test\n",
    "    # return STEADMAN, ADJ1_ROTH, ADJ2_ROTH, ROTH, HI\n",
    "    \n",
    "    return HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_heatindex(DIR_Tmax, DIR_RH, DIR_HI, unit_in, unit_out):\n",
    "    \"\"\"Function applies NOAA's heatindex to two pair directories w/ CSVs of realitive humidity\n",
    "    and tempatures, respective, in a pairwise fashion\n",
    "    \n",
    "    Args:\n",
    "        DIR_Tmax = the directory where Tmax .csv files are stored\n",
    "        DIR_RH = the directory where RH .csv files are stored\n",
    "        DIR_HI = the directory where HI files will be written\n",
    "        unit_in = temp unit for Tmax (C or F)\n",
    "        unit_out = desired temp unit for HI (C or F) for the output\n",
    "    \"\"\"\n",
    "    Tmax_fn_list = glob.glob(DIR_Tmax+'*.csv')\n",
    "    RH_fn_list = glob.glob(DIR_RH+'*.csv')\n",
    "\n",
    "    for Tmax_fn, RH_fn in zip(sorted(Tmax_fn_list),sorted(RH_fn_list)):\n",
    "    \n",
    "        # Check the years RH and Tmax \n",
    "        Tmax_year = Tmax_fn.split('GHS-Tmax-DAILY_')[1].split('.csv')[0]\n",
    "        print('Tmax year is ',Tmax_year)\n",
    "        RH_year = RH_fn.split('GHS-Tmax-RH_')[1].split('.csv')[0]\n",
    "        print('RH year is ', RH_year)\n",
    "\n",
    "        # Read csv as x-array\n",
    "        Tmax_xr = csv_to_xr(Tmax_fn, time_dim = 'date', space_dim = 'ID_HDC_G0')\n",
    "        RH_xr = csv_to_xr(RH_fn, time_dim = 'date', space_dim = 'ID_HDC_G0')\n",
    "\n",
    "        # Make heat index\n",
    "        hi = heatindex(Tmax_xr, RH_xr, unit_in = unit_in, unit_out = unit_out)\n",
    "\n",
    "\n",
    "        # CASCADE GO LOOK AT HOW X-ARRAYS ARE WRITTEN TO CSVS IN EARLIER CODE <<<<---- \n",
    "\n",
    "        # write to csv\n",
    "        df = hi.to_pandas()\n",
    "        df_out_nm = 'GHS-HI-DAILY_'+Tmax_year+'.csv'\n",
    "        df.to_csv(DIR_HI+df_out_nm)\n",
    "        print(RH_year, ' done \\n')\n",
    "    \n",
    "    print('ALL DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tmax year is  1983\n",
      "RH year is  1983\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1983  done \n",
      "\n",
      "Tmax year is  1984\n",
      "RH year is  1984\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "1984  done \n",
      "\n",
      "Tmax year is  1985\n",
      "RH year is  1985\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1985  done \n",
      "\n",
      "Tmax year is  1986\n",
      "RH year is  1986\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1986  done \n",
      "\n",
      "Tmax year is  1987\n",
      "RH year is  1987\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1987  done \n",
      "\n",
      "Tmax year is  1988\n",
      "RH year is  1988\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "1988  done \n",
      "\n",
      "Tmax year is  1989\n",
      "RH year is  1989\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1989  done \n",
      "\n",
      "Tmax year is  1990\n",
      "RH year is  1990\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1990  done \n",
      "\n",
      "Tmax year is  1991\n",
      "RH year is  1991\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1991  done \n",
      "\n",
      "Tmax year is  1992\n",
      "RH year is  1992\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "1992  done \n",
      "\n",
      "Tmax year is  1993\n",
      "RH year is  1993\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1993  done \n",
      "\n",
      "Tmax year is  1994\n",
      "RH year is  1994\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1994  done \n",
      "\n",
      "Tmax year is  1995\n",
      "RH year is  1995\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1995  done \n",
      "\n",
      "Tmax year is  1996\n",
      "RH year is  1996\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "1996  done \n",
      "\n",
      "Tmax year is  1997\n",
      "RH year is  1997\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1997  done \n",
      "\n",
      "Tmax year is  1998\n",
      "RH year is  1998\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1998  done \n",
      "\n",
      "Tmax year is  1999\n",
      "RH year is  1999\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1999  done \n",
      "\n",
      "Tmax year is  2000\n",
      "RH year is  2000\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2000  done \n",
      "\n",
      "Tmax year is  2001\n",
      "RH year is  2001\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2001  done \n",
      "\n",
      "Tmax year is  2002\n",
      "RH year is  2002\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2002  done \n",
      "\n",
      "Tmax year is  2003\n",
      "RH year is  2003\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2003  done \n",
      "\n",
      "Tmax year is  2004\n",
      "RH year is  2004\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2004  done \n",
      "\n",
      "Tmax year is  2005\n",
      "RH year is  2005\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2005  done \n",
      "\n",
      "Tmax year is  2006\n",
      "RH year is  2006\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2006  done \n",
      "\n",
      "Tmax year is  2007\n",
      "RH year is  2007\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2007  done \n",
      "\n",
      "Tmax year is  2008\n",
      "RH year is  2008\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2008  done \n",
      "\n",
      "Tmax year is  2009\n",
      "RH year is  2009\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2009  done \n",
      "\n",
      "Tmax year is  2010\n",
      "RH year is  2010\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2010  done \n",
      "\n",
      "Tmax year is  2011\n",
      "RH year is  2011\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2011  done \n",
      "\n",
      "Tmax year is  2012\n",
      "RH year is  2012\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2012  done \n",
      "\n",
      "Tmax year is  2013\n",
      "RH year is  2013\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2013  done \n",
      "\n",
      "Tmax year is  2014\n",
      "RH year is  2014\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2014  done \n",
      "\n",
      "Tmax year is  2015\n",
      "RH year is  2015\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2015  done \n",
      "\n",
      "Tmax year is  2016\n",
      "RH year is  2016\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2016  done \n",
      "\n",
      "ALL DONE!\n"
     ]
    }
   ],
   "source": [
    "DIR_Tmax = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-Tmax/'\n",
    "DIR_RH = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-RH/'\n",
    "DIR_HI = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-HI/'\n",
    "\n",
    "# FIRE HI\n",
    "apply_heatindex(DIR_Tmax, DIR_RH, DIR_HI, unit_in = 'C', unit_out = 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stead  <xarray.DataArray (dim_0: 4)>\n",
      "array([66.935,  0.   ,  0.   ,  0.   ])\n",
      "Dimensions without coordinates: dim_0\n",
      "Adj1 <xarray.DataArray (dim_0: 4)>\n",
      "array([ 0.      , 94.122483,  0.      ,  0.      ])\n",
      "Dimensions without coordinates: dim_0\n",
      "Adj2 <xarray.DataArray (dim_0: 4)>\n",
      "array([  0.      ,   0.      , 101.780804,   0.      ])\n",
      "Dimensions without coordinates: dim_0\n",
      "Roth <xarray.DataArray (dim_0: 4)>\n",
      "array([ 0.     ,  0.     ,  0.     , 97.47396])\n",
      "Dimensions without coordinates: dim_0\n",
      "All HI values <xarray.DataArray (dim_0: 4)>\n",
      "array([ 66.935   ,  94.122483, 101.780804,  97.47396 ])\n",
      "Dimensions without coordinates: dim_0\n"
     ]
    }
   ],
   "source": [
    "# Test with the conditions above test\n",
    "temp = xr.DataArray([70, 100, 85, 100])\n",
    "rh = xr.DataArray([5, 10, 90, 20])\n",
    "a,b,c,d, e = heatindex(temp, rh, unit_in = 'F', unit_out = 'F')\n",
    "print('Stead ', a)\n",
    "print('Adj1', b)\n",
    "print('Adj2', c)\n",
    "print('Roth', d)\n",
    "print('All HI values', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray ()>\n",
      "array(40) <xarray.DataArray ()>\n",
      "array(80) <xarray.DataArray (dim_0: 4)>\n",
      "array([79.58,  0.  ,  0.  ,  0.  ])\n",
      "Dimensions without coordinates: dim_0\n",
      "<xarray.DataArray ()>\n",
      "array(40) <xarray.DataArray ()>\n",
      "array(82) <xarray.DataArray (dim_0: 4)>\n",
      "array([0., 0., 0., 0.])\n",
      "Dimensions without coordinates: dim_0\n",
      "<xarray.DataArray ()>\n",
      "array(40) <xarray.DataArray ()>\n",
      "array(94) <xarray.DataArray (dim_0: 4)>\n",
      "array([0., 0., 0., 0.])\n",
      "Dimensions without coordinates: dim_0\n",
      "<xarray.DataArray ()>\n",
      "array(40) <xarray.DataArray ()>\n",
      "array(104) <xarray.DataArray (dim_0: 4)>\n",
      "array([  0.      ,  81.453392,  97.170973, 118.877065])\n",
      "Dimensions without coordinates: dim_0\n",
      "All HI values <xarray.DataArray (dim_0: 4)>\n",
      "array([ 79.58    ,  81.453392,  97.170973, 118.877065])\n",
      "Dimensions without coordinates: dim_0\n"
     ]
    }
   ],
   "source": [
    "# Test with actual data from HI chart : https://www.weather.gov/safety/heat-index\n",
    "# Results fit the table\n",
    "\n",
    "temp = xr.DataArray([80, 82, 94, 104])\n",
    "rh = xr.DataArray([40, 40, 40, 40])\n",
    "a,b,c,d, e = heatindex(temp, rh, unit_in = 'F', unit_out = 'F')\n",
    "print(rh[0], temp[0], a)\n",
    "print(rh[0], temp[1], b)\n",
    "print(rh[0], temp[2], c)\n",
    "print(rh[0], temp[3], d)\n",
    "print('All HI values', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test With CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_RH = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-RH/'\n",
    "DIR_Tmax = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-Tmax/'\n",
    "DIR_HI = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-HI/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_RH = 'GHS-Tmax-RH_1984.csv'\n",
    "FN_Tmax = 'GHS-Tmax-DAILY_1984.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n"
     ]
    }
   ],
   "source": [
    "RH = csv_to_xr(DIR_RH+FN_RH, space_dim = 'ID_HDC_G0', time_dim = 'date')\n",
    "Tmax = csv_to_xr(DIR_Tmax+FN_Tmax, space_dim = 'ID_HDC_G0', time_dim = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = heatindex(Tmax, RH, unit_in = 'C', unit_out = 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_HDC_G0\n",
       "11220    69.308345\n",
       "11182    68.724773\n",
       "10101    61.483578\n",
       "5348     57.905744\n",
       "6284     57.433921\n",
       "5530     57.274213\n",
       "6273     57.244881\n",
       "6286     57.195767\n",
       "10099    56.981850\n",
       "11228    56.764815\n",
       "6320     56.699861\n",
       "5523     56.672009\n",
       "6274     56.379129\n",
       "11199    56.377981\n",
       "6308     56.355506\n",
       "5543     56.245587\n",
       "11284    56.120548\n",
       "6306     56.120305\n",
       "6318     56.069588\n",
       "6311     55.826775\n",
       "5548     55.779169\n",
       "6215     55.771830\n",
       "5493     55.728903\n",
       "6314     55.713507\n",
       "6328     55.711013\n",
       "6333     55.661648\n",
       "6325     55.623955\n",
       "6278     55.591737\n",
       "6253     55.521060\n",
       "6223     55.458858\n",
       "5540     55.421757\n",
       "5509     55.397743\n",
       "11162    55.327412\n",
       "5506     55.325984\n",
       "11104    55.294701\n",
       "11131    55.290137\n",
       "6194     55.211096\n",
       "6269     55.175960\n",
       "6281     54.964046\n",
       "5538     54.913131\n",
       "11167    54.903616\n",
       "6251     54.893903\n",
       "11311    54.855647\n",
       "6257     54.768511\n",
       "11255    54.760381\n",
       "11294    54.734018\n",
       "11202    54.719885\n",
       "6232     54.712800\n",
       "11280    54.613163\n",
       "6247     54.572206\n",
       "Name: 1984.07.01, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd['1984.07.01'].sort_values(ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dir Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-Tmax/\n",
      "/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-RH/\n",
      "Tmax year is  1983\n",
      "RH year is  1983\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1983  done \n",
      "\n",
      "Tmax year is  1984\n",
      "RH year is  1984\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "1984  done \n",
      "\n",
      "Tmax year is  1985\n",
      "RH year is  1985\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1985  done \n",
      "\n",
      "Tmax year is  1986\n",
      "RH year is  1986\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1986  done \n",
      "\n",
      "Tmax year is  1987\n",
      "RH year is  1987\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1987  done \n",
      "\n",
      "Tmax year is  1988\n",
      "RH year is  1988\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "1988  done \n",
      "\n",
      "Tmax year is  1989\n",
      "RH year is  1989\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1989  done \n",
      "\n",
      "Tmax year is  1990\n",
      "RH year is  1990\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1990  done \n",
      "\n",
      "Tmax year is  1991\n",
      "RH year is  1991\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1991  done \n",
      "\n",
      "Tmax year is  1992\n",
      "RH year is  1992\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "1992  done \n",
      "\n",
      "Tmax year is  1993\n",
      "RH year is  1993\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1993  done \n",
      "\n",
      "Tmax year is  1994\n",
      "RH year is  1994\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1994  done \n",
      "\n",
      "Tmax year is  1995\n",
      "RH year is  1995\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1995  done \n",
      "\n",
      "Tmax year is  1996\n",
      "RH year is  1996\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "1996  done \n",
      "\n",
      "Tmax year is  1997\n",
      "RH year is  1997\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1997  done \n",
      "\n",
      "Tmax year is  1998\n",
      "RH year is  1998\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1998  done \n",
      "\n",
      "Tmax year is  1999\n",
      "RH year is  1999\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "1999  done \n",
      "\n",
      "Tmax year is  2000\n",
      "RH year is  2000\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2000  done \n",
      "\n",
      "Tmax year is  2001\n",
      "RH year is  2001\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2001  done \n",
      "\n",
      "Tmax year is  2002\n",
      "RH year is  2002\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2002  done \n",
      "\n",
      "Tmax year is  2003\n",
      "RH year is  2003\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2003  done \n",
      "\n",
      "Tmax year is  2004\n",
      "RH year is  2004\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2004  done \n",
      "\n",
      "Tmax year is  2005\n",
      "RH year is  2005\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2005  done \n",
      "\n",
      "Tmax year is  2006\n",
      "RH year is  2006\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2006  done \n",
      "\n",
      "Tmax year is  2007\n",
      "RH year is  2007\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2007  done \n",
      "\n",
      "Tmax year is  2008\n",
      "RH year is  2008\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2008  done \n",
      "\n",
      "Tmax year is  2009\n",
      "RH year is  2009\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2009  done \n",
      "\n",
      "Tmax year is  2010\n",
      "RH year is  2010\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2010  done \n",
      "\n",
      "Tmax year is  2011\n",
      "RH year is  2011\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2011  done \n",
      "\n",
      "Tmax year is  2012\n",
      "RH year is  2012\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2012  done \n",
      "\n",
      "Tmax year is  2013\n",
      "RH year is  2013\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2013  done \n",
      "\n",
      "Tmax year is  2014\n",
      "RH year is  2014\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2014  done \n",
      "\n",
      "Tmax year is  2015\n",
      "RH year is  2015\n",
      "(13135, 368)\n",
      "13067\n",
      "(13135, 368)\n",
      "13067\n",
      "2015  done \n",
      "\n",
      "Tmax year is  2016\n",
      "RH year is  2016\n",
      "(13135, 369)\n",
      "13067\n",
      "(13135, 369)\n",
      "13067\n",
      "2016  done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get files from both RH and temp\n",
    "\n",
    "DIR_Tmax = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-Tmax/'\n",
    "DIR_RH = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-RH/'\n",
    "DIR_HI = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-HI/'\n",
    "\n",
    "print(DIR_Tmax)\n",
    "print(DIR_RH) \n",
    "\n",
    "Tmax_fn_list = glob.glob(DIR_Tmax+'*.csv')\n",
    "RH_fn_list = glob.glob(DIR_RH+'*.csv')\n",
    "\n",
    "for Tmax_fn, RH_fn in zip(sorted(Tmax_fn_list),sorted(RH_fn_list)):\n",
    "    \n",
    "    # Check the years RH and Tmax \n",
    "    Tmax_year = Tmax_fn.split('GHS-Tmax-DAILY_')[1].split('.csv')[0]\n",
    "    print('Tmax year is ',Tmax_year)\n",
    "    RH_year = RH_fn.split('GHS-Tmax-RH_')[1].split('.csv')[0]\n",
    "    print('RH year is ', RH_year)\n",
    "    \n",
    "    # Read csv as x-array\n",
    "    Tmax_xr = csv_to_xr(Tmax_fn, time_dim = 'date', space_dim = 'ID_HDC_G0')\n",
    "    RH_xr = csv_to_xr(RH_fn, time_dim = 'date', space_dim = 'ID_HDC_G0')\n",
    "    \n",
    "    # Make heat index\n",
    "    hi = heatindex(Tmax_xr, RH_xr, unit_in = 'C', unit_out = 'F')\n",
    "    \n",
    "\n",
    "    # CASCADE GO LOOK AT HOW X-ARRAYS ARE WRITTEN TO CSVS IN EARLIER CODE <<<<---- \n",
    "    \n",
    "    # write to csv\n",
    "    df = hi.to_pandas()\n",
    "    df_out_nm = 'GHS-HI-DAILY_'+Tmax_year+'.csv'\n",
    "    df.to_csv(DIR_HI+df_out_nm)\n",
    "    print(RH_year, ' done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2016.01.01</th>\n",
       "      <th>2016.01.02</th>\n",
       "      <th>2016.01.03</th>\n",
       "      <th>2016.01.04</th>\n",
       "      <th>2016.01.05</th>\n",
       "      <th>2016.01.06</th>\n",
       "      <th>2016.01.07</th>\n",
       "      <th>2016.01.08</th>\n",
       "      <th>2016.01.09</th>\n",
       "      <th>2016.01.10</th>\n",
       "      <th>...</th>\n",
       "      <th>2016.12.22</th>\n",
       "      <th>2016.12.23</th>\n",
       "      <th>2016.12.24</th>\n",
       "      <th>2016.12.25</th>\n",
       "      <th>2016.12.26</th>\n",
       "      <th>2016.12.27</th>\n",
       "      <th>2016.12.28</th>\n",
       "      <th>2016.12.29</th>\n",
       "      <th>2016.12.30</th>\n",
       "      <th>2016.12.31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5782</td>\n",
       "      <td>-22.592424</td>\n",
       "      <td>-23.554328</td>\n",
       "      <td>2.574384</td>\n",
       "      <td>-0.192710</td>\n",
       "      <td>-19.426103</td>\n",
       "      <td>-24.760829</td>\n",
       "      <td>-28.832010</td>\n",
       "      <td>-25.283141</td>\n",
       "      <td>-26.063285</td>\n",
       "      <td>-23.418672</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.773782</td>\n",
       "      <td>-41.003207</td>\n",
       "      <td>-36.506794</td>\n",
       "      <td>-25.580735</td>\n",
       "      <td>-22.453830</td>\n",
       "      <td>3.642904</td>\n",
       "      <td>6.551416</td>\n",
       "      <td>0.463518</td>\n",
       "      <td>0.936664</td>\n",
       "      <td>-27.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3316</td>\n",
       "      <td>21.079766</td>\n",
       "      <td>11.637573</td>\n",
       "      <td>13.558403</td>\n",
       "      <td>-9.893018</td>\n",
       "      <td>2.573208</td>\n",
       "      <td>-22.632429</td>\n",
       "      <td>12.959620</td>\n",
       "      <td>18.931481</td>\n",
       "      <td>15.791468</td>\n",
       "      <td>-0.968569</td>\n",
       "      <td>...</td>\n",
       "      <td>27.752771</td>\n",
       "      <td>21.888568</td>\n",
       "      <td>15.209581</td>\n",
       "      <td>18.406033</td>\n",
       "      <td>14.394370</td>\n",
       "      <td>27.769338</td>\n",
       "      <td>28.287930</td>\n",
       "      <td>25.557817</td>\n",
       "      <td>26.247857</td>\n",
       "      <td>26.464227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5645</td>\n",
       "      <td>6.462986</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>-9.333129</td>\n",
       "      <td>-3.300113</td>\n",
       "      <td>-8.258814</td>\n",
       "      <td>-20.615119</td>\n",
       "      <td>-29.202079</td>\n",
       "      <td>-25.054321</td>\n",
       "      <td>-12.786564</td>\n",
       "      <td>-4.775674</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.774123</td>\n",
       "      <td>-6.890295</td>\n",
       "      <td>25.462953</td>\n",
       "      <td>18.750033</td>\n",
       "      <td>28.544915</td>\n",
       "      <td>29.574194</td>\n",
       "      <td>26.730558</td>\n",
       "      <td>18.537209</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>-9.914011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>21.567372</td>\n",
       "      <td>17.213610</td>\n",
       "      <td>18.869283</td>\n",
       "      <td>5.228945</td>\n",
       "      <td>3.181769</td>\n",
       "      <td>-9.277802</td>\n",
       "      <td>-4.438520</td>\n",
       "      <td>9.120031</td>\n",
       "      <td>13.654372</td>\n",
       "      <td>14.644074</td>\n",
       "      <td>...</td>\n",
       "      <td>33.183937</td>\n",
       "      <td>32.004164</td>\n",
       "      <td>29.872098</td>\n",
       "      <td>29.184973</td>\n",
       "      <td>27.761547</td>\n",
       "      <td>26.321243</td>\n",
       "      <td>29.199746</td>\n",
       "      <td>30.961252</td>\n",
       "      <td>34.033286</td>\n",
       "      <td>34.135880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3539</td>\n",
       "      <td>0.165386</td>\n",
       "      <td>21.354151</td>\n",
       "      <td>2.083760</td>\n",
       "      <td>-6.174497</td>\n",
       "      <td>-6.231603</td>\n",
       "      <td>1.162061</td>\n",
       "      <td>0.659924</td>\n",
       "      <td>-3.969674</td>\n",
       "      <td>-3.165011</td>\n",
       "      <td>-12.191002</td>\n",
       "      <td>...</td>\n",
       "      <td>30.159408</td>\n",
       "      <td>28.490874</td>\n",
       "      <td>26.150959</td>\n",
       "      <td>29.766860</td>\n",
       "      <td>28.474605</td>\n",
       "      <td>26.887929</td>\n",
       "      <td>26.165526</td>\n",
       "      <td>27.567009</td>\n",
       "      <td>28.703594</td>\n",
       "      <td>30.255283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date       2016.01.01  2016.01.02  2016.01.03  2016.01.04  2016.01.05  \\\n",
       "ID_HDC_G0                                                               \n",
       "5782       -22.592424  -23.554328    2.574384   -0.192710  -19.426103   \n",
       "3316        21.079766   11.637573   13.558403   -9.893018    2.573208   \n",
       "5645         6.462986    0.297900   -9.333129   -3.300113   -8.258814   \n",
       "3185        21.567372   17.213610   18.869283    5.228945    3.181769   \n",
       "3539         0.165386   21.354151    2.083760   -6.174497   -6.231603   \n",
       "\n",
       "date       2016.01.06  2016.01.07  2016.01.08  2016.01.09  2016.01.10  ...  \\\n",
       "ID_HDC_G0                                                              ...   \n",
       "5782       -24.760829  -28.832010  -25.283141  -26.063285  -23.418672  ...   \n",
       "3316       -22.632429   12.959620   18.931481   15.791468   -0.968569  ...   \n",
       "5645       -20.615119  -29.202079  -25.054321  -12.786564   -4.775674  ...   \n",
       "3185        -9.277802   -4.438520    9.120031   13.654372   14.644074  ...   \n",
       "3539         1.162061    0.659924   -3.969674   -3.165011  -12.191002  ...   \n",
       "\n",
       "date       2016.12.22  2016.12.23  2016.12.24  2016.12.25  2016.12.26  \\\n",
       "ID_HDC_G0                                                               \n",
       "5782       -41.773782  -41.003207  -36.506794  -25.580735  -22.453830   \n",
       "3316        27.752771   21.888568   15.209581   18.406033   14.394370   \n",
       "5645       -19.774123   -6.890295   25.462953   18.750033   28.544915   \n",
       "3185        33.183937   32.004164   29.872098   29.184973   27.761547   \n",
       "3539        30.159408   28.490874   26.150959   29.766860   28.474605   \n",
       "\n",
       "date       2016.12.27  2016.12.28  2016.12.29  2016.12.30  2016.12.31  \n",
       "ID_HDC_G0                                                              \n",
       "5782         3.642904    6.551416    0.463518    0.936664  -27.764096  \n",
       "3316        27.769338   28.287930   25.557817   26.247857   26.464227  \n",
       "5645        29.574194   26.730558   18.537209    0.690558   -9.914011  \n",
       "3185        26.321243   29.199746   30.961252   34.033286   34.135880  \n",
       "3539        26.887929   26.165526   27.567009   28.703594   30.255283  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2016.01.01</th>\n",
       "      <th>2016.01.02</th>\n",
       "      <th>2016.01.03</th>\n",
       "      <th>2016.01.04</th>\n",
       "      <th>2016.01.05</th>\n",
       "      <th>2016.01.06</th>\n",
       "      <th>2016.01.07</th>\n",
       "      <th>2016.01.08</th>\n",
       "      <th>2016.01.09</th>\n",
       "      <th>2016.01.10</th>\n",
       "      <th>...</th>\n",
       "      <th>2016.12.22</th>\n",
       "      <th>2016.12.23</th>\n",
       "      <th>2016.12.24</th>\n",
       "      <th>2016.12.25</th>\n",
       "      <th>2016.12.26</th>\n",
       "      <th>2016.12.27</th>\n",
       "      <th>2016.12.28</th>\n",
       "      <th>2016.12.29</th>\n",
       "      <th>2016.12.30</th>\n",
       "      <th>2016.12.31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5782</td>\n",
       "      <td>-22.592424</td>\n",
       "      <td>-23.554328</td>\n",
       "      <td>2.574384</td>\n",
       "      <td>-0.192710</td>\n",
       "      <td>-19.426103</td>\n",
       "      <td>-24.760829</td>\n",
       "      <td>-28.832010</td>\n",
       "      <td>-25.283141</td>\n",
       "      <td>-26.063285</td>\n",
       "      <td>-23.418672</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.773782</td>\n",
       "      <td>-41.003207</td>\n",
       "      <td>-36.506794</td>\n",
       "      <td>-25.580735</td>\n",
       "      <td>-22.453830</td>\n",
       "      <td>3.642904</td>\n",
       "      <td>6.551416</td>\n",
       "      <td>0.463518</td>\n",
       "      <td>0.936664</td>\n",
       "      <td>-27.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3316</td>\n",
       "      <td>21.079766</td>\n",
       "      <td>11.637573</td>\n",
       "      <td>13.558403</td>\n",
       "      <td>-9.893018</td>\n",
       "      <td>2.573208</td>\n",
       "      <td>-22.632429</td>\n",
       "      <td>12.959620</td>\n",
       "      <td>18.931481</td>\n",
       "      <td>15.791468</td>\n",
       "      <td>-0.968569</td>\n",
       "      <td>...</td>\n",
       "      <td>27.752771</td>\n",
       "      <td>21.888568</td>\n",
       "      <td>15.209581</td>\n",
       "      <td>18.406033</td>\n",
       "      <td>14.394370</td>\n",
       "      <td>27.769338</td>\n",
       "      <td>28.287930</td>\n",
       "      <td>25.557817</td>\n",
       "      <td>26.247857</td>\n",
       "      <td>26.464227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5645</td>\n",
       "      <td>6.462986</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>-9.333129</td>\n",
       "      <td>-3.300113</td>\n",
       "      <td>-8.258814</td>\n",
       "      <td>-20.615119</td>\n",
       "      <td>-29.202079</td>\n",
       "      <td>-25.054321</td>\n",
       "      <td>-12.786564</td>\n",
       "      <td>-4.775674</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.774123</td>\n",
       "      <td>-6.890295</td>\n",
       "      <td>25.462953</td>\n",
       "      <td>18.750033</td>\n",
       "      <td>28.544915</td>\n",
       "      <td>29.574194</td>\n",
       "      <td>26.730558</td>\n",
       "      <td>18.537209</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>-9.914011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>21.567372</td>\n",
       "      <td>17.213610</td>\n",
       "      <td>18.869283</td>\n",
       "      <td>5.228945</td>\n",
       "      <td>3.181769</td>\n",
       "      <td>-9.277802</td>\n",
       "      <td>-4.438520</td>\n",
       "      <td>9.120031</td>\n",
       "      <td>13.654372</td>\n",
       "      <td>14.644074</td>\n",
       "      <td>...</td>\n",
       "      <td>33.183937</td>\n",
       "      <td>32.004164</td>\n",
       "      <td>29.872098</td>\n",
       "      <td>29.184973</td>\n",
       "      <td>27.761547</td>\n",
       "      <td>26.321243</td>\n",
       "      <td>29.199746</td>\n",
       "      <td>30.961252</td>\n",
       "      <td>34.033286</td>\n",
       "      <td>34.135880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3539</td>\n",
       "      <td>0.165386</td>\n",
       "      <td>21.354151</td>\n",
       "      <td>2.083760</td>\n",
       "      <td>-6.174497</td>\n",
       "      <td>-6.231603</td>\n",
       "      <td>1.162061</td>\n",
       "      <td>0.659924</td>\n",
       "      <td>-3.969674</td>\n",
       "      <td>-3.165011</td>\n",
       "      <td>-12.191002</td>\n",
       "      <td>...</td>\n",
       "      <td>30.159408</td>\n",
       "      <td>28.490874</td>\n",
       "      <td>26.150959</td>\n",
       "      <td>29.766860</td>\n",
       "      <td>28.474605</td>\n",
       "      <td>26.887929</td>\n",
       "      <td>26.165526</td>\n",
       "      <td>27.567009</td>\n",
       "      <td>28.703594</td>\n",
       "      <td>30.255283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date       2016.01.01  2016.01.02  2016.01.03  2016.01.04  2016.01.05  \\\n",
       "ID_HDC_G0                                                               \n",
       "5782       -22.592424  -23.554328    2.574384   -0.192710  -19.426103   \n",
       "3316        21.079766   11.637573   13.558403   -9.893018    2.573208   \n",
       "5645         6.462986    0.297900   -9.333129   -3.300113   -8.258814   \n",
       "3185        21.567372   17.213610   18.869283    5.228945    3.181769   \n",
       "3539         0.165386   21.354151    2.083760   -6.174497   -6.231603   \n",
       "\n",
       "date       2016.01.06  2016.01.07  2016.01.08  2016.01.09  2016.01.10  ...  \\\n",
       "ID_HDC_G0                                                              ...   \n",
       "5782       -24.760829  -28.832010  -25.283141  -26.063285  -23.418672  ...   \n",
       "3316       -22.632429   12.959620   18.931481   15.791468   -0.968569  ...   \n",
       "5645       -20.615119  -29.202079  -25.054321  -12.786564   -4.775674  ...   \n",
       "3185        -9.277802   -4.438520    9.120031   13.654372   14.644074  ...   \n",
       "3539         1.162061    0.659924   -3.969674   -3.165011  -12.191002  ...   \n",
       "\n",
       "date       2016.12.22  2016.12.23  2016.12.24  2016.12.25  2016.12.26  \\\n",
       "ID_HDC_G0                                                               \n",
       "5782       -41.773782  -41.003207  -36.506794  -25.580735  -22.453830   \n",
       "3316        27.752771   21.888568   15.209581   18.406033   14.394370   \n",
       "5645       -19.774123   -6.890295   25.462953   18.750033   28.544915   \n",
       "3185        33.183937   32.004164   29.872098   29.184973   27.761547   \n",
       "3539        30.159408   28.490874   26.150959   29.766860   28.474605   \n",
       "\n",
       "date       2016.12.27  2016.12.28  2016.12.29  2016.12.30  2016.12.31  \n",
       "ID_HDC_G0                                                              \n",
       "5782         3.642904    6.551416    0.463518    0.936664  -27.764096  \n",
       "3316        27.769338   28.287930   25.557817   26.247857   26.464227  \n",
       "5645        29.574194   26.730558   18.537209    0.690558   -9.914011  \n",
       "3185        26.321243   29.199746   30.961252   34.033286   34.135880  \n",
       "3539        26.887929   26.165526   27.567009   28.703594   30.255283  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get GHS-UCDB\n",
    "ghs = gpd.read_file('/home/cascade/projects/UrbanHeat/data/raw/GHS_UCDB/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gpd.GeoDataFrame()\n",
    "out['geometry'] = ghs['geometry']\n",
    "out['ID_HDC_G0'] = ghs['ID_HDC_G0']\n",
    "\n",
    "HI_out = gpd.GeoDataFrame()\n",
    "HI_out['ID_HDC_G0'] = df.index\n",
    "HI_out['2016.07.01'] = df['2016.07.01']\n",
    "\n",
    "out = pd.merge(out, HI_out, on = 'ID_HDC_G0', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out.to_file('/home/cascade/projects/UrbanHeat/HI_20160701_test.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hotcheck values \n",
    "\n",
    "Tmax =  pd.read_csv(Tmax_fn)\n",
    "RH = pd.read_csv(RH_fn)\n",
    "\n",
    "check = pd.DataFrame()\n",
    "check['2016.07.01.HI'] = df['2016.07.01'].sort_values(ascending = False).head(50)\n",
    "check = check.merge(Tmax[['ID_HDC_G0', '2016.07.01']], on = 'ID_HDC_G0', how = 'inner')\n",
    "check.rename(columns = {'2016.07.01':'2016.07.01.Tmax'}, inplace = True)\n",
    "check = check.merge(RH[['ID_HDC_G0', '2016.07.01']], on = 'ID_HDC_G0', how = 'inner')\n",
    "check.rename(columns = {'2016.07.01':'2016.07.01.RH'}, inplace = True)\n",
    "# check['2016.07.01.RH'] = RH['2016.07.01'].sort_values(ascending = False).head(50)\n",
    "\n",
    "\n",
    "# df['2016.07.01'].sort_values(ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_HDC_G0</th>\n",
       "      <th>2016.07.01.HI</th>\n",
       "      <th>2016.07.01.Tmax</th>\n",
       "      <th>2016.07.01.RH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8076</td>\n",
       "      <td>149.982576</td>\n",
       "      <td>42.480167</td>\n",
       "      <td>52.281685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7947</td>\n",
       "      <td>149.849048</td>\n",
       "      <td>42.416350</td>\n",
       "      <td>52.465736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7801</td>\n",
       "      <td>149.146126</td>\n",
       "      <td>41.838413</td>\n",
       "      <td>54.470192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7866</td>\n",
       "      <td>148.968031</td>\n",
       "      <td>41.753212</td>\n",
       "      <td>54.727620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7988</td>\n",
       "      <td>148.927533</td>\n",
       "      <td>41.975243</td>\n",
       "      <td>53.759575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_HDC_G0  2016.07.01.HI  2016.07.01.Tmax  2016.07.01.RH\n",
       "0       8076     149.982576        42.480167      52.281685\n",
       "1       7947     149.849048        42.416350      52.465736\n",
       "2       7801     149.146126        41.838413      54.470192\n",
       "3       7866     148.968031        41.753212      54.727620\n",
       "4       7988     148.927533        41.975243      53.759575"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkTmax = xr.DataArray(check['2016.07.01.Tmax'].to_numpy())\n",
    "checkRH = xr.DataArray(check['2016.07.01.RH'].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check the heat index\n",
    "checkHI = heatindex(checkTmax, checkRH, unit_in = 'C', unit_out = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (dim_0: 50)>\n",
       "array([149.982576, 149.849048, 149.146126, 148.968031, 148.927533, 148.537434,\n",
       "       148.477097, 147.963079, 147.88449 , 147.599435, 147.24237 , 147.044344,\n",
       "       146.72067 , 146.666001, 146.608057, 146.579288, 146.572298, 146.421116,\n",
       "       146.400205, 146.34497 , 146.309686, 146.178303, 146.133537, 146.08185 ,\n",
       "       146.020217, 146.005356, 145.989807, 145.983705, 145.956715, 145.784795,\n",
       "       145.690167, 145.656583, 145.607071, 145.575731, 145.55699 , 145.320791,\n",
       "       145.197122, 144.971663, 144.917968, 144.845825, 144.60538 , 144.56525 ,\n",
       "       144.446476, 144.414984, 144.358871, 144.35668 , 144.345614, 144.283951,\n",
       "       144.282328, 144.281888])\n",
       "Dimensions without coordinates: dim_0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (dim_0: 4)>\n",
       "array([146.188224, 139.536591, 133.219817, 127.237902])\n",
       "Dimensions without coordinates: dim_0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with the conditions above test\n",
    "temp = xr.DataArray([42, 41, 40, 39])\n",
    "rh = xr.DataArray([52, 52, 52, 52])\n",
    "heatindex(temp, rh, unit_in = 'C', unit_out = 'F')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well it makes sense\n",
    "\n",
    "These crazy high values make sense when checked with NOAA's table. But once you have a Tmax >40C and RH > 40%, the HI values is crazy high ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_xr(file_in, time_dim, space_dim):\n",
    "    \n",
    "    \"\"\" Function reads in a csv w/ GHS-UCDB IDs and temp, isolates the temp\n",
    "    and returns a xarray data array with dims set to city ids and dates\n",
    "    \n",
    "    Args:\n",
    "        file_in = file name and path\n",
    "        time_dim = name for time dim as a str ... use date :-)\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_in) # read the file in as a df\n",
    "    print(df.shape)\n",
    "    \n",
    "    df_id = df[space_dim] # get IDs\n",
    "    df = df.iloc[:,3:] # get only temp columns\n",
    "    df.index = df_id # set index values\n",
    "    df_drop = df.dropna() # Drop cities w/ no temp record \n",
    "    print(len(df_drop))\n",
    "    \n",
    "    arr = df_drop.to_numpy() # turn temp cols into an np array\n",
    "    \n",
    "    # make xr Data Array w/ data as temp and dims as spece (e.g. id)\n",
    "    \n",
    "    # Note 2019 09 17 changed to xr.Dataset from xr.Dataarray\n",
    "    temp_xr_da = xr.DataArray(arr, coords=[df_temp_drop.index, df_temp_drop.columns], \n",
    "                            dims=[space_dim, time_dim])\n",
    "    \n",
    "    return xr_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #2 Function finds all the Tmax Events and writes it to a dateframe w/ dates for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_days(xarray, Tthresh):\n",
    "    \"\"\" Function finds all the tmax days in a year and sums total days per year \n",
    "    greater than a threshold within a year where Tmax > Tthresh for each city. Returns the total number of days,\n",
    "    the dates, the tempatures, and the intensity (daily Tmax - Tthresh)\n",
    "    \n",
    "    Args: \n",
    "        xarray = an xarray object with dims = (space, times)\n",
    "        Tthresh = int of temp threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty lists & df\n",
    "    id_list = []\n",
    "    date_list = []\n",
    "    dayTot_list = []\n",
    "    tmax_list = []\n",
    "    intensity_list = []\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # subset xarray\n",
    "    out = xarray.where(xarray > Tthresh, drop = True)\n",
    "\n",
    "    # start loop \n",
    "    for index, loc in enumerate(out.ID_HDC_G0):\n",
    "        id_list.append(out.ID_HDC_G0.values[index]) # get IDS\n",
    "        date_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values) # get event dates\n",
    "        \n",
    "        # this is actually getting the total events of all, 2019-09-22\n",
    "        dayTot_list.append(len(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').date.values)) # get event totals\n",
    "        \n",
    "        tmax_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values) # get temp values\n",
    "        intensity_list.append(out.sel(ID_HDC_G0 = loc).dropna(dim = 'date').values - Tthresh) # get severity\n",
    "\n",
    "    # write to a data frame\n",
    "    df_out['ID_HDC_G0'] = id_list\n",
    "    df_out['total_days'] = dayTot_list\n",
    "    df_out['dates'] = date_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "    df_out['tmax_tntensity'] = intensity_list\n",
    "\n",
    "    # return df_out\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #3 Function splits the dataset into Tmax events (continuous days >Tmax) for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jul_convert(dates):\n",
    "    \"Function turn days into julian datetime\"\n",
    "    jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "    \n",
    "    return jul_days\n",
    "\n",
    "def event_split(dates, ID_HDC_G0, intensity, tmax, total_days):\n",
    "    \"\"\" Searchs a list of dates and isolates sequential dates as a list, then calculates event stats.\n",
    "    See comments in code for more details. \n",
    "    \n",
    "    Args:\n",
    "        dates: pandas.core.index as julian dates\n",
    "        ID_HDC_G0: city ID as string\n",
    "        country: country for each city as string\n",
    "        intensity: numpy.ndarray of intensities values\n",
    "        tmax: numpy.ndarray of intensities values of tmax values\n",
    "        total_days: total number of tmax days in a year for a given city\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # city id\n",
    "    city_id = ID_HDC_G0\n",
    "    tot_days = total_days\n",
    "    \n",
    "    # lists to fill\n",
    "    city_id_list = []\n",
    "    tot_days_list = []\n",
    "    event_dates_list = []\n",
    "    dur_list = []\n",
    "    intensity_list = []\n",
    "    tmax_list = []\n",
    "    avg_temp_list = []\n",
    "    avg_int_list = []\n",
    "    tot_int_list = []\n",
    "    \n",
    "    # data frame out\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # turn days into julian days\n",
    "    jul_days = jul_convert(dates)\n",
    "    \n",
    "    # Counters to make sure we write the correct event dates to a list, don't want julian days in output\n",
    "    counter = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    # Loop through dur list and isolate seq days, temps, and intensities\n",
    "    for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "        \n",
    "        seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "        dur = len(seq) # duration of each event\n",
    "        \n",
    "        counter = counter + dur # add duration to counter\n",
    "        end = counter # end of current event\n",
    "        \n",
    "        event_dates = dates[start:end] # dates of tmax days during each event\n",
    "        intense = intensity[start:end] # intensity of each day during event\n",
    "        temp = tmax[start:end] # temp of each day during event\n",
    "        avg_temp = mean(temp) # avg. temp during event\n",
    "        avg_int = mean(intense) # avg. intensity during event\n",
    "        tot_int = intense.sum() # total intensity during event\n",
    "        \n",
    "        start = counter # reset start to current end (e.g. counter)\n",
    "        \n",
    "        # fill lists\n",
    "        city_id_list.append(city_id)\n",
    "        tot_days_list.append(tot_days)\n",
    "        dur_list.append(dur)\n",
    "        event_dates_list.append(event_dates)\n",
    "        intensity_list.append(intense)\n",
    "        tmax_list.append(temp)\n",
    "        avg_temp_list.append(avg_temp)\n",
    "        avg_int_list.append(avg_int)\n",
    "        tot_int_list.append(tot_int)\n",
    "\n",
    "    # write out as a dateframe\n",
    "    df_out['ID_HDC_G0'] = city_id_list\n",
    "    df_out['total_days'] = tot_days_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['avg_temp'] = avg_temp_list\n",
    "    df_out['avg_intensity'] = avg_int_list\n",
    "    df_out['tot_intensity'] = tot_int_list\n",
    "    df_out['event_dates'] = event_dates_list\n",
    "    df_out['duration'] = dur_list\n",
    "    df_out['intensity'] = intensity_list\n",
    "    df_out['tmax'] = tmax_list\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #4 Function feeds output from function 2 into function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmax_stats(df_in):\n",
    "    \"\"\" runs event_split functionon a dataframe to produce desired tmax stats\n",
    "    \n",
    "        NOTE - If you add arguments to event_split to make more states, \n",
    "        be sure to update this function\n",
    "    \n",
    "        args:\n",
    "            df: input dataframe\n",
    "        \n",
    "    \"\"\"\n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # NOTE - If you add arguments to event_split to make more stats, \n",
    "    # be sure to update this function\n",
    "    \n",
    "    for index, row in df_in.iterrows():\n",
    "        dates = row['dates'] # Get event dates\n",
    "        intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "        tmax = row['tmax'] # Get tmax for each day\n",
    "        ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "        total_days = row['total_days'] # get total number of tmax days\n",
    "\n",
    "        df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "\n",
    "        df_out = df_out.append(df)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #5 Loops through a file list and applies functions 1 - 4 to the data to produce Tmax stats for all tmax events in a given year across all cities in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_loop(dir_in, dir_out, fn_out, time_dim, space_dim, Tthresh):\n",
    "    \n",
    "    \"\"\" Loop through a dir with csvs to apply csv_to_xr and\n",
    "    tmax_stats function and save out a .csv for each year\n",
    "    \n",
    "    Args:\n",
    "        dir_in = dir path to loop through\n",
    "        dir_out = dir path to save files out\n",
    "        fn_out = string to label out files\n",
    "        time_dim = name for time dim as a str ... use date :-) for csv_to_xr function\n",
    "        space_dim = col name for GHS-UCDB IDs as an str (ID_HDC_G0) for csv_to_xr function\n",
    "        Tthresh = int of temp threshold for temp_event function -- 40.6 is used\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open the GHS-ID List with GeoPANDAS read_file\n",
    "    ghs_ids_fn = 'GHS-UCSB-IDS.csv'\n",
    "    ghs_ids_df = pd.read_csv(DATA_INTERIM+ghs_ids_fn)\n",
    "        \n",
    "    # Git File list\n",
    "    fn_list = glob.glob(dir_in+'*.csv')\n",
    "    \n",
    "    for fn in sorted(fn_list):\n",
    "        \n",
    "        # Get year for arg for temp_event function\n",
    "        year = fn.split('GHS-Tmax-DAILY_')[1].split('.csv')[0]\n",
    "        print(year)\n",
    "        \n",
    "        # read csv as a data array\n",
    "        temp_xr_da = csv_to_xr(fn, time_dim, space_dim)\n",
    "        \n",
    "        # data array to tmax events, out as df\n",
    "        df_days = tmax_days(temp_xr_da, Tthresh)\n",
    "        \n",
    "        # tmax events stats, out as df\n",
    "        df_out = tmax_stats(df_days)\n",
    "        \n",
    "        # merge to get countries\n",
    "        ghs_ids_df_out = ghs_ids_df.merge(df_out, on='ID_HDC_G0', how = 'inner') \n",
    "        \n",
    "        # write it all out\n",
    "        ghs_ids_df_out.to_csv(dir_out+fn_out+year+'.csv')\n",
    "\n",
    "        print(year, 'SAVED!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/UrbanHeat/data/interim/' # ghs ID list\n",
    "dir_out = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'\n",
    "fn_out = 'CHIRTS-GHS-Events-Stats'\n",
    "time_dim = 'date'\n",
    "space_dim = 'ID_HDC_G0'\n",
    "Tthresh = 40.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stats_loop(dir_in, dir_out, fn_out, time_dim, space_dim, Tthresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA/QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "\n",
    "dir_out = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-Events-Stats/'\n",
    "fn_out = 'CHIRTS-GHS-Events-Stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_df = pd.read_csv(dir_out+fn_out+'1983.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_city = qc_df[qc_df['ID_HDC_G0'] == 5534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/data_out_urbanheat/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open a raw file\n",
    "xr1983 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days1983 = tmax_days(xr1983, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = days1983[0:30]\n",
    "test\n",
    "\n",
    "# Maybe add in days_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build routine for loop through a csv\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "    \n",
    "    df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "    \n",
    "    df_out = df_out.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing code\n",
    "2019.10.19 Cascade Tuholkse\n",
    "\n",
    "Need to fix ```event split``` function\n",
    "\n",
    "Somewhere in 1984 is this event sequence: ['1984.01.01' '1984.01.02' '1984.01.07']\n",
    "\n",
    "\n",
    "**FOUND PROBLEM AND IT IS FIXED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DAILY_PATH = '/home/cascade/projects/data_out_urbanheat/CHIRTS-GHS-DAILY/' # output from avg temp\n",
    "DATA_INTERIM = '/home/cascade/projects/data_out_urbanheatv/data/interim/'\n",
    "DATA_OUT = '/home/cascade/projects/data_out_urbanheat/testout/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to test\n",
    "fn_in = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open a raw file\n",
    "xr1983 = csv_to_xr(DAILY_PATH+fn_in, 'date', 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the tmax days\n",
    "tmax1983 = tmax_days(xr1983, 40.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset\n",
    "\n",
    "test = tmax1983[tmax1983['ID_HDC_G0'] == 6279]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to jul days\n",
    "jul_days = pd.to_datetime(dates).to_julian_date()\n",
    "jul_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjd = 2445507.5 - 43200\n",
    "dt = julian.from_jd(mjd, fmt='mjd')\n",
    "print(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['1983.06.20', '1983.06.23', '1983.06.24', '1983.06.25',\n",
    "        '1983.06.26', '1983.06.27', '1983.06.28', '1983.06.29',\n",
    "        '1983.06.30', '1983.07.01', '1983.07.21', '1983.07.22',\n",
    "        '1983.07.23', '1983.08.01']\n",
    "\n",
    "pd_dates = pd.to_datetime(dates)\n",
    "df_dates = pd.DataFrame()\n",
    "df_dates['dates'] = pd_dates\n",
    "\n",
    "\n",
    "\n",
    "test = df_dates['dates'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "date.fromordinal(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = dates[0:10] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))\n",
    "\n",
    "event_dates = dates[10:13] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))\n",
    "\n",
    "event_dates = dates[13:14] # dates of tmax days during each event\n",
    "print(event_dates)\n",
    "print(len(event_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates_list = []\n",
    "counter = 0\n",
    "start = 0\n",
    "end = 0\n",
    "\n",
    "for k, g in groupby(enumerate(jul_days.values), lambda x: x[1]-x[0]):\n",
    "    \n",
    "    len_dates = len(dates) # len of all Tmax dates for a given city\n",
    "#   print(len(dates))\n",
    "    \n",
    "    seq = list(map(itemgetter(1), g)) # isolate seq. days\n",
    "    dur = len(seq) # duration of each event \n",
    "    \n",
    "    counter = counter + dur\n",
    "    end = counter\n",
    "    \n",
    "    print(end)\n",
    "    \n",
    "    event_dates = dates[start:end] # dates of tmax days during each event\n",
    "    print(event_dates)\n",
    "    \n",
    "    start = counter\n",
    "    \n",
    "# #     print('dur= ', dur)\n",
    "    \n",
    "#     event_dates = dates[0:10] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "#     event_dates = dates[11:13] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "#     event_dates = dates[:len_dates] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     counter = counter + dur\n",
    "\n",
    "#     print('counter = ', counter)\n",
    "    \n",
    "#     dif = dur - counter\n",
    "#     print('dif = ', dif)\n",
    "    \n",
    "#     start = start \n",
    "#     print('start = ',start)\n",
    "    \n",
    "# #     end = counter + dur\n",
    "# #     print(\"start = \",end)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     counter = counter + dur\n",
    "#     print(counter)\n",
    "#     end = counter + dur\n",
    "#     start\n",
    "#     event_dates = dates[start:end] # dates of tmax days during each event\n",
    "#     print(event_dates)\n",
    "# #     intense = intensity[0:dur] # intensity of each day during event\n",
    "#     temp = tmax[0:dur] # temp of each day during event\n",
    "#     avg_temp = mean(temp) # avg. temp during event\n",
    "#     avg_int = mean(intense) # avg. intensity during event\n",
    "#     tot_int = intense.sum() # total intensity during event\n",
    "    \n",
    "#     event_dates_list.append(event_dates)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['event_dates'] = event_dates_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tmax stats ------> CLEARLY NOTE WORKING\n",
    "\n",
    "# tmax1983_sub_stats = tmax_stats(tmax1983_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tmax1983['dates'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = tmax1983_sub['dates']\n",
    "#jul_days = pd.to_datetime(tmax1983['dates']).to_julian_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to break up events\n",
    "\n",
    "for index, row in tmax1983_sub.iterrows():\n",
    "    dates = row['dates'] # Get event dates\n",
    "    intensity = row['tmax_tntensity'] # Get intensity for each day\n",
    "    tmax = row['tmax'] # Get tmax for each day\n",
    "    ID_HDC_G0 = row['ID_HDC_G0'] # get city id\n",
    "    total_days = row['total_days'] # get total number of tmax days\n",
    "\n",
    "#     df = event_split(dates, ID_HDC_G0, intensity, tmax, total_days)\n",
    "\n",
    "#     df_out = df_out.append(df)\n",
    "\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_out['events'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Heat Index\n",
    "\n",
    "Get some paired values from the [NOAA CHART](https://www.weather.gov/safety/heat-index) and test the output. \n",
    "\n",
    "These results seem to be working well, though 104 F and 60 RH produced a higher number than the chart ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [25, 27, 35, 40, 41] # temp C\n",
    "RH = 60\n",
    "test = pd.DataFrame()\n",
    "test['temp'] = temp\n",
    "test['RH'] = RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, row in test.iterrows():\n",
    "    out = make_hi(row['temp'], row['RH'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the temp x array from C to F\n",
    "\n",
    "temp_xr_da = C_to_F(temp_xr_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply steadman's\n",
    "\n",
    "HI_steadman = steadman_hi(temp_xr_da, RH_xr_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## this doesn't work \n",
    "#HI_rothfusz = rothfusz_hi(HI_steadman, temp_xr_da, RH_xr_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_to_F(Tmax_C):\n",
    "    \"Function converts temp in c to f\"\n",
    "    Tmax_F = (Tmax_C * (9/5)) + 32\n",
    "    \n",
    "    return Tmax_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steadman_hi(Tmax_F, RH):\n",
    "    \"Simple heat index calculation\"\n",
    "    \n",
    "    HI_steadman = 0.5 * (Tmax_F + 61.0 + ((Tmax_F-68.0)*1.2) + (RH*0.094))\n",
    "    \n",
    "    HI_steadman = (HI_steadman + Tmax_F) / 2\n",
    "    \n",
    "    return HI_steadman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rothfusz_hi(HI_steadman, Tmax_F, RH):\n",
    "    \n",
    "    \"Heat Index applied to Steadman's heat index >80F\"\n",
    "    \n",
    "    if (HI_steadman > 80):\n",
    "    \n",
    "        HI_rothfusz = -42.379 + 2.04901523*Tmax_F + 10.14333127*RH - .22475541*Tmax_F*RH - .00683783*Tmax_F*Tmax_F - .05481717*RH*RH + .00122874*Tmax_F*Tmax_F*RH + .00085282*Tmax_F*RH*RH - .00000199*Tmax_F*Tmax_F*RH*RH\n",
    "    \n",
    "    if (RH < 13) & (Tmax_F > 80) & (Tmax_F < 112):\n",
    "        adjustment = ((13-RH)/4)*math.sqrt((17-abs(Tmax_F-95))/17)\n",
    "        HI_rothfusz = HI_rothfusz - adjustment \n",
    "    \n",
    "    \"If the RH is greater than 85% and the temperature is between 80 and 87 degrees F\" \n",
    "    if (RH > 85) & (Tmax_F > 80) & (Tmax_F < 87):\n",
    "        adjustment = ((RH-85)/10) * ((87-Tmax_F)/5)\n",
    "        HI_rothfusz = HI_rothfusz + adjustment \n",
    "    \n",
    "    return HI_rothfusz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hi(Tmax_F, RH):\n",
    "    \"Calculates the heat index for a CHIRTS Tmax value\"\n",
    "    Tmax_F = C_to_F(Tmax_C)\n",
    "#     print('F is ', Tmax_F)\n",
    "#     print('H is ', RH)\n",
    "    HI_steadman = steadman_hi(Tmax_F, RH)\n",
    "#     print('HI_steadman is ', HI_steadman)\n",
    "    HI_rothfusz = rothfusz_hi(HI_steadman, Tmax_F, RH)\n",
    "#     print('HI_rothfusz is ', HI_rothfusz)\n",
    "    \n",
    "    return HI_rothfusz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_RH = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-RH/'\n",
    "DIR_RAW = '/home/cascade/projects/UrbanHeat/data/interim/CHIRTS-GHS-DAILY-TEMP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_RH = 'GHS-Tmax-RH_1983.csv'\n",
    "FN_RAW = 'GHS-Tmax-DAILY_1983.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH = pd.read_csv(DIR_RH+FN_RH)\n",
    "RAW = pd.read_csv(DIR_RAW+FN_RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH = csv_to_xr(DIR_RH+FN_RH, time_dim = 'date', space_dim = 'ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_id = RAW['ID_HDC_G0'] # get IDs\n",
    "df_temp = RAW.iloc[:,3:] # get only temp columns\n",
    "df_temp.index = df_temp_id # set index values\n",
    "df_temp_drop = df_temp.dropna() # Drop cities w/ no temp record \n",
    "print(len(df_temp_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RH_id = RH['ID_HDC_G0'] # get IDs\n",
    "df_RH = RH.iloc[:,3:] # get only temp columns\n",
    "df_RH.index = df_RH_id # set index values\n",
    "df_RH_drop = df_RH.dropna() # Drop cities w/ no temp record \n",
    "print(len(df_RH_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try np arrays\n",
    "# temp_arr = df_temp_drop.to_numpy()\n",
    "# rh_arr = df_RH_drop.to_numpy()\n",
    "\n",
    "# Make them into a data array\n",
    "temp_xr_da = xr.DataArray(df_temp_drop, coords=[df_temp_drop.index, df_temp_drop.columns], \n",
    "                            dims=['ID_HDC_G0', 'date'])\n",
    "RH_xr_da = xr.DataArray(df_RH_drop, coords=[df_RH_drop.index, df_RH_drop.columns], \n",
    "                            dims=['ID_HDC_G0', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = hi(temp_xr_da, RH_xr_da, 'C') # STILL THROWS ERROR FIX IT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leap Year Load Issue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
