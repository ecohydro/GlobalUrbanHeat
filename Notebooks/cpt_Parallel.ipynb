{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program finds the TMax from CHIRTSMax Data and a raster with polygon IDS burned\n",
    "# By Cascade Tuholske 2019-08-20\n",
    "\n",
    "# Dependencies\n",
    "import rasterio \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio import features\n",
    "import os\n",
    "import xarray as xr\n",
    "import fnmatch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL TEST \n",
    "CHIRT_DIR = '/Users/cascade/Github/UrbanHeat/data/test_in/' # <<--- path to loop through\n",
    "SHP_DIR = '/Users/cascade/Github/PopRaster/data/raw/JRC/ghs-ucdb/'\n",
    "POLY_RST_DIR = '/Users/cascade/Github/PopRaster/data/interim/'\n",
    "DATA_OUT = '/Users/cascade/Gbithub/UrbanHeat/data/test_out/'\n",
    "\n",
    "# TANA\n",
    "# CHIRT_DIR = '/home/cascade/tana-spin-cascade/projects/CHIRTMax_Monthly/' # <<--- path to loop through\n",
    "# SHP_DIR = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/Data/raw/GHS_UCDB/'\n",
    "# POLY_RST_DIR = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/Data/interim/'\n",
    "# DATA_OUT = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/Data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open Polygon Raster\n",
    "# polyRst_fn = 'GHS_UCDB_Raster_Raster_touched.tif'\n",
    "# polyRst = rasterio.open(POLY_RST_DIR+polyRst_fn)\n",
    "\n",
    "# # Open the file with GeoPANDAS read_file\n",
    "# shp_fn = 'GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp'\n",
    "# shps = gpd.read_file(SHP_DIR+shp_fn)\n",
    "\n",
    "# # Set fn out, change as needed \n",
    "# fn_out = 'GHS-CHIRT-MONTHLY'  \n",
    "\n",
    "# # Isloate SHP Poly Col to merge back in later \n",
    "# df_ghs = gpd.GeoDataFrame()\n",
    "\n",
    "# df_ghs['ID_HDC_G0'] = shps.ID_HDC_G0\n",
    "# df_ghs['CTR_MN_NM'] = shps.CTR_MN_NM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn polyRst data as Xarray, \n",
    "# polyRst_da = xr.DataArray(polyRst.read(1), dims = ['y', 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through dirs\n",
    "\n",
    "# helper function \n",
    "def temp_ghs(dir_nm):\n",
    "#     print(type(dir_nm))\n",
    "\n",
    "    # Open files \n",
    "    # Open Polygon Raster\n",
    "    polyRst_fn = 'GHS_UCDB_Raster_Raster_touched.tif'\n",
    "    polyRst = rasterio.open(POLY_RST_DIR+polyRst_fn)\n",
    "\n",
    "    # Open the file with GeoPANDAS read_file\n",
    "    shp_fn = 'GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp'\n",
    "    shps = gpd.read_file(SHP_DIR+shp_fn)\n",
    "\n",
    "    # Set fn out, change as needed \n",
    "    fn_out = 'GHS-CHIRT-MONTHLY'  \n",
    "\n",
    "    # Isloate SHP Poly Col to merge back in later \n",
    "    df_ghs = gpd.GeoDataFrame()\n",
    "\n",
    "    df_ghs['ID_HDC_G0'] = shps.ID_HDC_G0\n",
    "    df_ghs['CTR_MN_NM'] = shps.CTR_MN_NM\n",
    "    \n",
    "    # Turn polyRst data as Xarray, \n",
    "    polyRst_da = xr.DataArray(polyRst.read(1), dims = ['y', 'x'])\n",
    "\n",
    "    # Start Loop\n",
    "    for fn in os.listdir(dir_nm):\n",
    "        \n",
    "        # Set dir name for writing files\n",
    "        dir_year = dir_nm.split(CHIRT_DIR)[1]\n",
    "        \n",
    "        # find all the tif files\n",
    "        if fn.endswith('.tif'):\n",
    "\n",
    "                # NEED TO BUILD META DATA CHECK INTO ROUTINE and throw an error<<<<---------\n",
    "\n",
    "                # Get the date of each chirt file\n",
    "                date = (fn.split('CHIRTSmax.')[1].split('.tif')[0])\n",
    "                print(dir_year)\n",
    "                print(date)\n",
    "\n",
    "                # Open CHIRT Data and turn data into array\n",
    "                tempRst = rasterio.open(dir_nm+'/'+fn)\n",
    "\n",
    "                # Make arrays into x    array DataArray\n",
    "                tempRst_da = xr.DataArray(tempRst.read(1), dims = ['y', 'x']) # y and x are our 2-d labels\n",
    "\n",
    "                # Make xarray dataset\n",
    "                ds = xr.Dataset(data_vars = \n",
    "                        {'ghs' : (['y', 'x'], polyRst_da),\n",
    "                        'temp' : (['y', 'x'], tempRst_da),})\n",
    "\n",
    "                # UPDATED 2019-08-19 Mask the CHIRTS PIXELS FIRST, THEN GHS\n",
    "                # Mask values from chirt that are ocean in ghs and chirt in our ds \n",
    "                ds_mask = ds.where(ds.temp != -9999, drop = False) #<<<<------ need to double check this\n",
    "\n",
    "                # Mask pixels for both ghs and chirts where ghs cities are not present\n",
    "                ds_mask = ds_mask.where(ds_mask.ghs > 0, drop = False)\n",
    "\n",
    "                # Group poly_IDs find temp\n",
    "                avg = ds_mask.groupby('ghs').mean(xr.ALL_DIMS)\n",
    "\n",
    "                # turn GHS IDS and avg. CHIRTMax values into 1-D numpy arrays of equal length\n",
    "                avg_ID = np.array(avg.ghs)\n",
    "                avg_temp = np.array(avg.temp)\n",
    "\n",
    "                print(len(avg_ID))\n",
    "                print(len(avg_temp))\n",
    "\n",
    "                # turn chirt max and IDS into a DF\n",
    "                df_avg = pd.DataFrame()\n",
    "                df_avg[date] = avg_temp\n",
    "                df_avg['ID_HDC_G0'] = avg_ID\n",
    "\n",
    "                # merge the df\n",
    "                # df_merge = df_merge.merge(df_avg, on='ID_HDC_G0', how = 'outer') <<<<----- NEED TO FIX THIS\n",
    "\n",
    "\n",
    "    #df_merge.to_csv(DATA_OUT+fn_out+'_'+dir_year+'ParPro.csv') # csv out\n",
    "    print('DONE ! ! !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEED TO FIX MERGE, SHOULD BE // otherwise whoot! Check clock speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year2\n",
      "1983.09\n",
      "Year1\n",
      "1983.01\n",
      "13067\n",
      "13067\n",
      "Year1\n",
      "1983.03\n",
      "13067\n",
      "13067\n",
      "Year2\n",
      "1983.08\n",
      "13067\n",
      "13067\n",
      "Year1\n",
      "1983.02\n",
      "13067\n",
      "13067\n",
      "Year2\n",
      "1983.12\n",
      "13067\n",
      "13067\n",
      "Year1\n",
      "1983.06\n",
      "13067\n",
      "13067\n",
      "Year2\n",
      "1983.07\n",
      "13067\n",
      "13067\n",
      "Year1\n",
      "1983.05\n",
      "13067\n",
      "13067\n",
      "Year2\n",
      "1983.11\n",
      "13067\n",
      "13067\n",
      "Year1\n",
      "1983.04\n",
      "13067\n",
      "13067\n",
      "Year2\n",
      "1983.10\n"
     ]
    }
   ],
   "source": [
    "CHIRT_DIR = '/Users/cascade/Github/UrbanHeat/data/test_in/' # <<--- path to loop through\n",
    "\n",
    "from multiprocessing import Pool, Queue, Process\n",
    "import time \n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# helper function \n",
    "# def open_file(dir_nm):\n",
    "# #     print(type(dir_nm))\n",
    "#     for fn in os.listdir(dir_nm):\n",
    "#         date = (fn.split('CHIRTSmax.')[1].split('.tif')[0])\n",
    "#         print(date)\n",
    "\n",
    "dir_list = glob(CHIRT_DIR+\"/*\")\n",
    "\n",
    "from multiprocessing import Pool\n",
    " \n",
    "def doubler(number):\n",
    "    return number * 2\n",
    " \n",
    "pool = Pool(processes=3)\n",
    "print(pool.map(temp_ghs, dir_list))\n",
    "\n",
    "# for dir_nm in (dir_list):\n",
    "#     proc = Process(target=temp_ghs, args=(dir_nm,))\n",
    "#     proc.start()\n",
    "#     proc.join()\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
