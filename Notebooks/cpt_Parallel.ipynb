{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program finds the TMax from CHIRTSMax Data and a raster with polygon IDS burned in Parallel\n",
    "By Cascade Tuholske 2019-08-20\n",
    "\n",
    "https://sebastianraschka.com/Articles/2014_multiprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program finds the TMax from CHIRTSMax Data and a raster with polygon IDS burned\n",
    "# By Cascade Tuholske 2019-08-20\n",
    "\n",
    "#https://sebastianraschka.com/Articles/2014_multiprocessing.html\n",
    "\n",
    "# Dependencies\n",
    "import rasterio \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio import features\n",
    "import os\n",
    "import xarray as xr\n",
    "import fnmatch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset core affienity ??\n",
    "# os.system(\"taskset -p 0xff %d\" % os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL TEST \n",
    "# CHIRT_DIR = '/Users/cascade/Github/UrbanHeat/data/test_in/' # <<--- path to loop through\n",
    "# SHP_DIR = '/Users/cascade/Github/PopRaster/data/raw/JRC/ghs-ucdb/'\n",
    "# POLY_RST_DIR = '/Users/cascade/Github/PopRaster/data/interim/'\n",
    "# DATA_OUT = '/Users/cascade/Github/UrbanHeat/data/test_out/'\n",
    "\n",
    "# TANA\n",
    "CHIRT_DIR = '/home/cascade/tana-spin-cascade/projects/UrbanTempData/CHTSMax_Monthly/' # <<--- path to loop through\n",
    "SHP_DIR = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/raw/GHS_UCDB/'\n",
    "POLY_RST_DIR = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/interim/'\n",
    "DATA_OUT = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/processed/'\n",
    "\n",
    "# Tana Test\n",
    "# CHIRT_DIR = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/test_in/' # <<--- path to loop through\n",
    "# DATA_OUT = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/test_out/' # <<--- path to loop through\n",
    "# POLY_RST_DIR = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/interim/'\n",
    "# SHP_DIR = '/home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/raw/GHS_UCDB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through dirs in //\n",
    "\n",
    "def temp_ghs(dir_nm):\n",
    "    \n",
    "    # print current process\n",
    "    print(mp.current_process())\n",
    "    \n",
    "    #     print(type(dir_nm))\n",
    "\n",
    "    # Open files \n",
    "    # Open Polygon Raster\n",
    "    polyRst_fn = 'GHS_UCDB_Raster_touched.tif'\n",
    "    polyRst = rasterio.open(POLY_RST_DIR+polyRst_fn)\n",
    "\n",
    "    # Open the file with GeoPANDAS read_file\n",
    "    shp_fn = 'GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_0.shp'\n",
    "    shps = gpd.read_file(SHP_DIR+shp_fn)\n",
    "\n",
    "    # Set fn out, change as needed \n",
    "    fn_out = 'GHS-CHIRT-MONTHLY'  \n",
    "\n",
    "    # Isloate SHP Poly Col to merge back in later \n",
    "    df_ghs = gpd.GeoDataFrame()\n",
    "\n",
    "    df_ghs['ID_HDC_G0'] = shps.ID_HDC_G0\n",
    "    df_ghs['CTR_MN_NM'] = shps.CTR_MN_NM\n",
    "    \n",
    "    # Turn polyRst data as Xarray, \n",
    "    polyRst_da = xr.DataArray(polyRst.read(1), dims = ['y', 'x'])\n",
    "\n",
    "    # Start Loop\n",
    "    for fn in os.listdir(dir_nm):\n",
    "        \n",
    "        # Set dir name for writing files\n",
    "        dir_year = dir_nm.split(CHIRT_DIR)[1].split('/')[0]\n",
    "\n",
    "        \n",
    "        # find all the tif files\n",
    "        if fn.endswith('.tif'):\n",
    "\n",
    "                # Get the date of each chirt file\n",
    "                date = (fn.split('CHTSmax.')[1].split('.tif')[0]) # change this ! \n",
    "                print(dir_year)\n",
    "                print(date)\n",
    "\n",
    "                # Open CHIRT Data and turn data into array\n",
    "                tempRst = rasterio.open(dir_nm+'/'+fn)\n",
    "\n",
    "                # Make arrays into x    array DataArray\n",
    "                tempRst_da = xr.DataArray(tempRst.read(1), dims = ['y', 'x']) # y and x are our 2-d labels\n",
    "\n",
    "                # Make xarray dataset\n",
    "                ds = xr.Dataset(data_vars = \n",
    "                        {'ghs' : (['y', 'x'], polyRst_da),\n",
    "                        'temp' : (['y', 'x'], tempRst_da),})\n",
    "\n",
    "                # UPDATED 2019-08-19 Mask the CHIRTS PIXELS FIRST, THEN GHS\n",
    "                # Mask values from chirt that are ocean in ghs and chirt in our ds \n",
    "                ds_mask = ds.where(ds.temp != -9999, drop = False) #<<<<------ need to double check this\n",
    "\n",
    "                # Mask pixels for both ghs and chirts where ghs cities are not present\n",
    "                ds_mask = ds_mask.where(ds_mask.ghs > 0, drop = False)\n",
    "\n",
    "                # Group poly_IDs find temp\n",
    "                avg = ds_mask.groupby('ghs').mean(xr.ALL_DIMS)\n",
    "\n",
    "                # turn GHS IDS and avg. CHIRTMax values into 1-D numpy arrays of equal length\n",
    "                avg_ID = np.array(avg.ghs)\n",
    "                avg_temp = np.array(avg.temp)\n",
    "\n",
    "                print(len(avg_ID))\n",
    "                print(len(avg_temp))\n",
    "\n",
    "                # turn chirt max and IDS into a DF\n",
    "                df_avg = pd.DataFrame()\n",
    "                df_avg[date] = avg_temp\n",
    "                df_avg['ID_HDC_G0'] = avg_ID\n",
    "\n",
    "                # merge the df\n",
    "                df_merge = df_ghs.merge(df_avg, on='ID_HDC_G0', how = 'outer') #<<<<----- NEED TO FIX THIS\n",
    "\n",
    "    df_merge.to_csv(DATA_OUT+fn_out+'_'+dir_year+'test.csv') # csv out\n",
    "    print('DONE ! ! !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get dir list\n",
    "from glob import glob\n",
    "\n",
    "dir_list= glob(CHIRT_DIR+'*/')\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, Queue, Process\n",
    "import time \n",
    "import os\n",
    "import multiprocessing as mp\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# start pools\n",
    "pool = Pool(processes = 7)\n",
    "pool.map(temp_ghs, dir_list)\n",
    "# pool.map_async(temp_ghs, dir_list)\n",
    "pool.close()\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test function \n",
    "# def test_mp(dir_nm):\n",
    "#     # Start Loop\n",
    "    \n",
    "#     # print current process\n",
    "#     print(mp.current_process())\n",
    "    \n",
    "#     fn_list = []\n",
    "#     for fn in os.listdir(dir_nm):\n",
    "        \n",
    "#         # find all the tif files\n",
    "#         if fn.endswith('.tif'):\n",
    "\n",
    "#                 # Get the date of each chirt file\n",
    "#                 date = (fn.split('CHIRTSmax.')[1].split('.tif')[0])\n",
    "                \n",
    "#                 print(dir_year)\n",
    "#                 print(date)\n",
    "                \n",
    "#                 fn_list.append(date)\n",
    "#     print(fn_list)\n",
    "#     # Save it out\n",
    "#     out_df = pd.DataFrame(fn_list)\n",
    "#     out_df.to_csv(DATA_OUT+dir_year+'.csv')\n",
    "\n",
    "#     /home/cascade/tana-crunch-cascade/projects/UrbanHeat/data/test_out/GHS-CHIRT-MONTHLY_Year2/ParPro.csv'\n",
    "    \n",
    "#     #df_merge.to_csv(DATA_OUT+fn_out+'_'+dir_year+'ParPro.csv') # csv out\n",
    "#     print('DONE ! ! !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
