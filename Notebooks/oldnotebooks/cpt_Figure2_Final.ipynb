{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2 Final\n",
    "\n",
    "Notebook to make figure 2 for ms <br>\n",
    "by Cascade Tuholske 2020.02.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Depdencies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from scipy.optimize import fmin\n",
    "from scipy.stats import beta\n",
    "from scipy.special import gamma as gammaf\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions\n",
    "def OLS(df, geog, col, alpha):\n",
    "    \n",
    "    \"\"\"Finds linear coef for increase in stat by a given geography from 1983 - 2016, as well\n",
    "    as the pct change in population of the cities within the given geography\n",
    "    \n",
    "    NOTE 2020.03.01 - This will throw a run time warning if all values of a col are zero (e.g. can regress\n",
    "    a bunch of zeros) ... See note in run_OLD. CPT \n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        df = HI stats dataframe\n",
    "        geog = subset geography to calc people days regression\n",
    "        col = col to regress on \n",
    "        alpha = ci alpha for coef\n",
    "    \"\"\"\n",
    "\n",
    "    # Get results\n",
    "    labels = []\n",
    "    #delt_list = [] #CPT 2020.02.26\n",
    "    #r2_list = [] #CPT 2020.02.26\n",
    "    coef_list = []\n",
    "    leftci_list = []\n",
    "    rightci_list = []\n",
    "    p_list = []\n",
    "    df_out = pd.DataFrame()\n",
    "\n",
    "    for label, df_geog in df.groupby(geog):\n",
    "\n",
    "        # Get Data\n",
    "        X_year = np.array(df_geog.groupby('year')['ID_HDC_G0'].mean().index).reshape((-1, 1))\n",
    "        Y_stats = np.array(df_geog.groupby('year')[col].sum()).reshape((-1, 1))\n",
    "\n",
    "        # Add Intercept\n",
    "        X_year_2 = sm.add_constant(X_year)\n",
    "\n",
    "        # Regress\n",
    "        model = sm.OLS(Y_stats, X_year_2).fit() \n",
    "        \n",
    "        # Get slope\n",
    "        # first param in intercept coef, second is slope of line but if slope = 0, then intecept\n",
    "        if len(model.params) == 2:\n",
    "            coef = model.params[1]\n",
    "            \n",
    "        else:\n",
    "            coef = model.params[0]\n",
    "        \n",
    "        # R2 and P\n",
    "        #r2 = model.rsquared_adj #CPT 2020.02.26\n",
    "        p = model.pvalues[0]\n",
    "\n",
    "        # Pop change #CPT 2020.02.26\n",
    "#         delt = df_geog.drop_duplicates('ID_HDC_G0').copy()\n",
    "#         delt['delt_pop'] = delt['P2016'] - delt['P1983']\n",
    "#         delt = delt['delt_pop'].sum()\n",
    "\n",
    "        # GET Left and Right CI\n",
    "        left_ci = model.conf_int(alpha=alpha)[1][0]\n",
    "        right_ci = model.conf_int(alpha=alpha)[1][1]\n",
    "        \n",
    "        # Make lists\n",
    "        labels.append(label)\n",
    "        #r2_list.append(r2) #CPT 2020.02.26\n",
    "        coef_list.append(coef)\n",
    "        p_list.append(p)\n",
    "        leftci_list.append(left_ci)\n",
    "        rightci_list.append(right_ci)\n",
    "        #delt_list.append(delt) #CPT 2020.02.26\n",
    "\n",
    "    # Make data frame\n",
    "    df_out[geog] = labels\n",
    "    #df_out['p_delt'] = delt_list #CPT 2020.02.26\n",
    "    #df_out['r2'] = r2_list #CPT 2020.02.26\n",
    "    df_out['coef'] = coef_list\n",
    "    df_out['p_value'] = [round(elem, 4) for elem in p_list]\n",
    "    df_out['ci_left'] = leftci_list\n",
    "    df_out['ci_right'] = rightci_list \n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_OLS(stats, geog, alpha):\n",
    "    \"\"\" Function calculate OLS coef of people days due to pop and heat and the \n",
    "    attribution index for distribution plots.\n",
    "    \n",
    "        \n",
    "    NOTE 2020.03.01 - This will throw a run time warning if all values of a col are zero (e.g. can regress\n",
    "    a bunch of zeros, now can we). This will happen if people_days, people_days_pop, people_days_heat or \n",
    "    total_days is zero for all years for a given city. This is still OK for our analysis. What is happening is\n",
    "    that for some cities, the people-days due to heat is zero, meaning pday increases in only due to population. \n",
    "    \n",
    "    This is because with the GHS-UCDB some city's population in 1983 is zero, which forces the pdays due to heat\n",
    "    to be zero.\n",
    "    \n",
    "    -- CPT  \n",
    "    \n",
    "    Args:\n",
    "        stats = df to feed in\n",
    "        geog = geography level to conduct analysis (city-level is 'ID-HDC-G0')\n",
    "        alpha = alpha for CI coef   \n",
    "    \"\"\"\n",
    "    # Get coef for people days\n",
    "    out = OLS(stats, geog, 'people_days', alpha = alpha)\n",
    "    out.rename(columns={\"coef\": \"coef_pdays\"}, inplace = True)\n",
    "    out.rename(columns={\"p_value\": \"p_value_pdays\"}, inplace = True)\n",
    "    out.rename(columns={\"ci_left\": \"ci_left_pdays\"}, inplace = True)\n",
    "    out.rename(columns={\"ci_right\": \"ci_right_pdays\"}, inplace = True)\n",
    "    \n",
    "    # Get people days due to heat coef\n",
    "    heat = OLS(stats, geog, 'people_days_heat', alpha = alpha) # get stats \n",
    "    heat.rename(columns={\"coef\": \"coef_heat\"}, inplace = True)\n",
    "    heat.rename(columns={\"p_value\": \"p_value_heat\"}, inplace = True)\n",
    "    heat.rename(columns={\"ci_left\": \"ci_left_heat\"}, inplace = True)\n",
    "    heat.rename(columns={\"ci_right\": \"ci_right_heat\"}, inplace = True)\n",
    "    out = out.merge(heat, on = geog, how = 'left') # merge\n",
    "    \n",
    "    # Get people days due to pop\n",
    "    pop = OLS(stats, geog, 'people_days_pop', alpha = alpha) # get stats \n",
    "    pop.rename(columns={\"coef\": \"coef_pop\"}, inplace = True)\n",
    "    pop.rename(columns={\"p_value\": \"p_value_pop\"}, inplace = True)\n",
    "    pop.rename(columns={\"ci_left\": \"ci_left_pop\"}, inplace = True)\n",
    "    pop.rename(columns={\"ci_right\": \"ci_right_pop\"}, inplace = True)\n",
    "    out = out.merge(pop, on = geog, how = 'left') # merge\n",
    "    \n",
    "    # Get total days\n",
    "    totDays = OLS(stats, geog, 'total_days', alpha = alpha) # get stats \n",
    "    totDays.rename(columns={\"coef\": \"coef_totDays\"}, inplace = True)\n",
    "    totDays.rename(columns={\"p_value\": \"p_value_totDays\"}, inplace = True)\n",
    "    totDays.rename(columns={\"ci_left\": \"ci_left_totDays\"}, inplace = True)\n",
    "    totDays.rename(columns={\"ci_right\": \"ci_right_totDays\"}, inplace = True)\n",
    "    out = out.merge(totDays, on = geog, how = 'left') # merge\n",
    "    \n",
    "    # attrib coef --- creates range -1 to 1 index of heat vs. population as a driver of total pdays increase\n",
    "    out['coef_attrib'] = (out['coef_pop'] - out['coef_heat']) / (out['coef_pop'] + out['coef_heat']) # normalize dif\n",
    "    \n",
    "    # I am not sure if this works correcetly ... CPT 2020.02.27\n",
    "    out['coef_attrib_left'] = (out['ci_left_pop'] - out['ci_left_heat']) / (out['ci_left_pop'] + out['ci_left_heat']) # normalize dif\n",
    "    out['coef_attrib_right'] = (out['ci_right_pop'] - out['ci_right_heat']) / (out['ci_right_pop'] + out['ci_left_heat']) # normalize dif\n",
    "    \n",
    "    # drop all neg or zero pday slopes\n",
    "    out = out[out['coef_pdays'] > 0]\n",
    "    out = out[out['coef_heat'] > 0]\n",
    "    out = out[out['coef_pop'] > 0]\n",
    "    \n",
    "    # normalize coef of attribution \n",
    "    norm = out['coef_attrib']\n",
    "    out['coef_attrib_norm'] = (norm-min(norm))/(max(norm)-min(norm))\n",
    "    norm = out['coef_attrib_left']\n",
    "    out['coef_attrib_norm_left'] = (norm-min(norm))/(max(norm)-min(norm))\n",
    "    norm = out['coef_attrib_right']\n",
    "    out['coef_attrib_norm_right'] = (norm-min(norm))/(max(norm)-min(norm))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  ID_HDC_G0  year  total_days              P          P1983  \\\n",
      "0           0         22  1983           2   52064.452435   52064.452435   \n",
      "1           1         26  1983           1  194088.886834  194088.886834   \n",
      "\n",
      "           P2016  people_days  people_days_heat  people_days_pop  \n",
      "0   73006.671133     0.000104          0.000104              0.0  \n",
      "1  268055.635628     0.000194          0.000194              0.0  \n",
      "   Unnamed: 0  ID_HDC_G0  year  total_days             P         P1983  \\\n",
      "0           0         22  1983           2  52064.452435  52064.452435   \n",
      "1       10112         22  1984           1  53373.163358  52064.452435   \n",
      "\n",
      "          P2016  people_days  people_days_heat  people_days_pop    region  \\\n",
      "0  73006.671133     0.000104          0.000104         0.000000  Americas   \n",
      "1  73006.671133     0.000053          0.000052         0.000001  Americas   \n",
      "\n",
      "  intermediate-region        sub-region      CTR_MN_NM  \n",
      "0    Northern America  Northern America  United States  \n",
      "1    Northern America  Northern America  United States  \n"
     ]
    }
   ],
   "source": [
    "#### Load Data\n",
    "# file path\n",
    "DATA_IN = \"/home/cascade/projects/UrbanHeat/data/\"  # Note: Need ?dl=1 to make sure this file gets read correctly\n",
    "FIG_OUT = \"/home/cascade/projects/UrbanHeat/figures/\"\n",
    "\n",
    "# Raw Heat\n",
    "FN_IN = 'processed/All_data_HI406_figdata.csv'\n",
    "HI_STATS = pd.read_csv(DATA_IN+FN_IN)\n",
    "\n",
    "# scale the date in the plot \n",
    "scale = 10**9 \n",
    "\n",
    "print(HI_STATS.head(2))\n",
    "\n",
    "# cols we want to add to HI_STATS\n",
    "cols = ['region', 'intermediate-region', 'sub-region','CTR_MN_NM', 'ID_HDC_G0'] \n",
    "\n",
    "# open all the data\n",
    "meta_fn = 'processed/All_data_HI406_meta.csv' # open all the data\n",
    "all_data = pd.read_csv(DATA_IN+meta_fn)\n",
    "\n",
    "# drop ID duplicates\n",
    "meta = all_data.drop_duplicates('ID_HDC_G0')\n",
    "meta = meta[cols]\n",
    "\n",
    "HI_STATS = HI_STATS.merge(meta, on = 'ID_HDC_G0', how = 'inner')\n",
    "print(HI_STATS.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392972\n",
      "391612\n"
     ]
    }
   ],
   "source": [
    "#### Drop 40 cities where P1983 == 40\n",
    "print(len(HI_STATS))\n",
    "HI_STATS = HI_STATS[HI_STATS['P1983'] > 0]\n",
    "print(len(HI_STATS))\n",
    "\n",
    "#### Drop cities with only one Tmax Day in 1983 and none else because you cannot regress them\n",
    "drop_list = [2543, 2560, 3667, 3669, 6122, 6156] # city IDS\n",
    "HI_STATS= HI_STATS[~HI_STATS['ID_HDC_G0'].isin(drop_list)]\n",
    "print(len(HI_STATS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cascade/miniconda3/envs/geo/lib/python3.6/site-packages/statsmodels/base/model.py:1294: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/home/cascade/miniconda3/envs/geo/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/cascade/miniconda3/envs/geo/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/cascade/miniconda3/envs/geo/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    }
   ],
   "source": [
    "#### Chunk Data for plots -- see functions for warnings explained \n",
    "\n",
    "# Get Populations\n",
    "df_years = HI_STATS[['ID_HDC_G0', 'P1983', 'P2016']]\n",
    "df_years = df_years.drop_duplicates('ID_HDC_G0')\n",
    "\n",
    "# Global\n",
    "# plotdata = run_OLS(HI_STATS, 'ID_HDC_G0', alpha = 0.05)\n",
    "\n",
    "# Chunk 1\n",
    "geog1 = 'region'\n",
    "loc1 = 'Europe'\n",
    "chunk1 = HI_STATS[HI_STATS[geog1] == loc1]\n",
    "plotdata1 = run_OLS(chunk1, 'ID_HDC_G0', alpha = 0.05)\n",
    "plotdata1 = plotdata1.merge(df_years, on = 'ID_HDC_G0', how = 'left')\n",
    "\n",
    "# Chunk 2\n",
    "geog2 = 'sub-region'\n",
    "loc2 = 'Eastern Asia'\n",
    "chunk2 = HI_STATS[HI_STATS[geog2] == loc2]\n",
    "plotdata2 = run_OLS(chunk2, 'ID_HDC_G0', alpha = 0.05)\n",
    "plotdata2 = plotdata2.merge(df_years, on = 'ID_HDC_G0', how = 'left')\n",
    "\n",
    "\n",
    "# Chunk 3\n",
    "geog3 = 'sub-region'\n",
    "loc3 = 'Western Asia'\n",
    "chunk3 = HI_STATS[HI_STATS[geog3] == loc3]\n",
    "plotdata3 = run_OLS(chunk3, 'ID_HDC_G0', alpha = 0.05)\n",
    "plotdata3 = plotdata3.merge(df_years, on = 'ID_HDC_G0', how = 'left')\n",
    "\n",
    "# Chunk 4\n",
    "geog4 = 'sub-region'\n",
    "loc4 = 'Sub-Saharan Africa'\n",
    "chunk4 = HI_STATS[HI_STATS[geog4] == loc4]\n",
    "plotdata4 = run_OLS(chunk4, 'ID_HDC_G0', alpha = 0.05)\n",
    "plotdata4 = plotdata4.merge(df_years, on = 'ID_HDC_G0', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Fig 2 Plot\n",
    "\n",
    "# Chunks in a list & colors\n",
    "df_list = [plotdata1 , plotdata2 , plotdata3 , plotdata4, plotdata1 , plotdata2 , plotdata3 , plotdata4]\n",
    "color_list = ['purple', 'teal', 'dodgerblue', 'orange', 'purple', 'teal', 'dodgerblue', 'orange']\n",
    "loc_list = [loc1, loc2, loc3, loc4, loc1, loc2, loc3, loc4]\n",
    "\n",
    "# Size\n",
    "fig, axs = plt.subplots(2, 4, figsize = (24, 12), sharex=False, sharey = False)\n",
    "axs = axs.ravel()\n",
    "fig.subplots_adjust(wspace= 0.25, hspace = 0.35)\n",
    "fig = plt.gcf()\n",
    "xlim_1 = [0,1]\n",
    "ylim_1 = [0,4]\n",
    "\n",
    "# Plot args\n",
    "kwargs = {'lw': 3, 'alpha' : 0.9, 'linestyle' : '-'} # ked line kwargs\n",
    "\n",
    "for i, df in enumerate(zip(df_list, color_list)):\n",
    "    \n",
    "    # First row\n",
    "    if i < 4:\n",
    "        ticks = [0, .25, .5, .75, 1]\n",
    "        labels = [str(100), 50, 0, 50, str(100)]#[100, 80, 60, 40, 20, 0, 20, 40, 60, 80, 100]\n",
    "        data = df[0]['coef_attrib_norm'] # get data\n",
    "        axs[i].hist(data, density = True, color = df[1], alpha = 0.15, bins = 30) # Hist\n",
    "        sns.kdeplot(data, color = df[1], ax = axs[i], **kwargs, legend = False) # kernel\n",
    "        axs[i].set_title(loc_list[i], fontsize = 15) \n",
    "        axs[i].set_xlim(xlim_1)\n",
    "        axs[i].set_ylim(ylim_1)\n",
    "        axs[i].set_ylabel('PDF', fontsize = 15)\n",
    "        axs[i].set_xlabel('% Warming                 % Population', fontsize = 15)\n",
    "        axs[i].set_xticks(ticks);\n",
    "        axs[i].set_xticklabels(labels)\n",
    "    \n",
    "    if i >= 4:\n",
    "        \n",
    "    # Plot Loop 2\n",
    "        X = np.log10(df[0]['coef_pop']*scale)\n",
    "        Y = np.log10(df[0]['coef_heat']*scale)\n",
    "        C = np.log10(df[0]['P2016']) ##########<<<< CASCADE FIX SO WE CAN CITY\n",
    "\n",
    "        # plots\n",
    "        im  = axs[i].scatter(X, Y, alpha = 0.4, marker = 'h', c = C, cmap = 'rainbow')\n",
    "\n",
    "        # Make one-to-one-line\n",
    "        axs[i].plot([0, lim], [0, lim], ':', lw=3, alpha = 0.7, color = 'black')\n",
    "        axs[i].set_title(loc_list[i], fontsize = 15)\n",
    "        \n",
    "        if i == 4:\n",
    "            cmap = axs[i].scatter(X, Y, alpha = 0.4, marker = 'h', c = C, cmap = 'rainbow')\n",
    "\n",
    "        fig.colorbar(ax = axs[i],  mappable = cmap)\n",
    "\n",
    "        # Set limits\n",
    "        axs[i].set_xlim([-0.5, lim])\n",
    "        axs[i].set_ylim([-0.5, lim])\n",
    "        \n",
    "        axs[i].set_ylabel('Increase from Warming [log10]', fontsize = 15)\n",
    "        axs[i].set_xlabel('Increase from Population [log10]', fontsize = 15)\n",
    "\n",
    "\n",
    "# Set the ticks and ticklabels for all axes\n",
    "#plt.setp(axs, xticks=ticks, xticklabels=labels);\n",
    "\n",
    "## Labels \n",
    "# plt.xlabel('Coef of Attribtuion (Right is people, left heat)', fontsize = 15, labelpad = 10)\n",
    "# plt.ylabel('PDF', fontsize = 15)\n",
    "# fig.title('Dist of PeopleDays Attribution Coef, 1983 - 2016', fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = HI_STATS.drop_duplicates('ID_HDC_G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(check[check['P1983'] == 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
